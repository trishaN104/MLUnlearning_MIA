{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, log_loss, confusion_matrix, accuracy_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data = pd.read_csv(\"../data/loan_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_map = {'High School': 0, 'Associate': 1, 'Bachelor':2, 'Master':3, 'Doctorate':4}\n",
    "\n",
    "loan_data['person_education'] = loan_data['person_education'].map(education_map)\n",
    "\n",
    "\n",
    "hot_enc_cols = ['person_gender', 'person_home_ownership','loan_intent', 'previous_loan_defaults_on_file']\n",
    "loan_data = pd.get_dummies(loan_data, columns=hot_enc_cols,drop_first=True)\n",
    "\n",
    "\n",
    "to_fix_col = loan_data.select_dtypes(include='bool').columns\n",
    "loan_data[to_fix_col] = loan_data[to_fix_col].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_education</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_emp_exp</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>person_gender_male</th>\n",
       "      <th>person_home_ownership_OTHER</th>\n",
       "      <th>person_home_ownership_OWN</th>\n",
       "      <th>person_home_ownership_RENT</th>\n",
       "      <th>loan_intent_EDUCATION</th>\n",
       "      <th>loan_intent_HOMEIMPROVEMENT</th>\n",
       "      <th>loan_intent_MEDICAL</th>\n",
       "      <th>loan_intent_PERSONAL</th>\n",
       "      <th>loan_intent_VENTURE</th>\n",
       "      <th>previous_loan_defaults_on_file_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>3</td>\n",
       "      <td>71948.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>16.02</td>\n",
       "      <td>0.49</td>\n",
       "      <td>3.0</td>\n",
       "      <td>561</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12282.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>11.14</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>504</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12438.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>12.87</td>\n",
       "      <td>0.44</td>\n",
       "      <td>3.0</td>\n",
       "      <td>635</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.0</td>\n",
       "      <td>2</td>\n",
       "      <td>79753.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>15.23</td>\n",
       "      <td>0.44</td>\n",
       "      <td>2.0</td>\n",
       "      <td>675</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0</td>\n",
       "      <td>3</td>\n",
       "      <td>66135.0</td>\n",
       "      <td>1</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>14.27</td>\n",
       "      <td>0.53</td>\n",
       "      <td>4.0</td>\n",
       "      <td>586</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12951.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>7.14</td>\n",
       "      <td>0.19</td>\n",
       "      <td>2.0</td>\n",
       "      <td>532</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26.0</td>\n",
       "      <td>2</td>\n",
       "      <td>93471.0</td>\n",
       "      <td>1</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>12.42</td>\n",
       "      <td>0.37</td>\n",
       "      <td>3.0</td>\n",
       "      <td>701</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>95550.0</td>\n",
       "      <td>5</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>11.11</td>\n",
       "      <td>0.37</td>\n",
       "      <td>4.0</td>\n",
       "      <td>585</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>100684.0</td>\n",
       "      <td>3</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>8.90</td>\n",
       "      <td>0.35</td>\n",
       "      <td>2.0</td>\n",
       "      <td>544</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12739.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>14.74</td>\n",
       "      <td>0.13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>640</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person_age  person_education  person_income  person_emp_exp  loan_amnt  \\\n",
       "0        22.0                 3        71948.0               0    35000.0   \n",
       "1        21.0                 0        12282.0               0     1000.0   \n",
       "2        25.0                 0        12438.0               3     5500.0   \n",
       "3        23.0                 2        79753.0               0    35000.0   \n",
       "4        24.0                 3        66135.0               1    35000.0   \n",
       "5        21.0                 0        12951.0               0     2500.0   \n",
       "6        26.0                 2        93471.0               1    35000.0   \n",
       "7        24.0                 0        95550.0               5    35000.0   \n",
       "8        24.0                 1       100684.0               3    35000.0   \n",
       "9        21.0                 0        12739.0               0     1600.0   \n",
       "\n",
       "   loan_int_rate  loan_percent_income  cb_person_cred_hist_length  \\\n",
       "0          16.02                 0.49                         3.0   \n",
       "1          11.14                 0.08                         2.0   \n",
       "2          12.87                 0.44                         3.0   \n",
       "3          15.23                 0.44                         2.0   \n",
       "4          14.27                 0.53                         4.0   \n",
       "5           7.14                 0.19                         2.0   \n",
       "6          12.42                 0.37                         3.0   \n",
       "7          11.11                 0.37                         4.0   \n",
       "8           8.90                 0.35                         2.0   \n",
       "9          14.74                 0.13                         3.0   \n",
       "\n",
       "   credit_score  loan_status  person_gender_male  person_home_ownership_OTHER  \\\n",
       "0           561            1                   0                            0   \n",
       "1           504            0                   0                            0   \n",
       "2           635            1                   0                            0   \n",
       "3           675            1                   0                            0   \n",
       "4           586            1                   1                            0   \n",
       "5           532            1                   0                            0   \n",
       "6           701            1                   0                            0   \n",
       "7           585            1                   0                            0   \n",
       "8           544            1                   0                            0   \n",
       "9           640            1                   0                            0   \n",
       "\n",
       "   person_home_ownership_OWN  person_home_ownership_RENT  \\\n",
       "0                          0                           1   \n",
       "1                          1                           0   \n",
       "2                          0                           0   \n",
       "3                          0                           1   \n",
       "4                          0                           1   \n",
       "5                          1                           0   \n",
       "6                          0                           1   \n",
       "7                          0                           1   \n",
       "8                          0                           1   \n",
       "9                          1                           0   \n",
       "\n",
       "   loan_intent_EDUCATION  loan_intent_HOMEIMPROVEMENT  loan_intent_MEDICAL  \\\n",
       "0                      0                            0                    0   \n",
       "1                      1                            0                    0   \n",
       "2                      0                            0                    1   \n",
       "3                      0                            0                    1   \n",
       "4                      0                            0                    1   \n",
       "5                      0                            0                    0   \n",
       "6                      1                            0                    0   \n",
       "7                      0                            0                    1   \n",
       "8                      0                            0                    0   \n",
       "9                      0                            0                    0   \n",
       "\n",
       "   loan_intent_PERSONAL  loan_intent_VENTURE  \\\n",
       "0                     1                    0   \n",
       "1                     0                    0   \n",
       "2                     0                    0   \n",
       "3                     0                    0   \n",
       "4                     0                    0   \n",
       "5                     0                    1   \n",
       "6                     0                    0   \n",
       "7                     0                    0   \n",
       "8                     1                    0   \n",
       "9                     0                    1   \n",
       "\n",
       "   previous_loan_defaults_on_file_Yes  \n",
       "0                                   0  \n",
       "1                                   1  \n",
       "2                                   0  \n",
       "3                                   0  \n",
       "4                                   0  \n",
       "5                                   0  \n",
       "6                                   0  \n",
       "7                                   0  \n",
       "8                                   0  \n",
       "9                                   0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_education</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_emp_exp</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>person_gender_male</th>\n",
       "      <th>person_home_ownership_OTHER</th>\n",
       "      <th>person_home_ownership_OWN</th>\n",
       "      <th>person_home_ownership_RENT</th>\n",
       "      <th>loan_intent_EDUCATION</th>\n",
       "      <th>loan_intent_HOMEIMPROVEMENT</th>\n",
       "      <th>loan_intent_MEDICAL</th>\n",
       "      <th>loan_intent_PERSONAL</th>\n",
       "      <th>loan_intent_VENTURE</th>\n",
       "      <th>previous_loan_defaults_on_file_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>45000.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>4.500000e+04</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>27.764178</td>\n",
       "      <td>1.383333</td>\n",
       "      <td>8.031905e+04</td>\n",
       "      <td>5.410333</td>\n",
       "      <td>9583.157556</td>\n",
       "      <td>11.006606</td>\n",
       "      <td>0.139725</td>\n",
       "      <td>5.867489</td>\n",
       "      <td>632.608756</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.552022</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.065578</td>\n",
       "      <td>0.520956</td>\n",
       "      <td>0.203400</td>\n",
       "      <td>0.106289</td>\n",
       "      <td>0.189956</td>\n",
       "      <td>0.167822</td>\n",
       "      <td>0.173756</td>\n",
       "      <td>0.507956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.045108</td>\n",
       "      <td>1.077741</td>\n",
       "      <td>8.042250e+04</td>\n",
       "      <td>6.063532</td>\n",
       "      <td>6314.886691</td>\n",
       "      <td>2.978808</td>\n",
       "      <td>0.087212</td>\n",
       "      <td>3.879702</td>\n",
       "      <td>50.435865</td>\n",
       "      <td>0.415744</td>\n",
       "      <td>0.497292</td>\n",
       "      <td>0.050924</td>\n",
       "      <td>0.247545</td>\n",
       "      <td>0.499566</td>\n",
       "      <td>0.402532</td>\n",
       "      <td>0.308210</td>\n",
       "      <td>0.392270</td>\n",
       "      <td>0.373712</td>\n",
       "      <td>0.378903</td>\n",
       "      <td>0.499942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>5.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.720400e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>8.590000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>601.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.704800e+04</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>11.010000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.578925e+04</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>12237.250000</td>\n",
       "      <td>12.990000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>670.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>144.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.200766e+06</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         person_age  person_education  person_income  person_emp_exp  \\\n",
       "count  45000.000000      45000.000000   4.500000e+04    45000.000000   \n",
       "mean      27.764178          1.383333   8.031905e+04        5.410333   \n",
       "std        6.045108          1.077741   8.042250e+04        6.063532   \n",
       "min       20.000000          0.000000   8.000000e+03        0.000000   \n",
       "25%       24.000000          0.000000   4.720400e+04        1.000000   \n",
       "50%       26.000000          1.000000   6.704800e+04        4.000000   \n",
       "75%       30.000000          2.000000   9.578925e+04        8.000000   \n",
       "max      144.000000          4.000000   7.200766e+06      125.000000   \n",
       "\n",
       "          loan_amnt  loan_int_rate  loan_percent_income  \\\n",
       "count  45000.000000   45000.000000         45000.000000   \n",
       "mean    9583.157556      11.006606             0.139725   \n",
       "std     6314.886691       2.978808             0.087212   \n",
       "min      500.000000       5.420000             0.000000   \n",
       "25%     5000.000000       8.590000             0.070000   \n",
       "50%     8000.000000      11.010000             0.120000   \n",
       "75%    12237.250000      12.990000             0.190000   \n",
       "max    35000.000000      20.000000             0.660000   \n",
       "\n",
       "       cb_person_cred_hist_length  credit_score   loan_status  \\\n",
       "count                45000.000000  45000.000000  45000.000000   \n",
       "mean                     5.867489    632.608756      0.222222   \n",
       "std                      3.879702     50.435865      0.415744   \n",
       "min                      2.000000    390.000000      0.000000   \n",
       "25%                      3.000000    601.000000      0.000000   \n",
       "50%                      4.000000    640.000000      0.000000   \n",
       "75%                      8.000000    670.000000      0.000000   \n",
       "max                     30.000000    850.000000      1.000000   \n",
       "\n",
       "       person_gender_male  person_home_ownership_OTHER  \\\n",
       "count        45000.000000                 45000.000000   \n",
       "mean             0.552022                     0.002600   \n",
       "std              0.497292                     0.050924   \n",
       "min              0.000000                     0.000000   \n",
       "25%              0.000000                     0.000000   \n",
       "50%              1.000000                     0.000000   \n",
       "75%              1.000000                     0.000000   \n",
       "max              1.000000                     1.000000   \n",
       "\n",
       "       person_home_ownership_OWN  person_home_ownership_RENT  \\\n",
       "count               45000.000000                45000.000000   \n",
       "mean                    0.065578                    0.520956   \n",
       "std                     0.247545                    0.499566   \n",
       "min                     0.000000                    0.000000   \n",
       "25%                     0.000000                    0.000000   \n",
       "50%                     0.000000                    1.000000   \n",
       "75%                     0.000000                    1.000000   \n",
       "max                     1.000000                    1.000000   \n",
       "\n",
       "       loan_intent_EDUCATION  loan_intent_HOMEIMPROVEMENT  \\\n",
       "count           45000.000000                 45000.000000   \n",
       "mean                0.203400                     0.106289   \n",
       "std                 0.402532                     0.308210   \n",
       "min                 0.000000                     0.000000   \n",
       "25%                 0.000000                     0.000000   \n",
       "50%                 0.000000                     0.000000   \n",
       "75%                 0.000000                     0.000000   \n",
       "max                 1.000000                     1.000000   \n",
       "\n",
       "       loan_intent_MEDICAL  loan_intent_PERSONAL  loan_intent_VENTURE  \\\n",
       "count         45000.000000          45000.000000         45000.000000   \n",
       "mean              0.189956              0.167822             0.173756   \n",
       "std               0.392270              0.373712             0.378903   \n",
       "min               0.000000              0.000000             0.000000   \n",
       "25%               0.000000              0.000000             0.000000   \n",
       "50%               0.000000              0.000000             0.000000   \n",
       "75%               0.000000              0.000000             0.000000   \n",
       "max               1.000000              1.000000             1.000000   \n",
       "\n",
       "       previous_loan_defaults_on_file_Yes  \n",
       "count                        45000.000000  \n",
       "mean                             0.507956  \n",
       "std                              0.499942  \n",
       "min                              0.000000  \n",
       "25%                              0.000000  \n",
       "50%                              1.000000  \n",
       "75%                              1.000000  \n",
       "max                              1.000000  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data.describe()\n",
    "#print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(loan_data, test_size=0.4, random_state=42, stratify=loan_data['loan_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9362"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate_threshold = train_data['loan_int_rate'].quantile(0.85)\n",
    "percent_income_threshold = train_data['loan_percent_income'].quantile(0.85)\n",
    "loan_amnt_threshold = train_data['loan_amnt'].quantile(0.85) \n",
    "\n",
    "\n",
    "\n",
    "forget = train_data[(train_data['loan_int_rate'] >= rate_threshold) | \n",
    "              (train_data['loan_percent_income'] >= percent_income_threshold) |\n",
    "              (train_data['loan_amnt'] >= loan_amnt_threshold)]\n",
    "\n",
    "X_forget = forget.drop(columns=['loan_status'])\n",
    "Y_forget = forget['loan_status']\n",
    "len(forget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=100000, max_iter=10000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=100000, max_iter=10000)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=100000, max_iter=10000)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = LogisticRegression( C=100000,max_iter=10000)\n",
    "\n",
    "X = train_data.drop('loan_status', axis=1)\n",
    "Y =train_data['loan_status']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=42)\n",
    "\n",
    "#change\n",
    "# Find this line:\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_train, Y_train, \n",
    "    train_size=900,  # CHANGE THIS TO 500\n",
    "    random_state=42,\n",
    "    stratify=Y_train\n",
    ")\n",
    "X_train_scale = scaler.fit_transform(X_train)\n",
    "X_test_scale = scaler.transform(X_test)\n",
    "\n",
    "target.fit(X_train_scale, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlearn_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=100000, max_iter=10000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=100000, max_iter=10000)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=100000, max_iter=10000)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep = train_data.drop(forget.index)\n",
    "\n",
    "\n",
    "unlearn = LogisticRegression( C=100000,max_iter=10000)\n",
    "\n",
    "X_unlearn = keep.drop('loan_status', axis=1)\n",
    "Y_unlearn =keep['loan_status']\n",
    "\n",
    "\n",
    "X_train_unlearn, X_test_unlearn, Y_train_unlearn, Y_test_unlearn = train_test_split(X_unlearn, Y_unlearn, test_size=.2, random_state=42)\n",
    "\n",
    "#change\n",
    "X_train_unlearn, X_test_unlearn, Y_train_unlearn, Y_test_unlearn = train_test_split(\n",
    "    X_train_unlearn, Y_train_unlearn,\n",
    "    train_size=900, \n",
    "    random_state=42,\n",
    "    stratify=Y_train_unlearn\n",
    ")\n",
    "\n",
    "X_train_unlearn_scale = unlearn_scaler.fit_transform(X_train_unlearn)\n",
    "X_test_unlearn_scale = unlearn_scaler.transform(X_test_unlearn)\n",
    "\n",
    "unlearn.fit(X_train_unlearn_scale , Y_train_unlearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.832\n",
      "F1: 84.761\n",
      "\n",
      "\n",
      "Accuracy: 75.027\n",
      "F1: 73.756\n",
      "Original model coef: [[ 0.07983598 -0.09723493  0.391805   -0.32748278 -0.76429478  0.81393193\n",
      "   1.5596452   0.02255722 -0.63286981  0.00651187 -0.31550383 -0.24847138\n",
      "   0.25749687 -0.10401367  0.1759697  -0.10180881 -0.20093705 -0.24463165\n",
      "  -6.25775329]]\n",
      "Unlearned model coef: [[ 0.80058035  0.0168508  -1.5632596  -0.55636391  0.41671814  0.52169805\n",
      "  -0.13567845 -0.52575726 -0.29849335  0.19207682 -0.24718648 -0.44170922\n",
      "  -0.16724392 -0.37728983 -0.00638909 -0.3042707  -0.32778792 -0.43827376\n",
      "  -4.45327517]]\n"
     ]
    }
   ],
   "source": [
    "X_forget_scaled = unlearn_scaler.transform(X_forget)\n",
    "\n",
    "\n",
    "\n",
    "predictions = target.predict(X_forget_scaled)\n",
    "predictions_unlearn = unlearn.predict(X_forget_scaled)\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {100*accuracy_score(Y_forget, predictions):.3f}\")\n",
    "\n",
    "print(f\"F1: {100*f1_score(Y_forget, predictions, average='weighted'):.3f}\")\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {100*accuracy_score(Y_forget, predictions_unlearn):.3f}\")\n",
    "\n",
    "print(f\"F1: {100*f1_score(Y_forget, predictions_unlearn, average='weighted'):.3f}\")\n",
    "\n",
    "\n",
    "print(\"Original model coef:\", target.coef_)\n",
    "print(\"Unlearned model coef:\", unlearn.coef_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900\n"
     ]
    }
   ],
   "source": [
    "num_shadow_models = 10\n",
    "chunks = int(len(test_data)/num_shadow_models)\n",
    "shuffled_df = test_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "shadow_sets = []\n",
    "\n",
    "\n",
    "for num in range(num_shadow_models):\n",
    "    start_index = int(chunks*num)\n",
    "    end_index = int(start_index+chunks)\n",
    "\n",
    "    shadow_train, shadow_test = train_test_split(shuffled_df[start_index:end_index], test_size=.5, random_state=42)\n",
    "    shadow_sets.append((shadow_train, shadow_test))\n",
    "\n",
    "print(len(shadow_sets[4][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900\n",
      "shadow model 0 trained\n",
      "900\n",
      "shadow model 1 trained\n",
      "900\n",
      "shadow model 2 trained\n",
      "900\n",
      "shadow model 3 trained\n",
      "900\n",
      "shadow model 4 trained\n",
      "900\n",
      "shadow model 5 trained\n",
      "900\n",
      "shadow model 6 trained\n",
      "900\n",
      "shadow model 7 trained\n",
      "900\n",
      "shadow model 8 trained\n",
      "900\n",
      "shadow model 9 trained\n"
     ]
    }
   ],
   "source": [
    "shadow_models = []\n",
    "shadow_scaled_data = []\n",
    "shadow_scalers =[]\n",
    "for num in range(num_shadow_models):\n",
    "    shadow_scaler = StandardScaler()\n",
    "    \n",
    "    shadow_train = shadow_sets[num][0]\n",
    "    X_shadow_train = shadow_train.drop('loan_status', axis=1)\n",
    "    Y_shadow_train = shadow_train['loan_status']\n",
    "\n",
    "    X_shadow_train_scaled = shadow_scaler.fit_transform(X_shadow_train)\n",
    "    print(len(X_shadow_train))\n",
    "\n",
    "    i = LogisticRegression(C=100000, max_iter=10000)\n",
    "    i.fit(X_shadow_train_scaled, Y_shadow_train )\n",
    "    print(\"shadow model \" + str(num) + \" trained\")\n",
    "\n",
    "    shadow_scalers.append(shadow_scaler)\n",
    "    shadow_scaled_data.append((X_shadow_train_scaled,Y_shadow_train))\n",
    "    shadow_models.append((i))\n",
    " \n",
    "#test if #of shadow models changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_model_metrics(model, X_scaled, y_true, model_name):\n",
    "    \n",
    "    predictions = model.predict(X_scaled)\n",
    "    probabilities = model.predict_proba(X_scaled)[:, 1]  \n",
    "    \n",
    "    metrics = {\n",
    "        f'{model_name}_accuracy': accuracy_score(y_true, predictions),\n",
    "        f'{model_name}_f1': f1_score(y_true, predictions),\n",
    "        f'{model_name}_auc': roc_auc_score(y_true, probabilities)\n",
    "    }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def run_pipeline(config):\\n    scaler = StandardScaler()\\n\\n\\n    train_data, test_data = train_test_split(loan_data, test_size=0.4, random_state=config['random_seed'], stratify=loan_data['loan_status'])\\n\\n\\n    rate_threshold = train_data['loan_int_rate'].quantile(config['forget_percentile'])\\n    percent_income_threshold = train_data['loan_percent_income'].quantile(config['forget_percentile'])\\n    loan_amnt_threshold = train_data['loan_amnt'].quantile(config['forget_percentile'])\\n\\n\\n    forget = train_data[(train_data['loan_int_rate'] >= rate_threshold) |\\n                (train_data['loan_percent_income'] >= percent_income_threshold) |\\n                (train_data['loan_amnt'] >= loan_amnt_threshold)]\\n\\n\\n    X_forget = forget.drop(columns=['loan_status'])\\n    Y_forget = forget['loan_status']\\n    len(forget)\\n\\n\\n    target = LogisticRegression(C=10000, max_iter=10000)\\n\\n\\n    X = train_data.drop('loan_status', axis=1)\\n    Y =train_data['loan_status']\\n\\n\\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=config['random_seed'])\\n\\n\\n    #change\\n    # Find this line:\\n    X_train, X_test, Y_train, Y_test = train_test_split(\\n    X_train, Y_train,\\n    train_size=900,  # CHANGE THIS TO 500\\n    random_state=config['random_seed'],\\n    stratify=Y_train\\n    )\\n    X_train_scale = scaler.fit_transform(X_train)\\n    X_test_scale = scaler.transform(X_test)\\n\\n\\n    target.fit(X_train_scale, Y_train)\\n    unlearn_scaler = StandardScaler()\\n    keep = train_data.drop(forget.index)\\n\\n\\n\\n\\n    unlearn = LogisticRegression(C=10000, max_iter=10000)\\n\\n\\n    X_unlearn = keep.drop('loan_status', axis=1)\\n    Y_unlearn =keep['loan_status']\\n\\n\\n\\n\\n    X_train_unlearn, X_test_unlearn, Y_train_unlearn, Y_test_unlearn = train_test_split(X_unlearn, Y_unlearn, test_size=.2, random_state=config['random_seed'])\\n\\n\\n    #change\\n    X_train_unlearn, X_test_unlearn, Y_train_unlearn, Y_test_unlearn = train_test_split(\\n    X_train_unlearn, Y_train_unlearn,\\n    train_size=900,\\n    random_state=config['random_seed'],\\n    stratify=Y_train_unlearn\\n    )\\n\\n\\n    X_train_unlearn_scale = unlearn_scaler.fit_transform(X_train_unlearn)\\n    X_test_unlearn_scale = unlearn_scaler.transform(X_test_unlearn)\\n\\n\\n    unlearn.fit(X_train_unlearn_scale , Y_train_unlearn)\\n    X_forget_scaled = unlearn_scaler.transform(X_forget)\\n\\n\\n\\n    predictions = target.predict(X_forget_scaled)\\n    predictions_unlearn = unlearn.predict(X_forget_scaled)\\n\\n\\n\\n\\n    num_shadow_models = config['num_shadow_models']\\n    chunks = int(len(test_data)/num_shadow_models)\\n    shuffled_df = test_data.sample(frac=1, random_state=config['random_seed']).reset_index(drop=True)\\n    shadow_sets = []\\n\\n\\n    for num in range(num_shadow_models):\\n        start_index = int(chunks*num)\\n        end_index = int(start_index+chunks)\\n\\n\\n        shadow_train, shadow_test = train_test_split(shuffled_df[start_index:end_index], test_size=.5, random_state=config['random_seed'])\\n        shadow_sets.append((shadow_train, shadow_test))\\n\\n\\n    shadow_models = []\\n    shadow_scaled_data = []\\n    shadow_scalers =[]\\n    for num in range(num_shadow_models):\\n        shadow_scaler = StandardScaler()\\n        \\n        shadow_train = shadow_sets[num][0]\\n        X_shadow_train = shadow_train.drop('loan_status', axis=1)\\n        Y_shadow_train = shadow_train['loan_status']\\n\\n\\n        X_shadow_train_scaled = shadow_scaler.fit_transform(X_shadow_train)\\n\\n\\n\\n        i = LogisticRegression(C=10000,max_iter=10000)\\n        i.fit(X_shadow_train_scaled, Y_shadow_train )\\n\\n\\n        shadow_scalers.append(shadow_scaler)\\n        shadow_scaled_data.append((X_shadow_train_scaled,Y_shadow_train))\\n        shadow_models.append((i))\\n    #test if #of shadow models changes\\n    member_feature= []\\n    member_label = []\\n\\n\\n    for num in range(num_shadow_models):\\n\\n\\n        model = shadow_models[num]\\n        scaled_data = shadow_scaled_data[num][0]\\n        Y_data = shadow_scaled_data[num][1]\\n\\n\\n        results = model.predict_proba(scaled_data)\\n\\n\\n\\n\\n        max_confidence = np.max(results, axis=1)\\n        entropy = -np.sum(results * np.log(results + 1e-8), axis=1)\\n        predictions = model.predict(scaled_data)\\n        true_class_proba = results[np.arange(len(Y_data)), Y_data]\\n        correctness = (predictions == Y_data).astype(int)\\n        loss = -np.log(true_class_proba + 1e-8)\\n        vectors = calculate_model_metrics(model, scaled_data, Y_data, num)\\n      \\n\\n\\n        attack_features = np.column_stack([\\n            max_confidence,\\n            entropy,\\n            true_class_proba,\\n            loss\\n        ])\\n        member_feature.append(attack_features)\\n        member_label.append(np.ones(len(attack_features)))\\n\\n\\n    non_member_feature= []\\n    non_member_label = []\\n\\n\\n    for num in range(num_shadow_models):\\n\\n\\n        model = shadow_models[num]\\n        test_set = shadow_sets[num][1]\\n        scaler = shadow_scalers[num]\\n\\n\\n        X_test = test_set.drop('loan_status', axis=1)\\n        Y_data_test = test_set['loan_status']\\n        X_test_scaled = scaler.transform(X_test)\\n\\n\\n        results = model.predict_proba(X_test_scaled)\\n\\n\\n\\n\\n\\n\\n        max_confidence = np.max(results, axis=1)\\n        entropy = -np.sum(results * np.log(results + 1e-8), axis=1)\\n        predictions = model.predict(X_test_scaled)\\n        true_class_proba = results[np.arange(len(Y_data_test)), Y_data_test]\\n        correctness = (predictions == Y_data_test).astype(int)\\n        loss = -np.log(true_class_proba + 1e-8)\\n\\n\\n        vectors = calculate_model_metrics(model, X_test_scaled, Y_data_test, num)\\n      \\n\\n\\n        attack_features = np.column_stack([\\n            max_confidence,\\n            entropy,\\n            true_class_proba,\\n            loss\\n        ])\\n        #print(attack_features)\\n        non_member_feature.append(attack_features)\\n        non_member_label.append(np.zeros(len(attack_features)))\\n\\n\\n\\n\\n    X_attack = np.vstack(member_feature + non_member_feature)\\n    y_attack = np.hstack(member_label + non_member_label)\\n    attack_scaler = StandardScaler()\\n\\n\\n    X_attack_scale = attack_scaler.fit_transform(X_attack)\\n\\n\\n    attack = LogisticRegression(max_iter=1000)\\n    attack.fit(X_attack_scale, y_attack)\\n    target_results = target.predict_proba(X_forget_scaled)\\n\\n    max_confidence = np.max(target_results, axis=1)\\n    entropy = -np.sum(target_results * np.log(target_results + 1e-8), axis=1)\\n    target_predictions = target.predict(X_forget_scaled)\\n    true_class_proba = target_results[np.arange(len(Y_forget)), Y_forget]\\n    correctness = (target_predictions == Y_forget).astype(int)\\n    loss = -np.log(true_class_proba + 1e-8)\\n\\n\\n    target_attack_features = np.column_stack([\\n        max_confidence,\\n        entropy,\\n        true_class_proba,\\n        loss\\n    ])\\n\\n\\n    target_attack_features_scaled = attack_scaler.transform(target_attack_features)\\n    unlearn_results = unlearn.predict_proba(X_forget_scaled)\\n\\n\\n    max_confidence = np.max(unlearn_results, axis=1)\\n    entropy = -np.sum(unlearn_results * np.log(unlearn_results + 1e-8), axis=1)\\n    unlearn_predictions = unlearn.predict(X_forget_scaled)\\n    true_class_proba = unlearn_results[np.arange(len(Y_forget)), Y_forget]\\n    correctness = (unlearn_predictions == Y_forget).astype(int)\\n    loss = -np.log(true_class_proba + 1e-8)\\n\\n\\n    unlearn_attack_features = np.column_stack([\\n        max_confidence,\\n        entropy,\\n        true_class_proba,\\n        loss\\n    ])\\n\\n\\n    unlearn_attack_features_scaled = attack_scaler.transform(unlearn_attack_features)\\n    target_attack_predictions = attack.predict(target_attack_features_scaled)\\n    target_attack_accuracy = accuracy_score(np.ones(len(target_attack_predictions)), target_attack_predictions)\\n    unlearn_attack_predictions = attack.predict(unlearn_attack_features_scaled)\\n    unlearn_attack_accuracy = accuracy_score(np.ones(len(unlearn_attack_predictions)), unlearn_attack_predictions) \\n\\n\\n    retain_metrics_original = calculate_model_metrics(target, scaler.transform(X_test_scale), Y_test, 'original_retain')\\n    retain_metrics_unlearned = calculate_model_metrics(unlearn, X_test_unlearn_scale, Y_test_unlearn, 'unlearned_retain')\\n    forget_metrics_original = calculate_model_metrics(target, scaler.transform(X_forget), Y_forget, 'original_forget')\\n    forget_metrics_unlearned = calculate_model_metrics(unlearn, X_forget_scaled, Y_forget, 'unlearned_forget')\\n    \\n\\n    unlearn_attack_features_scaled = attack_scaler.transform(unlearn_attack_features)\\n    target_attack_predictions = attack.predict(target_attack_features_scaled)\\n    target_attack_accuracy = accuracy_score(np.ones(len(target_attack_predictions)), target_attack_predictions)\\n    unlearn_attack_predictions = attack.predict(unlearn_attack_features_scaled)\\n    unlearn_attack_accuracy = accuracy_score(np.ones(len(unlearn_attack_predictions)), unlearn_attack_predictions)\\n    \\n    \\n    return {\\n        'attack_model': attack,\\n        'attack_scaler': attack_scaler,\\n        'target_model': target,\\n        'unlearned_model': unlearn,\\n        'target_attack_features_scaled': target_attack_features_scaled,\\n        'forget_set': forget,\\n        'target_accuracy':target_attack_accuracy,\\n        'unlearn_accuracy':unlearn_attack_accuracy,\\n        'retain_metrics_original': retain_metrics_original,\\n        'retain_metrics_unlearned': retain_metrics_unlearned,\\n        'forget_metrics_original': forget_metrics_original,\\n        'forget_metrics_unlearned': forget_metrics_unlearned\\n    }\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#original standalone\n",
    "def run_pipeline(config):\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "\n",
    "    train_data, test_data = train_test_split(loan_data, test_size=0.4, random_state=config['random_seed'], stratify=loan_data['loan_status'])\n",
    "\n",
    "\n",
    "    rate_threshold = train_data['loan_int_rate'].quantile(config['forget_percentile'])\n",
    "    percent_income_threshold = train_data['loan_percent_income'].quantile(config['forget_percentile'])\n",
    "    loan_amnt_threshold = train_data['loan_amnt'].quantile(config['forget_percentile'])\n",
    "\n",
    "\n",
    "    forget = train_data[(train_data['loan_int_rate'] >= rate_threshold) |\n",
    "                (train_data['loan_percent_income'] >= percent_income_threshold) |\n",
    "                (train_data['loan_amnt'] >= loan_amnt_threshold)]\n",
    "\n",
    "\n",
    "    X_forget = forget.drop(columns=['loan_status'])\n",
    "    Y_forget = forget['loan_status']\n",
    "    len(forget)\n",
    "\n",
    "\n",
    "    target = LogisticRegression(C=10000, max_iter=10000)\n",
    "\n",
    "\n",
    "    X = train_data.drop('loan_status', axis=1)\n",
    "    Y =train_data['loan_status']\n",
    "\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=config['random_seed'])\n",
    "\n",
    "\n",
    "    #change\n",
    "    # Find this line:\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_train, Y_train,\n",
    "    train_size=900,  # CHANGE THIS TO 500\n",
    "    random_state=config['random_seed'],\n",
    "    stratify=Y_train\n",
    "    )\n",
    "    X_train_scale = scaler.fit_transform(X_train)\n",
    "    X_test_scale = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "    target.fit(X_train_scale, Y_train)\n",
    "    unlearn_scaler = StandardScaler()\n",
    "    keep = train_data.drop(forget.index)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    unlearn = LogisticRegression(C=10000, max_iter=10000)\n",
    "\n",
    "\n",
    "    X_unlearn = keep.drop('loan_status', axis=1)\n",
    "    Y_unlearn =keep['loan_status']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    X_train_unlearn, X_test_unlearn, Y_train_unlearn, Y_test_unlearn = train_test_split(X_unlearn, Y_unlearn, test_size=.2, random_state=config['random_seed'])\n",
    "\n",
    "\n",
    "    #change\n",
    "    X_train_unlearn, X_test_unlearn, Y_train_unlearn, Y_test_unlearn = train_test_split(\n",
    "    X_train_unlearn, Y_train_unlearn,\n",
    "    train_size=900,\n",
    "    random_state=config['random_seed'],\n",
    "    stratify=Y_train_unlearn\n",
    "    )\n",
    "\n",
    "\n",
    "    X_train_unlearn_scale = unlearn_scaler.fit_transform(X_train_unlearn)\n",
    "    X_test_unlearn_scale = unlearn_scaler.transform(X_test_unlearn)\n",
    "\n",
    "\n",
    "    unlearn.fit(X_train_unlearn_scale , Y_train_unlearn)\n",
    "    X_forget_scaled = unlearn_scaler.transform(X_forget)\n",
    "\n",
    "\n",
    "\n",
    "    predictions = target.predict(X_forget_scaled)\n",
    "    predictions_unlearn = unlearn.predict(X_forget_scaled)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    num_shadow_models = config['num_shadow_models']\n",
    "    chunks = int(len(test_data)/num_shadow_models)\n",
    "    shuffled_df = test_data.sample(frac=1, random_state=config['random_seed']).reset_index(drop=True)\n",
    "    shadow_sets = []\n",
    "\n",
    "\n",
    "    for num in range(num_shadow_models):\n",
    "        start_index = int(chunks*num)\n",
    "        end_index = int(start_index+chunks)\n",
    "\n",
    "\n",
    "        shadow_train, shadow_test = train_test_split(shuffled_df[start_index:end_index], test_size=.5, random_state=config['random_seed'])\n",
    "        shadow_sets.append((shadow_train, shadow_test))\n",
    "\n",
    "\n",
    "    shadow_models = []\n",
    "    shadow_scaled_data = []\n",
    "    shadow_scalers =[]\n",
    "    for num in range(num_shadow_models):\n",
    "        shadow_scaler = StandardScaler()\n",
    "        \n",
    "        shadow_train = shadow_sets[num][0]\n",
    "        X_shadow_train = shadow_train.drop('loan_status', axis=1)\n",
    "        Y_shadow_train = shadow_train['loan_status']\n",
    "\n",
    "\n",
    "        X_shadow_train_scaled = shadow_scaler.fit_transform(X_shadow_train)\n",
    "\n",
    "\n",
    "\n",
    "        i = LogisticRegression(C=10000,max_iter=10000)\n",
    "        i.fit(X_shadow_train_scaled, Y_shadow_train )\n",
    "\n",
    "\n",
    "        shadow_scalers.append(shadow_scaler)\n",
    "        shadow_scaled_data.append((X_shadow_train_scaled,Y_shadow_train))\n",
    "        shadow_models.append((i))\n",
    "    #test if #of shadow models changes\n",
    "    member_feature= []\n",
    "    member_label = []\n",
    "\n",
    "\n",
    "    for num in range(num_shadow_models):\n",
    "\n",
    "\n",
    "        model = shadow_models[num]\n",
    "        scaled_data = shadow_scaled_data[num][0]\n",
    "        Y_data = shadow_scaled_data[num][1]\n",
    "\n",
    "\n",
    "        results = model.predict_proba(scaled_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        max_confidence = np.max(results, axis=1)\n",
    "        entropy = -np.sum(results * np.log(results + 1e-8), axis=1)\n",
    "        predictions = model.predict(scaled_data)\n",
    "        true_class_proba = results[np.arange(len(Y_data)), Y_data]\n",
    "        correctness = (predictions == Y_data).astype(int)\n",
    "        loss = -np.log(true_class_proba + 1e-8)\n",
    "        vectors = calculate_model_metrics(model, scaled_data, Y_data, num)\n",
    "      \n",
    "\n",
    "\n",
    "        attack_features = np.column_stack([\n",
    "            max_confidence,\n",
    "            entropy,\n",
    "            true_class_proba,\n",
    "            loss\n",
    "        ])\n",
    "        member_feature.append(attack_features)\n",
    "        member_label.append(np.ones(len(attack_features)))\n",
    "\n",
    "\n",
    "    non_member_feature= []\n",
    "    non_member_label = []\n",
    "\n",
    "\n",
    "    for num in range(num_shadow_models):\n",
    "\n",
    "\n",
    "        model = shadow_models[num]\n",
    "        test_set = shadow_sets[num][1]\n",
    "        scaler = shadow_scalers[num]\n",
    "\n",
    "\n",
    "        X_test = test_set.drop('loan_status', axis=1)\n",
    "        Y_data_test = test_set['loan_status']\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "        results = model.predict_proba(X_test_scaled)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        max_confidence = np.max(results, axis=1)\n",
    "        entropy = -np.sum(results * np.log(results + 1e-8), axis=1)\n",
    "        predictions = model.predict(X_test_scaled)\n",
    "        true_class_proba = results[np.arange(len(Y_data_test)), Y_data_test]\n",
    "        correctness = (predictions == Y_data_test).astype(int)\n",
    "        loss = -np.log(true_class_proba + 1e-8)\n",
    "\n",
    "\n",
    "        vectors = calculate_model_metrics(model, X_test_scaled, Y_data_test, num)\n",
    "      \n",
    "\n",
    "\n",
    "        attack_features = np.column_stack([\n",
    "            max_confidence,\n",
    "            entropy,\n",
    "            true_class_proba,\n",
    "            loss\n",
    "        ])\n",
    "        #print(attack_features)\n",
    "        non_member_feature.append(attack_features)\n",
    "        non_member_label.append(np.zeros(len(attack_features)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    X_attack = np.vstack(member_feature + non_member_feature)\n",
    "    y_attack = np.hstack(member_label + non_member_label)\n",
    "    attack_scaler = StandardScaler()\n",
    "\n",
    "\n",
    "    X_attack_scale = attack_scaler.fit_transform(X_attack)\n",
    "\n",
    "\n",
    "    attack = LogisticRegression(max_iter=1000)\n",
    "    attack.fit(X_attack_scale, y_attack)\n",
    "    target_results = target.predict_proba(X_forget_scaled)\n",
    "\n",
    "    max_confidence = np.max(target_results, axis=1)\n",
    "    entropy = -np.sum(target_results * np.log(target_results + 1e-8), axis=1)\n",
    "    target_predictions = target.predict(X_forget_scaled)\n",
    "    true_class_proba = target_results[np.arange(len(Y_forget)), Y_forget]\n",
    "    correctness = (target_predictions == Y_forget).astype(int)\n",
    "    loss = -np.log(true_class_proba + 1e-8)\n",
    "\n",
    "\n",
    "    target_attack_features = np.column_stack([\n",
    "        max_confidence,\n",
    "        entropy,\n",
    "        true_class_proba,\n",
    "        loss\n",
    "    ])\n",
    "\n",
    "\n",
    "    target_attack_features_scaled = attack_scaler.transform(target_attack_features)\n",
    "    unlearn_results = unlearn.predict_proba(X_forget_scaled)\n",
    "\n",
    "\n",
    "    max_confidence = np.max(unlearn_results, axis=1)\n",
    "    entropy = -np.sum(unlearn_results * np.log(unlearn_results + 1e-8), axis=1)\n",
    "    unlearn_predictions = unlearn.predict(X_forget_scaled)\n",
    "    true_class_proba = unlearn_results[np.arange(len(Y_forget)), Y_forget]\n",
    "    correctness = (unlearn_predictions == Y_forget).astype(int)\n",
    "    loss = -np.log(true_class_proba + 1e-8)\n",
    "\n",
    "\n",
    "    unlearn_attack_features = np.column_stack([\n",
    "        max_confidence,\n",
    "        entropy,\n",
    "        true_class_proba,\n",
    "        loss\n",
    "    ])\n",
    "\n",
    "\n",
    "    unlearn_attack_features_scaled = attack_scaler.transform(unlearn_attack_features)\n",
    "    target_attack_predictions = attack.predict(target_attack_features_scaled)\n",
    "    target_attack_accuracy = accuracy_score(np.ones(len(target_attack_predictions)), target_attack_predictions)\n",
    "    unlearn_attack_predictions = attack.predict(unlearn_attack_features_scaled)\n",
    "    unlearn_attack_accuracy = accuracy_score(np.ones(len(unlearn_attack_predictions)), unlearn_attack_predictions) \n",
    "\n",
    "\n",
    "    retain_metrics_original = calculate_model_metrics(target, scaler.transform(X_test_scale), Y_test, 'original_retain')\n",
    "    retain_metrics_unlearned = calculate_model_metrics(unlearn, X_test_unlearn_scale, Y_test_unlearn, 'unlearned_retain')\n",
    "    forget_metrics_original = calculate_model_metrics(target, scaler.transform(X_forget), Y_forget, 'original_forget')\n",
    "    forget_metrics_unlearned = calculate_model_metrics(unlearn, X_forget_scaled, Y_forget, 'unlearned_forget')\n",
    "    \n",
    "\n",
    "    unlearn_attack_features_scaled = attack_scaler.transform(unlearn_attack_features)\n",
    "    target_attack_predictions = attack.predict(target_attack_features_scaled)\n",
    "    target_attack_accuracy = accuracy_score(np.ones(len(target_attack_predictions)), target_attack_predictions)\n",
    "    unlearn_attack_predictions = attack.predict(unlearn_attack_features_scaled)\n",
    "    unlearn_attack_accuracy = accuracy_score(np.ones(len(unlearn_attack_predictions)), unlearn_attack_predictions)\n",
    "    \n",
    "    \n",
    "    return {\n",
    "        'attack_model': attack,\n",
    "        'attack_scaler': attack_scaler,\n",
    "        'target_model': target,\n",
    "        'unlearned_model': unlearn,\n",
    "        'target_attack_features_scaled': target_attack_features_scaled,\n",
    "        'forget_set': forget,\n",
    "        'target_accuracy':target_attack_accuracy,\n",
    "        'unlearn_accuracy':unlearn_attack_accuracy,\n",
    "        'retain_metrics_original': retain_metrics_original,\n",
    "        'retain_metrics_unlearned': retain_metrics_unlearned,\n",
    "        'forget_metrics_original': forget_metrics_original,\n",
    "        'forget_metrics_unlearned': forget_metrics_unlearned\n",
    "    }'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def run_pipeline(config):\\n    # --- SETUP ---\\n    scaler_target = StandardScaler()\\n    train_data, test_data = train_test_split(loan_data, test_size=0.4, random_state=config['random_seed'],\\n        stratify=loan_data['loan_status']\\n    )\\n\\n    # --- Define forget set ---\\n    rate_thresh = train_data['loan_int_rate'].quantile(config['forget_percentile'])\\n    income_thresh = train_data['loan_percent_income'].quantile(config['forget_percentile'])\\n    amount_thresh = train_data['loan_amnt'].quantile(config['forget_percentile'])\\n\\n    forget = train_data[(train_data['loan_int_rate'] >= rate_thresh) |\\n                        (train_data['loan_percent_income'] >= income_thresh) |\\n                        (train_data['loan_amnt'] >= amount_thresh)]\\n\\n    keep = train_data.drop(forget.index)\\n\\n    X_forget = forget.drop(columns=['loan_status'])\\n    Y_forget = forget['loan_status']\\n\\n    # --- Train target model on full data ---\\n    X = train_data.drop(columns=['loan_status'])\\n    Y = train_data['loan_status']\\n    X_train, _, Y_train, _ = train_test_split(X, Y, train_size=900, stratify=Y, random_state=config['random_seed'])\\n\\n    X_train_scaled = scaler_target.fit_transform(X_train)\\n    target = LogisticRegression(C=10000, max_iter=10000)\\n    target.fit(X_train_scaled, Y_train)\\n\\n    # --- Train unlearned model (on keep set only) ---\\n    X_unlearn = keep.drop(columns=['loan_status'])\\n    Y_unlearn = keep['loan_status']\\n    X_unlearn_train, _, Y_unlearn_train, _ = train_test_split(X_unlearn, Y_unlearn, train_size=900, stratify=Y_unlearn, random_state=config['random_seed'])\\n\\n    unlearn_scaler = StandardScaler()\\n    X_unlearn_scaled = unlearn_scaler.fit_transform(X_unlearn_train)\\n    unlearn = LogisticRegression(C=10000, max_iter=10000)\\n    unlearn.fit(X_unlearn_scaled, Y_unlearn_train)\\n\\n    # --- Train shadow models ---\\n    shadow_sets = []\\n    shuffled = test_data.sample(frac=1, random_state=config['random_seed']).reset_index(drop=True)\\n    chunks = int(len(test_data) / config['num_shadow_models'])\\n    for i in range(config['num_shadow_models']):\\n        start, end = i * chunks, (i + 1) * chunks\\n        shadow_train, shadow_test = train_test_split(shuffled[start:end], test_size=0.5, random_state=config['random_seed'])\\n        shadow_sets.append((shadow_train, shadow_test))\\n\\n    shadow_models, shadow_scalers = [], []\\n    per_class_features, per_class_labels = {}, {}\\n\\n    for shadow_train, shadow_test in shadow_sets:\\n        scaler = StandardScaler()\\n        X_train = shadow_train.drop('loan_status', axis=1)\\n        y_train = shadow_train['loan_status']\\n        X_test = shadow_test.drop('loan_status', axis=1)\\n        y_test = shadow_test['loan_status']\\n\\n        X_train_scaled = scaler.fit_transform(X_train)\\n        X_test_scaled = scaler.transform(X_test)\\n\\n        model = LogisticRegression(C=10000, max_iter=10000)\\n        model.fit(X_train_scaled, y_train)\\n\\n        shadow_models.append(model)\\n        shadow_scalers.append(scaler)\\n\\n        # Member data\\n        train_probs = model.predict_proba(X_train_scaled)\\n        for i in range(len(train_probs)):\\n            label = y_train.iloc[i]\\n            prob = train_probs[i]\\n            per_class_features.setdefault(label, []).append(prob)\\n            per_class_labels.setdefault(label, []).append(1)\\n\\n        # Non-member data\\n        test_probs = model.predict_proba(X_test_scaled)\\n        for i in range(len(test_probs)):\\n            label = y_test.iloc[i]\\n            prob = test_probs[i]\\n            per_class_features.setdefault(label, []).append(prob)\\n            per_class_labels.setdefault(label, []).append(0)\\n\\n    # --- Train per-class attack models ---\\n    attack_models = {}\\n    attack_scalers = {}\\n    for cls in per_class_features:\\n        attack_scaler = StandardScaler()\\n        X_cls = np.array(per_class_features[cls])\\n        y_cls = np.array(per_class_labels[cls])\\n        X_train_cls, X_test_cls, y_train_cls, y_test_cls = train_test_split(X_cls, y_cls, test_size=0.3, stratify=y_cls, random_state=42)\\n\\n        \\n        X_train_scaled = attack_scaler.fit_transform(X_train_cls)\\n        attack_model = LogisticRegression(max_iter=1000)\\n        attack_model.fit(X_train_scaled, y_train_cls)\\n\\n        attack_models[cls] = attack_model\\n        attack_scalers[cls] = attack_scaler\\n\\n    # --- Evaluate Attack ---\\n    def evaluate_attack(model, scaler, X, y):\\n        probs = model.predict_proba(scaler.transform(X))\\n        results = []\\n        for i in range(len(X)):\\n            label = y.iloc[i]\\n            prob = probs[i]\\n            if label in attack_models:\\n                pred = attack_models[label].predict(attack_scalers[label].transform([prob]))[0]\\n                results.append(pred)\\n            else:\\n                results.append(0)\\n        return np.mean(results)\\n\\n    target_acc = evaluate_attack(target, scaler_target, X_forget, Y_forget)\\n    unlearn_acc = evaluate_attack(unlearn, unlearn_scaler, X_forget, Y_forget)\\n\\n    return {\\n        'forget_set': forget,\\n        'target_accuracy': target_acc,\\n        'unlearn_accuracy': unlearn_acc\\n    }\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#doesnt work\n",
    "'''def run_pipeline(config):\n",
    "    # --- SETUP ---\n",
    "    scaler_target = StandardScaler()\n",
    "    train_data, test_data = train_test_split(loan_data, test_size=0.4, random_state=config['random_seed'],\n",
    "        stratify=loan_data['loan_status']\n",
    "    )\n",
    "\n",
    "    # --- Define forget set ---\n",
    "    rate_thresh = train_data['loan_int_rate'].quantile(config['forget_percentile'])\n",
    "    income_thresh = train_data['loan_percent_income'].quantile(config['forget_percentile'])\n",
    "    amount_thresh = train_data['loan_amnt'].quantile(config['forget_percentile'])\n",
    "\n",
    "    forget = train_data[(train_data['loan_int_rate'] >= rate_thresh) |\n",
    "                        (train_data['loan_percent_income'] >= income_thresh) |\n",
    "                        (train_data['loan_amnt'] >= amount_thresh)]\n",
    "\n",
    "    keep = train_data.drop(forget.index)\n",
    "\n",
    "    X_forget = forget.drop(columns=['loan_status'])\n",
    "    Y_forget = forget['loan_status']\n",
    "\n",
    "    # --- Train target model on full data ---\n",
    "    X = train_data.drop(columns=['loan_status'])\n",
    "    Y = train_data['loan_status']\n",
    "    X_train, _, Y_train, _ = train_test_split(X, Y, train_size=900, stratify=Y, random_state=config['random_seed'])\n",
    "\n",
    "    X_train_scaled = scaler_target.fit_transform(X_train)\n",
    "    target = LogisticRegression(C=10000, max_iter=10000)\n",
    "    target.fit(X_train_scaled, Y_train)\n",
    "\n",
    "    # --- Train unlearned model (on keep set only) ---\n",
    "    X_unlearn = keep.drop(columns=['loan_status'])\n",
    "    Y_unlearn = keep['loan_status']\n",
    "    X_unlearn_train, _, Y_unlearn_train, _ = train_test_split(X_unlearn, Y_unlearn, train_size=900, stratify=Y_unlearn, random_state=config['random_seed'])\n",
    "\n",
    "    unlearn_scaler = StandardScaler()\n",
    "    X_unlearn_scaled = unlearn_scaler.fit_transform(X_unlearn_train)\n",
    "    unlearn = LogisticRegression(C=10000, max_iter=10000)\n",
    "    unlearn.fit(X_unlearn_scaled, Y_unlearn_train)\n",
    "\n",
    "    # --- Train shadow models ---\n",
    "    shadow_sets = []\n",
    "    shuffled = test_data.sample(frac=1, random_state=config['random_seed']).reset_index(drop=True)\n",
    "    chunks = int(len(test_data) / config['num_shadow_models'])\n",
    "    for i in range(config['num_shadow_models']):\n",
    "        start, end = i * chunks, (i + 1) * chunks\n",
    "        shadow_train, shadow_test = train_test_split(shuffled[start:end], test_size=0.5, random_state=config['random_seed'])\n",
    "        shadow_sets.append((shadow_train, shadow_test))\n",
    "\n",
    "    shadow_models, shadow_scalers = [], []\n",
    "    per_class_features, per_class_labels = {}, {}\n",
    "\n",
    "    for shadow_train, shadow_test in shadow_sets:\n",
    "        scaler = StandardScaler()\n",
    "        X_train = shadow_train.drop('loan_status', axis=1)\n",
    "        y_train = shadow_train['loan_status']\n",
    "        X_test = shadow_test.drop('loan_status', axis=1)\n",
    "        y_test = shadow_test['loan_status']\n",
    "\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        model = LogisticRegression(C=10000, max_iter=10000)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "\n",
    "        shadow_models.append(model)\n",
    "        shadow_scalers.append(scaler)\n",
    "\n",
    "        # Member data\n",
    "        train_probs = model.predict_proba(X_train_scaled)\n",
    "        for i in range(len(train_probs)):\n",
    "            label = y_train.iloc[i]\n",
    "            prob = train_probs[i]\n",
    "            per_class_features.setdefault(label, []).append(prob)\n",
    "            per_class_labels.setdefault(label, []).append(1)\n",
    "\n",
    "        # Non-member data\n",
    "        test_probs = model.predict_proba(X_test_scaled)\n",
    "        for i in range(len(test_probs)):\n",
    "            label = y_test.iloc[i]\n",
    "            prob = test_probs[i]\n",
    "            per_class_features.setdefault(label, []).append(prob)\n",
    "            per_class_labels.setdefault(label, []).append(0)\n",
    "\n",
    "    # --- Train per-class attack models ---\n",
    "    attack_models = {}\n",
    "    attack_scalers = {}\n",
    "    for cls in per_class_features:\n",
    "        attack_scaler = StandardScaler()\n",
    "        X_cls = np.array(per_class_features[cls])\n",
    "        y_cls = np.array(per_class_labels[cls])\n",
    "        X_train_cls, X_test_cls, y_train_cls, y_test_cls = train_test_split(X_cls, y_cls, test_size=0.3, stratify=y_cls, random_state=42)\n",
    "\n",
    "        \n",
    "        X_train_scaled = attack_scaler.fit_transform(X_train_cls)\n",
    "        attack_model = LogisticRegression(max_iter=1000)\n",
    "        attack_model.fit(X_train_scaled, y_train_cls)\n",
    "\n",
    "        attack_models[cls] = attack_model\n",
    "        attack_scalers[cls] = attack_scaler\n",
    "\n",
    "    # --- Evaluate Attack ---\n",
    "    def evaluate_attack(model, scaler, X, y):\n",
    "        probs = model.predict_proba(scaler.transform(X))\n",
    "        results = []\n",
    "        for i in range(len(X)):\n",
    "            label = y.iloc[i]\n",
    "            prob = probs[i]\n",
    "            if label in attack_models:\n",
    "                pred = attack_models[label].predict(attack_scalers[label].transform([prob]))[0]\n",
    "                results.append(pred)\n",
    "            else:\n",
    "                results.append(0)\n",
    "        return np.mean(results)\n",
    "\n",
    "    target_acc = evaluate_attack(target, scaler_target, X_forget, Y_forget)\n",
    "    unlearn_acc = evaluate_attack(unlearn, unlearn_scaler, X_forget, Y_forget)\n",
    "\n",
    "    return {\n",
    "        'forget_set': forget,\n",
    "        'target_accuracy': target_acc,\n",
    "        'unlearn_accuracy': unlearn_acc\n",
    "    }'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def run_pipeline(config):\\n    scaler = StandardScaler()\\n\\n    train_data, test_data = train_test_split(loan_data, test_size=0.4, random_state=config[\\'random_seed\\'], stratify=loan_data[\\'loan_status\\'])\\n\\n    rate_threshold = train_data[\\'loan_int_rate\\'].quantile(config[\\'forget_percentile\\'])\\n    percent_income_threshold = train_data[\\'loan_percent_income\\'].quantile(config[\\'forget_percentile\\'])\\n    loan_amnt_threshold = train_data[\\'loan_amnt\\'].quantile(config[\\'forget_percentile\\'])\\n\\n    forget = train_data[(train_data[\\'loan_int_rate\\'] >= rate_threshold) |\\n                (train_data[\\'loan_percent_income\\'] >= percent_income_threshold) |\\n                (train_data[\\'loan_amnt\\'] >= loan_amnt_threshold)]\\n\\n    X_forget = forget.drop(columns=[\\'loan_status\\'])\\n    Y_forget = forget[\\'loan_status\\']\\n\\n    target = LogisticRegression(C=10000, max_iter=10000)\\n\\n    X = train_data.drop(\\'loan_status\\', axis=1)\\n    Y = train_data[\\'loan_status\\']\\n\\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=config[\\'random_seed\\'])\\n\\n    X_train, X_test, Y_train, Y_test = train_test_split(\\n        X_train, Y_train,\\n        train_size=900,\\n        random_state=config[\\'random_seed\\'],\\n        stratify=Y_train\\n    )\\n    \\n    X_train_scale = scaler.fit_transform(X_train)\\n    X_test_scale = scaler.transform(X_test)\\n\\n    target.fit(X_train_scale, Y_train)\\n    \\n    unlearn_scaler = StandardScaler()\\n    keep = train_data.drop(forget.index)\\n\\n    unlearn = LogisticRegression(C=10000, max_iter=10000)\\n\\n    X_unlearn = keep.drop(\\'loan_status\\', axis=1)\\n    Y_unlearn = keep[\\'loan_status\\']\\n\\n    X_train_unlearn, X_test_unlearn, Y_train_unlearn, Y_test_unlearn = train_test_split(\\n        X_unlearn, Y_unlearn, test_size=.2, random_state=config[\\'random_seed\\'])\\n\\n    X_train_unlearn, X_test_unlearn, Y_train_unlearn, Y_test_unlearn = train_test_split(\\n        X_train_unlearn, Y_train_unlearn,\\n        train_size=900,\\n        random_state=config[\\'random_seed\\'],\\n        stratify=Y_train_unlearn\\n    )\\n\\n    X_train_unlearn_scale = unlearn_scaler.fit_transform(X_train_unlearn)\\n    X_test_unlearn_scale = unlearn_scaler.transform(X_test_unlearn)\\n\\n    unlearn.fit(X_train_unlearn_scale, Y_train_unlearn)\\n    X_forget_scaled = unlearn_scaler.transform(X_forget)\\n\\n    predictions = target.predict(X_forget_scaled)\\n    predictions_unlearn = unlearn.predict(X_forget_scaled)\\n\\n    # Shadow model setup\\n    num_shadow_models = config[\\'num_shadow_models\\']\\n    chunks = int(len(test_data)/num_shadow_models)\\n    shuffled_df = test_data.sample(frac=1, random_state=config[\\'random_seed\\']).reset_index(drop=True)\\n    shadow_sets = []\\n\\n    for num in range(num_shadow_models):\\n        start_index = int(chunks*num)\\n        end_index = int(start_index+chunks)\\n\\n        shadow_train, shadow_test = train_test_split(\\n            shuffled_df[start_index:end_index], test_size=.5, random_state=config[\\'random_seed\\'])\\n        shadow_sets.append((shadow_train, shadow_test))\\n\\n    shadow_models = []\\n    shadow_scaled_data = []\\n    shadow_scalers = []\\n    \\n    for num in range(num_shadow_models):\\n        shadow_scaler = StandardScaler()\\n        \\n        shadow_train = shadow_sets[num][0]\\n        X_shadow_train = shadow_train.drop(\\'loan_status\\', axis=1)\\n        Y_shadow_train = shadow_train[\\'loan_status\\']\\n\\n        X_shadow_train_scaled = shadow_scaler.fit_transform(X_shadow_train)\\n\\n        i = LogisticRegression(C=10000, max_iter=10000)\\n        i.fit(X_shadow_train_scaled, Y_shadow_train)\\n\\n        shadow_scalers.append(shadow_scaler)\\n        shadow_scaled_data.append((X_shadow_train_scaled, Y_shadow_train))\\n        shadow_models.append(i)\\n\\n    # NEW APPROACH: Use full posterior vectors and per-class attack models\\n    \\n    # Collect member and non-member data per class\\n    class_member_data = {0: [], 1: []}  # For binary classification\\n    class_member_labels = {0: [], 1: []}\\n    class_non_member_data = {0: [], 1: []}\\n    class_non_member_labels = {0: [], 1: []}\\n    \\n    # Collect member data (training data from shadow models)\\n    for num in range(num_shadow_models):\\n        model = shadow_models[num]\\n        scaled_data = shadow_scaled_data[num][0]\\n        Y_data = shadow_scaled_data[num][1]\\n\\n        results = model.predict_proba(scaled_data)\\n        # Use RAW posterior vector (not sorted) - like your working standalone code\\n        # sorted_probs = np.sort(results, axis=1)  # Remove this line\\n\\n        # Group by true class\\n        for class_label in [0, 1]:\\n            class_mask = (Y_data == class_label)\\n            if np.sum(class_mask) > 0:\\n                class_member_data[class_label].append(results[class_mask])  # Use raw results\\n                class_member_labels[class_label].append(np.ones(np.sum(class_mask)))\\n\\n    # Collect non-member data (test data from shadow models)\\n    for num in range(num_shadow_models):\\n        model = shadow_models[num]\\n        test_set = shadow_sets[num][1]\\n        scaler = shadow_scalers[num]\\n\\n        X_test = test_set.drop(\\'loan_status\\', axis=1)\\n        Y_data_test = test_set[\\'loan_status\\']\\n        X_test_scaled = scaler.transform(X_test)\\n\\n        results = model.predict_proba(X_test_scaled)\\n        # Use RAW posterior vector (not sorted) - like your working standalone code\\n        # sorted_probs = np.sort(results, axis=1)  # Remove this line\\n\\n        # Group by true class\\n        for class_label in [0, 1]:\\n            class_mask = (Y_data_test == class_label)\\n            if np.sum(class_mask) > 0:\\n                class_non_member_data[class_label].append(results[class_mask])  # Use raw results\\n                class_non_member_labels[class_label].append(np.zeros(np.sum(class_mask)))\\n\\n    # Train separate attack models per class\\n    attack_models = {}\\n    attack_scalers = {}\\n\\n    for class_label in [0, 1]:\\n        if class_member_data[class_label] and class_non_member_data[class_label]:\\n            # Combine member and non-member data for this class\\n            X_attack_class = np.vstack(class_member_data[class_label] + class_non_member_data[class_label])\\n            y_attack_class = np.hstack(class_member_labels[class_label] + class_non_member_labels[class_label])\\n\\n            # Train/test split for this class\\n            X_train_attack, X_test_attack, y_train_attack, y_test_attack = train_test_split(\\n                X_attack_class, y_attack_class, test_size=0.3, random_state=config[\\'random_seed\\'], \\n                stratify=y_attack_class\\n            )\\n\\n            # Scale and train attack model for this class\\n            attack_scaler_class = StandardScaler()\\n            X_train_attack_scaled = attack_scaler_class.fit_transform(X_train_attack)\\n            X_test_attack_scaled = attack_scaler_class.transform(X_test_attack)\\n\\n            attack_class = LogisticRegression(max_iter=1000)\\n            attack_class.fit(X_train_attack_scaled, y_train_attack)\\n\\n            print(f\"Class {class_label} attack accuracy: {attack_class.score(X_test_attack_scaled, y_test_attack):.3f}\")\\n\\n            attack_models[class_label] = attack_class\\n            attack_scalers[class_label] = attack_scaler_class\\n\\n    # Evaluate on target model using per-class attack models\\n    def evaluate_attack_corrected(model, X_scaled, Y_true, attack_models, attack_scalers):\\n        probs = model.predict_proba(X_scaled)\\n        results = []\\n        \\n        for i in range(len(X_scaled)):\\n            true_class = Y_true.iloc[i] if hasattr(Y_true, \\'iloc\\') else Y_true[i]\\n            prob = probs[i]  # Use raw probability vector, not sorted\\n            \\n            if true_class in attack_models:\\n                attack_model = attack_models[true_class]\\n                attack_scaler = attack_scalers[true_class]\\n                \\n                # Use the raw probability vector (like your working standalone code)\\n                scaled_input = attack_scaler.transform([prob])\\n                pred = attack_model.predict(scaled_input)[0]\\n                results.append(pred)\\n            else:\\n                results.append(0)  # Fallback if class wasn\\'t seen in shadow\\n        \\n        return np.mean(results)\\n\\n    target_attack_accuracy = evaluate_attack_corrected(target, X_forget_scaled, Y_forget, attack_models, attack_scalers)\\n    unlearn_attack_accuracy = evaluate_attack_corrected(unlearn, X_forget_scaled, Y_forget, attack_models, attack_scalers)\\n\\n    # Calculate metrics (you\\'ll need to implement calculate_model_metrics)\\n    retain_metrics_original = calculate_model_metrics(target, scaler.transform(X_test_scale), Y_test, \\'original_retain\\')\\n    retain_metrics_unlearned = calculate_model_metrics(unlearn, X_test_unlearn_scale, Y_test_unlearn, \\'unlearned_retain\\')\\n    forget_metrics_original = calculate_model_metrics(target, scaler.transform(X_forget), Y_forget, \\'original_forget\\')\\n    forget_metrics_unlearned = calculate_model_metrics(unlearn, X_forget_scaled, Y_forget, \\'unlearned_forget\\')\\n\\n    return {\\n        \\'attack_models\\': attack_models,  # Now a dict of per-class models\\n        \\'attack_scalers\\': attack_scalers,  # Now a dict of per-class scalers\\n        \\'target_model\\': target,\\n        \\'unlearned_model\\': unlearn,\\n        \\'forget_set\\': forget,\\n        \\'target_accuracy\\': target_attack_accuracy,\\n        \\'unlearn_accuracy\\': unlearn_attack_accuracy,\\n        \\'retain_metrics_original\\': retain_metrics_original,\\n        \\'retain_metrics_unlearned\\': retain_metrics_unlearned,\\n        \\'forget_metrics_original\\': forget_metrics_original,\\n        \\'forget_metrics_unlearned\\': forget_metrics_unlearned\\n    }'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#weird per class and raw vectors it is the good standalone one btw\n",
    "'''def run_pipeline(config):\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    train_data, test_data = train_test_split(loan_data, test_size=0.4, random_state=config['random_seed'], stratify=loan_data['loan_status'])\n",
    "\n",
    "    rate_threshold = train_data['loan_int_rate'].quantile(config['forget_percentile'])\n",
    "    percent_income_threshold = train_data['loan_percent_income'].quantile(config['forget_percentile'])\n",
    "    loan_amnt_threshold = train_data['loan_amnt'].quantile(config['forget_percentile'])\n",
    "\n",
    "    forget = train_data[(train_data['loan_int_rate'] >= rate_threshold) |\n",
    "                (train_data['loan_percent_income'] >= percent_income_threshold) |\n",
    "                (train_data['loan_amnt'] >= loan_amnt_threshold)]\n",
    "\n",
    "    X_forget = forget.drop(columns=['loan_status'])\n",
    "    Y_forget = forget['loan_status']\n",
    "\n",
    "    target = LogisticRegression(C=10000, max_iter=10000)\n",
    "\n",
    "    X = train_data.drop('loan_status', axis=1)\n",
    "    Y = train_data['loan_status']\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=config['random_seed'])\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X_train, Y_train,\n",
    "        train_size=900,\n",
    "        random_state=config['random_seed'],\n",
    "        stratify=Y_train\n",
    "    )\n",
    "    \n",
    "    X_train_scale = scaler.fit_transform(X_train)\n",
    "    X_test_scale = scaler.transform(X_test)\n",
    "\n",
    "    target.fit(X_train_scale, Y_train)\n",
    "    \n",
    "    unlearn_scaler = StandardScaler()\n",
    "    keep = train_data.drop(forget.index)\n",
    "\n",
    "    unlearn = LogisticRegression(C=10000, max_iter=10000)\n",
    "\n",
    "    X_unlearn = keep.drop('loan_status', axis=1)\n",
    "    Y_unlearn = keep['loan_status']\n",
    "\n",
    "    X_train_unlearn, X_test_unlearn, Y_train_unlearn, Y_test_unlearn = train_test_split(\n",
    "        X_unlearn, Y_unlearn, test_size=.2, random_state=config['random_seed'])\n",
    "\n",
    "    X_train_unlearn, X_test_unlearn, Y_train_unlearn, Y_test_unlearn = train_test_split(\n",
    "        X_train_unlearn, Y_train_unlearn,\n",
    "        train_size=900,\n",
    "        random_state=config['random_seed'],\n",
    "        stratify=Y_train_unlearn\n",
    "    )\n",
    "\n",
    "    X_train_unlearn_scale = unlearn_scaler.fit_transform(X_train_unlearn)\n",
    "    X_test_unlearn_scale = unlearn_scaler.transform(X_test_unlearn)\n",
    "\n",
    "    unlearn.fit(X_train_unlearn_scale, Y_train_unlearn)\n",
    "    X_forget_scaled = unlearn_scaler.transform(X_forget)\n",
    "\n",
    "    predictions = target.predict(X_forget_scaled)\n",
    "    predictions_unlearn = unlearn.predict(X_forget_scaled)\n",
    "\n",
    "    # Shadow model setup\n",
    "    num_shadow_models = config['num_shadow_models']\n",
    "    chunks = int(len(test_data)/num_shadow_models)\n",
    "    shuffled_df = test_data.sample(frac=1, random_state=config['random_seed']).reset_index(drop=True)\n",
    "    shadow_sets = []\n",
    "\n",
    "    for num in range(num_shadow_models):\n",
    "        start_index = int(chunks*num)\n",
    "        end_index = int(start_index+chunks)\n",
    "\n",
    "        shadow_train, shadow_test = train_test_split(\n",
    "            shuffled_df[start_index:end_index], test_size=.5, random_state=config['random_seed'])\n",
    "        shadow_sets.append((shadow_train, shadow_test))\n",
    "\n",
    "    shadow_models = []\n",
    "    shadow_scaled_data = []\n",
    "    shadow_scalers = []\n",
    "    \n",
    "    for num in range(num_shadow_models):\n",
    "        shadow_scaler = StandardScaler()\n",
    "        \n",
    "        shadow_train = shadow_sets[num][0]\n",
    "        X_shadow_train = shadow_train.drop('loan_status', axis=1)\n",
    "        Y_shadow_train = shadow_train['loan_status']\n",
    "\n",
    "        X_shadow_train_scaled = shadow_scaler.fit_transform(X_shadow_train)\n",
    "\n",
    "        i = LogisticRegression(C=10000, max_iter=10000)\n",
    "        i.fit(X_shadow_train_scaled, Y_shadow_train)\n",
    "\n",
    "        shadow_scalers.append(shadow_scaler)\n",
    "        shadow_scaled_data.append((X_shadow_train_scaled, Y_shadow_train))\n",
    "        shadow_models.append(i)\n",
    "\n",
    "    # NEW APPROACH: Use full posterior vectors and per-class attack models\n",
    "    \n",
    "    # Collect member and non-member data per class\n",
    "    class_member_data = {0: [], 1: []}  # For binary classification\n",
    "    class_member_labels = {0: [], 1: []}\n",
    "    class_non_member_data = {0: [], 1: []}\n",
    "    class_non_member_labels = {0: [], 1: []}\n",
    "    \n",
    "    # Collect member data (training data from shadow models)\n",
    "    for num in range(num_shadow_models):\n",
    "        model = shadow_models[num]\n",
    "        scaled_data = shadow_scaled_data[num][0]\n",
    "        Y_data = shadow_scaled_data[num][1]\n",
    "\n",
    "        results = model.predict_proba(scaled_data)\n",
    "        # Use RAW posterior vector (not sorted) - like your working standalone code\n",
    "        # sorted_probs = np.sort(results, axis=1)  # Remove this line\n",
    "\n",
    "        # Group by true class\n",
    "        for class_label in [0, 1]:\n",
    "            class_mask = (Y_data == class_label)\n",
    "            if np.sum(class_mask) > 0:\n",
    "                class_member_data[class_label].append(results[class_mask])  # Use raw results\n",
    "                class_member_labels[class_label].append(np.ones(np.sum(class_mask)))\n",
    "\n",
    "    # Collect non-member data (test data from shadow models)\n",
    "    for num in range(num_shadow_models):\n",
    "        model = shadow_models[num]\n",
    "        test_set = shadow_sets[num][1]\n",
    "        scaler = shadow_scalers[num]\n",
    "\n",
    "        X_test = test_set.drop('loan_status', axis=1)\n",
    "        Y_data_test = test_set['loan_status']\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        results = model.predict_proba(X_test_scaled)\n",
    "        # Use RAW posterior vector (not sorted) - like your working standalone code\n",
    "        # sorted_probs = np.sort(results, axis=1)  # Remove this line\n",
    "\n",
    "        # Group by true class\n",
    "        for class_label in [0, 1]:\n",
    "            class_mask = (Y_data_test == class_label)\n",
    "            if np.sum(class_mask) > 0:\n",
    "                class_non_member_data[class_label].append(results[class_mask])  # Use raw results\n",
    "                class_non_member_labels[class_label].append(np.zeros(np.sum(class_mask)))\n",
    "\n",
    "    # Train separate attack models per class\n",
    "    attack_models = {}\n",
    "    attack_scalers = {}\n",
    "\n",
    "    for class_label in [0, 1]:\n",
    "        if class_member_data[class_label] and class_non_member_data[class_label]:\n",
    "            # Combine member and non-member data for this class\n",
    "            X_attack_class = np.vstack(class_member_data[class_label] + class_non_member_data[class_label])\n",
    "            y_attack_class = np.hstack(class_member_labels[class_label] + class_non_member_labels[class_label])\n",
    "\n",
    "            # Train/test split for this class\n",
    "            X_train_attack, X_test_attack, y_train_attack, y_test_attack = train_test_split(\n",
    "                X_attack_class, y_attack_class, test_size=0.3, random_state=config['random_seed'], \n",
    "                stratify=y_attack_class\n",
    "            )\n",
    "\n",
    "            # Scale and train attack model for this class\n",
    "            attack_scaler_class = StandardScaler()\n",
    "            X_train_attack_scaled = attack_scaler_class.fit_transform(X_train_attack)\n",
    "            X_test_attack_scaled = attack_scaler_class.transform(X_test_attack)\n",
    "\n",
    "            attack_class = LogisticRegression(max_iter=1000)\n",
    "            attack_class.fit(X_train_attack_scaled, y_train_attack)\n",
    "\n",
    "            print(f\"Class {class_label} attack accuracy: {attack_class.score(X_test_attack_scaled, y_test_attack):.3f}\")\n",
    "\n",
    "            attack_models[class_label] = attack_class\n",
    "            attack_scalers[class_label] = attack_scaler_class\n",
    "\n",
    "    # Evaluate on target model using per-class attack models\n",
    "    def evaluate_attack_corrected(model, X_scaled, Y_true, attack_models, attack_scalers):\n",
    "        probs = model.predict_proba(X_scaled)\n",
    "        results = []\n",
    "        \n",
    "        for i in range(len(X_scaled)):\n",
    "            true_class = Y_true.iloc[i] if hasattr(Y_true, 'iloc') else Y_true[i]\n",
    "            prob = probs[i]  # Use raw probability vector, not sorted\n",
    "            \n",
    "            if true_class in attack_models:\n",
    "                attack_model = attack_models[true_class]\n",
    "                attack_scaler = attack_scalers[true_class]\n",
    "                \n",
    "                # Use the raw probability vector (like your working standalone code)\n",
    "                scaled_input = attack_scaler.transform([prob])\n",
    "                pred = attack_model.predict(scaled_input)[0]\n",
    "                results.append(pred)\n",
    "            else:\n",
    "                results.append(0)  # Fallback if class wasn't seen in shadow\n",
    "        \n",
    "        return np.mean(results)\n",
    "\n",
    "    target_attack_accuracy = evaluate_attack_corrected(target, X_forget_scaled, Y_forget, attack_models, attack_scalers)\n",
    "    unlearn_attack_accuracy = evaluate_attack_corrected(unlearn, X_forget_scaled, Y_forget, attack_models, attack_scalers)\n",
    "\n",
    "    # Calculate metrics (you'll need to implement calculate_model_metrics)\n",
    "    retain_metrics_original = calculate_model_metrics(target, scaler.transform(X_test_scale), Y_test, 'original_retain')\n",
    "    retain_metrics_unlearned = calculate_model_metrics(unlearn, X_test_unlearn_scale, Y_test_unlearn, 'unlearned_retain')\n",
    "    forget_metrics_original = calculate_model_metrics(target, scaler.transform(X_forget), Y_forget, 'original_forget')\n",
    "    forget_metrics_unlearned = calculate_model_metrics(unlearn, X_forget_scaled, Y_forget, 'unlearned_forget')\n",
    "\n",
    "    return {\n",
    "        'attack_models': attack_models,  # Now a dict of per-class models\n",
    "        'attack_scalers': attack_scalers,  # Now a dict of per-class scalers\n",
    "        'target_model': target,\n",
    "        'unlearned_model': unlearn,\n",
    "        'forget_set': forget,\n",
    "        'target_accuracy': target_attack_accuracy,\n",
    "        'unlearn_accuracy': unlearn_attack_accuracy,\n",
    "        'retain_metrics_original': retain_metrics_original,\n",
    "        'retain_metrics_unlearned': retain_metrics_unlearned,\n",
    "        'forget_metrics_original': forget_metrics_original,\n",
    "        'forget_metrics_unlearned': forget_metrics_unlearned\n",
    "    }'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def run_pipeline(config):\\n    scaler = StandardScaler()\\n\\n    train_data, test_data = train_test_split(loan_data, test_size=0.4, random_state=config['random_seed'], stratify=loan_data['loan_status'])\\n\\n    rate_threshold = train_data['loan_int_rate'].quantile(config['forget_percentile'])\\n    percent_income_threshold = train_data['loan_percent_income'].quantile(config['forget_percentile'])\\n    loan_amnt_threshold = train_data['loan_amnt'].quantile(config['forget_percentile'])\\n\\n    forget = train_data[(train_data['loan_int_rate'] >= rate_threshold) |\\n                (train_data['loan_percent_income'] >= percent_income_threshold) |\\n                (train_data['loan_amnt'] >= loan_amnt_threshold)]\\n\\n    X_forget = forget.drop(columns=['loan_status'])\\n    Y_forget = forget['loan_status']\\n\\n    target = LogisticRegression(C=10000, max_iter=10000)\\n\\n    X = train_data.drop('loan_status', axis=1)\\n    Y = train_data['loan_status']\\n\\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=config['random_seed'])\\n\\n    X_train, X_test, Y_train, Y_test = train_test_split(\\n        X_train, Y_train,\\n        train_size=900,\\n        random_state=config['random_seed'],\\n        stratify=Y_train\\n    )\\n    \\n    X_train_scale = scaler.fit_transform(X_train)\\n    X_test_scale = scaler.transform(X_test)\\n\\n    target.fit(X_train_scale, Y_train)\\n    \\n    unlearn_scaler = StandardScaler()\\n    keep = train_data.drop(forget.index)\\n\\n    unlearn = LogisticRegression(C=10000, max_iter=10000)\\n\\n    X_unlearn = keep.drop('loan_status', axis=1)\\n    Y_unlearn = keep['loan_status']\\n\\n    X_train_unlearn, X_test_unlearn, Y_train_unlearn, Y_test_unlearn = train_test_split(\\n        X_unlearn, Y_unlearn, test_size=.2, random_state=config['random_seed'])\\n\\n    X_train_unlearn, X_test_unlearn, Y_train_unlearn, Y_test_unlearn = train_test_split(\\n        X_train_unlearn, Y_train_unlearn,\\n        train_size=900,\\n        random_state=config['random_seed'],\\n        stratify=Y_train_unlearn\\n    )\\n\\n    X_train_unlearn_scale = unlearn_scaler.fit_transform(X_train_unlearn)\\n    X_test_unlearn_scale = unlearn_scaler.transform(X_test_unlearn)\\n\\n    unlearn.fit(X_train_unlearn_scale, Y_train_unlearn)\\n    X_forget_scaled = unlearn_scaler.transform(X_forget)\\n\\n    predictions = target.predict(X_forget_scaled)\\n    predictions_unlearn = unlearn.predict(X_forget_scaled)\\n\\n    # Shadow model setup\\n    num_shadow_models = config['num_shadow_models']\\n    chunks = int(len(test_data)/num_shadow_models)\\n    shuffled_df = test_data.sample(frac=1, random_state=config['random_seed']).reset_index(drop=True)\\n    shadow_sets = []\\n\\n    for num in range(num_shadow_models):\\n        start_index = int(chunks*num)\\n        end_index = int(start_index+chunks)\\n\\n        shadow_train, shadow_test = train_test_split(\\n            shuffled_df[start_index:end_index], test_size=.5, random_state=config['random_seed'])\\n        shadow_sets.append((shadow_train, shadow_test))\\n\\n    shadow_models = []\\n    shadow_scaled_data = []\\n    shadow_scalers = []\\n    \\n    for num in range(num_shadow_models):\\n        shadow_scaler = StandardScaler()\\n        \\n        shadow_train = shadow_sets[num][0]\\n        X_shadow_train = shadow_train.drop('loan_status', axis=1)\\n        Y_shadow_train = shadow_train['loan_status']\\n\\n        X_shadow_train_scaled = shadow_scaler.fit_transform(X_shadow_train)\\n\\n        i = LogisticRegression(C=10000, max_iter=10000)\\n        i.fit(X_shadow_train_scaled, Y_shadow_train)\\n\\n        shadow_scalers.append(shadow_scaler)\\n        shadow_scaled_data.append((X_shadow_train_scaled, Y_shadow_train))\\n        shadow_models.append(i)\\n\\n    # MODIFIED: Use raw probability vectors instead of engineered features\\n    member_feature = []\\n    member_label = []\\n\\n    for num in range(num_shadow_models):\\n        model = shadow_models[num]\\n        scaled_data = shadow_scaled_data[num][0]\\n        Y_data = shadow_scaled_data[num][1]\\n\\n        results = model.predict_proba(scaled_data)\\n        \\n        # CHANGE: Use raw probability vectors directly (no engineered features)\\n        attack_features = results  # Shape: (n_samples, n_classes)\\n        \\n        member_feature.append(attack_features)\\n        member_label.append(np.ones(len(attack_features)))\\n\\n    non_member_feature = []\\n    non_member_label = []\\n\\n    for num in range(num_shadow_models):\\n        model = shadow_models[num]\\n        test_set = shadow_sets[num][1]\\n        scaler = shadow_scalers[num]\\n\\n        X_test = test_set.drop('loan_status', axis=1)\\n        Y_data_test = test_set['loan_status']\\n        X_test_scaled = scaler.transform(X_test)\\n\\n        results = model.predict_proba(X_test_scaled)\\n        \\n        # CHANGE: Use raw probability vectors directly (no engineered features)\\n        attack_features = results  # Shape: (n_samples, n_classes)\\n        \\n        non_member_feature.append(attack_features)\\n        non_member_label.append(np.zeros(len(attack_features)))\\n\\n    X_attack = np.vstack(member_feature + non_member_feature)\\n    y_attack = np.hstack(member_label + non_member_label)\\n    attack_scaler = StandardScaler()\\n\\n    X_attack_scale = attack_scaler.fit_transform(X_attack)\\n\\n    attack = LogisticRegression(max_iter=1000)\\n    attack.fit(X_attack_scale, y_attack)\\n    \\n    # MODIFIED: Evaluate target model with raw probability vectors\\n    target_results = target.predict_proba(X_forget_scaled)\\n    \\n    # CHANGE: Use raw probability vectors directly\\n    target_attack_features = target_results  # Shape: (n_samples, n_classes)\\n    \\n    target_attack_features_scaled = attack_scaler.transform(target_attack_features)\\n    \\n    # MODIFIED: Evaluate unlearn model with raw probability vectors  \\n    unlearn_results = unlearn.predict_proba(X_forget_scaled)\\n    \\n    # CHANGE: Use raw probability vectors directly\\n    unlearn_attack_features = unlearn_results  # Shape: (n_samples, n_classes)\\n    \\n    unlearn_attack_features_scaled = attack_scaler.transform(unlearn_attack_features)\\n    \\n    target_attack_predictions = attack.predict(target_attack_features_scaled)\\n    target_attack_accuracy = accuracy_score(np.ones(len(target_attack_predictions)), target_attack_predictions)\\n    \\n    unlearn_attack_predictions = attack.predict(unlearn_attack_features_scaled)\\n    unlearn_attack_accuracy = accuracy_score(np.ones(len(unlearn_attack_predictions)), unlearn_attack_predictions)\\n\\n    retain_metrics_original = calculate_model_metrics(target, scaler.transform(X_test_scale), Y_test, 'original_retain')\\n    retain_metrics_unlearned = calculate_model_metrics(unlearn, X_test_unlearn_scale, Y_test_unlearn, 'unlearned_retain')\\n    forget_metrics_original = calculate_model_metrics(target, scaler.transform(X_forget), Y_forget, 'original_forget')\\n    forget_metrics_unlearned = calculate_model_metrics(unlearn, X_forget_scaled, Y_forget, 'unlearned_forget')\\n\\n    return {\\n        'attack_model': attack,\\n        'attack_scaler': attack_scaler,\\n        'target_model': target,\\n        'unlearned_model': unlearn,\\n        'target_attack_features_scaled': target_attack_features_scaled,\\n        'forget_set': forget,\\n        'target_accuracy': target_attack_accuracy,\\n        'unlearn_accuracy': unlearn_attack_accuracy,\\n        'retain_metrics_original': retain_metrics_original,\\n        'retain_metrics_unlearned': retain_metrics_unlearned,\\n        'forget_metrics_original': forget_metrics_original,\\n        'forget_metrics_unlearned': forget_metrics_unlearned\\n    }\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#only raw vectors\n",
    "'''def run_pipeline(config):\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    train_data, test_data = train_test_split(loan_data, test_size=0.4, random_state=config['random_seed'], stratify=loan_data['loan_status'])\n",
    "\n",
    "    rate_threshold = train_data['loan_int_rate'].quantile(config['forget_percentile'])\n",
    "    percent_income_threshold = train_data['loan_percent_income'].quantile(config['forget_percentile'])\n",
    "    loan_amnt_threshold = train_data['loan_amnt'].quantile(config['forget_percentile'])\n",
    "\n",
    "    forget = train_data[(train_data['loan_int_rate'] >= rate_threshold) |\n",
    "                (train_data['loan_percent_income'] >= percent_income_threshold) |\n",
    "                (train_data['loan_amnt'] >= loan_amnt_threshold)]\n",
    "\n",
    "    X_forget = forget.drop(columns=['loan_status'])\n",
    "    Y_forget = forget['loan_status']\n",
    "\n",
    "    target = LogisticRegression(C=10000, max_iter=10000)\n",
    "\n",
    "    X = train_data.drop('loan_status', axis=1)\n",
    "    Y = train_data['loan_status']\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=config['random_seed'])\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X_train, Y_train,\n",
    "        train_size=900,\n",
    "        random_state=config['random_seed'],\n",
    "        stratify=Y_train\n",
    "    )\n",
    "    \n",
    "    X_train_scale = scaler.fit_transform(X_train)\n",
    "    X_test_scale = scaler.transform(X_test)\n",
    "\n",
    "    target.fit(X_train_scale, Y_train)\n",
    "    \n",
    "    unlearn_scaler = StandardScaler()\n",
    "    keep = train_data.drop(forget.index)\n",
    "\n",
    "    unlearn = LogisticRegression(C=10000, max_iter=10000)\n",
    "\n",
    "    X_unlearn = keep.drop('loan_status', axis=1)\n",
    "    Y_unlearn = keep['loan_status']\n",
    "\n",
    "    X_train_unlearn, X_test_unlearn, Y_train_unlearn, Y_test_unlearn = train_test_split(\n",
    "        X_unlearn, Y_unlearn, test_size=.2, random_state=config['random_seed'])\n",
    "\n",
    "    X_train_unlearn, X_test_unlearn, Y_train_unlearn, Y_test_unlearn = train_test_split(\n",
    "        X_train_unlearn, Y_train_unlearn,\n",
    "        train_size=900,\n",
    "        random_state=config['random_seed'],\n",
    "        stratify=Y_train_unlearn\n",
    "    )\n",
    "\n",
    "    X_train_unlearn_scale = unlearn_scaler.fit_transform(X_train_unlearn)\n",
    "    X_test_unlearn_scale = unlearn_scaler.transform(X_test_unlearn)\n",
    "\n",
    "    unlearn.fit(X_train_unlearn_scale, Y_train_unlearn)\n",
    "    X_forget_scaled = unlearn_scaler.transform(X_forget)\n",
    "\n",
    "    predictions = target.predict(X_forget_scaled)\n",
    "    predictions_unlearn = unlearn.predict(X_forget_scaled)\n",
    "\n",
    "    # Shadow model setup\n",
    "    num_shadow_models = config['num_shadow_models']\n",
    "    chunks = int(len(test_data)/num_shadow_models)\n",
    "    shuffled_df = test_data.sample(frac=1, random_state=config['random_seed']).reset_index(drop=True)\n",
    "    shadow_sets = []\n",
    "\n",
    "    for num in range(num_shadow_models):\n",
    "        start_index = int(chunks*num)\n",
    "        end_index = int(start_index+chunks)\n",
    "\n",
    "        shadow_train, shadow_test = train_test_split(\n",
    "            shuffled_df[start_index:end_index], test_size=.5, random_state=config['random_seed'])\n",
    "        shadow_sets.append((shadow_train, shadow_test))\n",
    "\n",
    "    shadow_models = []\n",
    "    shadow_scaled_data = []\n",
    "    shadow_scalers = []\n",
    "    \n",
    "    for num in range(num_shadow_models):\n",
    "        shadow_scaler = StandardScaler()\n",
    "        \n",
    "        shadow_train = shadow_sets[num][0]\n",
    "        X_shadow_train = shadow_train.drop('loan_status', axis=1)\n",
    "        Y_shadow_train = shadow_train['loan_status']\n",
    "\n",
    "        X_shadow_train_scaled = shadow_scaler.fit_transform(X_shadow_train)\n",
    "\n",
    "        i = LogisticRegression(C=10000, max_iter=10000)\n",
    "        i.fit(X_shadow_train_scaled, Y_shadow_train)\n",
    "\n",
    "        shadow_scalers.append(shadow_scaler)\n",
    "        shadow_scaled_data.append((X_shadow_train_scaled, Y_shadow_train))\n",
    "        shadow_models.append(i)\n",
    "\n",
    "    # MODIFIED: Use raw probability vectors instead of engineered features\n",
    "    member_feature = []\n",
    "    member_label = []\n",
    "\n",
    "    for num in range(num_shadow_models):\n",
    "        model = shadow_models[num]\n",
    "        scaled_data = shadow_scaled_data[num][0]\n",
    "        Y_data = shadow_scaled_data[num][1]\n",
    "\n",
    "        results = model.predict_proba(scaled_data)\n",
    "        \n",
    "        # CHANGE: Use raw probability vectors directly (no engineered features)\n",
    "        attack_features = results  # Shape: (n_samples, n_classes)\n",
    "        \n",
    "        member_feature.append(attack_features)\n",
    "        member_label.append(np.ones(len(attack_features)))\n",
    "\n",
    "    non_member_feature = []\n",
    "    non_member_label = []\n",
    "\n",
    "    for num in range(num_shadow_models):\n",
    "        model = shadow_models[num]\n",
    "        test_set = shadow_sets[num][1]\n",
    "        scaler = shadow_scalers[num]\n",
    "\n",
    "        X_test = test_set.drop('loan_status', axis=1)\n",
    "        Y_data_test = test_set['loan_status']\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        results = model.predict_proba(X_test_scaled)\n",
    "        \n",
    "        # CHANGE: Use raw probability vectors directly (no engineered features)\n",
    "        attack_features = results  # Shape: (n_samples, n_classes)\n",
    "        \n",
    "        non_member_feature.append(attack_features)\n",
    "        non_member_label.append(np.zeros(len(attack_features)))\n",
    "\n",
    "    X_attack = np.vstack(member_feature + non_member_feature)\n",
    "    y_attack = np.hstack(member_label + non_member_label)\n",
    "    attack_scaler = StandardScaler()\n",
    "\n",
    "    X_attack_scale = attack_scaler.fit_transform(X_attack)\n",
    "\n",
    "    attack = LogisticRegression(max_iter=1000)\n",
    "    attack.fit(X_attack_scale, y_attack)\n",
    "    \n",
    "    # MODIFIED: Evaluate target model with raw probability vectors\n",
    "    target_results = target.predict_proba(X_forget_scaled)\n",
    "    \n",
    "    # CHANGE: Use raw probability vectors directly\n",
    "    target_attack_features = target_results  # Shape: (n_samples, n_classes)\n",
    "    \n",
    "    target_attack_features_scaled = attack_scaler.transform(target_attack_features)\n",
    "    \n",
    "    # MODIFIED: Evaluate unlearn model with raw probability vectors  \n",
    "    unlearn_results = unlearn.predict_proba(X_forget_scaled)\n",
    "    \n",
    "    # CHANGE: Use raw probability vectors directly\n",
    "    unlearn_attack_features = unlearn_results  # Shape: (n_samples, n_classes)\n",
    "    \n",
    "    unlearn_attack_features_scaled = attack_scaler.transform(unlearn_attack_features)\n",
    "    \n",
    "    target_attack_predictions = attack.predict(target_attack_features_scaled)\n",
    "    target_attack_accuracy = accuracy_score(np.ones(len(target_attack_predictions)), target_attack_predictions)\n",
    "    \n",
    "    unlearn_attack_predictions = attack.predict(unlearn_attack_features_scaled)\n",
    "    unlearn_attack_accuracy = accuracy_score(np.ones(len(unlearn_attack_predictions)), unlearn_attack_predictions)\n",
    "\n",
    "    retain_metrics_original = calculate_model_metrics(target, scaler.transform(X_test_scale), Y_test, 'original_retain')\n",
    "    retain_metrics_unlearned = calculate_model_metrics(unlearn, X_test_unlearn_scale, Y_test_unlearn, 'unlearned_retain')\n",
    "    forget_metrics_original = calculate_model_metrics(target, scaler.transform(X_forget), Y_forget, 'original_forget')\n",
    "    forget_metrics_unlearned = calculate_model_metrics(unlearn, X_forget_scaled, Y_forget, 'unlearned_forget')\n",
    "\n",
    "    return {\n",
    "        'attack_model': attack,\n",
    "        'attack_scaler': attack_scaler,\n",
    "        'target_model': target,\n",
    "        'unlearned_model': unlearn,\n",
    "        'target_attack_features_scaled': target_attack_features_scaled,\n",
    "        'forget_set': forget,\n",
    "        'target_accuracy': target_attack_accuracy,\n",
    "        'unlearn_accuracy': unlearn_attack_accuracy,\n",
    "        'retain_metrics_original': retain_metrics_original,\n",
    "        'retain_metrics_unlearned': retain_metrics_unlearned,\n",
    "        'forget_metrics_original': forget_metrics_original,\n",
    "        'forget_metrics_unlearned': forget_metrics_unlearned\n",
    "    }'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def run_pipeline(config):\\n    scaler = StandardScaler()\\n\\n    train_data, test_data = train_test_split(loan_data, test_size=0.4, random_state=config[\\'random_seed\\'], stratify=loan_data[\\'loan_status\\'])\\n\\n    # CREATE MULTI-CLASS TARGET: Convert loan_status + loan_grade into multi-class\\n    # Assume you have loan_grade column with values like \\'A\\', \\'B\\', \\'C\\', \\'D\\', etc.\\n    \\n    # Option 1: Combine loan_status with another categorical feature\\n    if \\'loan_grade\\' in train_data.columns:\\n        # Create 4-6 classes by combining loan_status (0,1) with loan_grade (A,B,C)\\n        train_data[\\'multi_class\\'] = train_data[\\'loan_status\\'].astype(str) + \\'_\\' + train_data[\\'loan_grade\\'].astype(str)\\n        test_data[\\'multi_class\\'] = test_data[\\'loan_status\\'].astype(str) + \\'_\\' + test_data[\\'loan_grade\\'].astype(str)\\n    else:\\n        # Option 2: Create classes based on loan_int_rate quartiles\\n        train_data[\\'rate_quartile\\'] = pd.qcut(train_data[\\'loan_int_rate\\'], q=4, labels=[\\'Low\\', \\'Med\\', \\'High\\', \\'VHigh\\'])\\n        test_data[\\'rate_quartile\\'] = pd.qcut(test_data[\\'loan_int_rate\\'], q=4, labels=[\\'Low\\', \\'Med\\', \\'High\\', \\'VHigh\\'])\\n        \\n        # Combine loan_status with rate quartiles for 8 classes\\n        train_data[\\'multi_class\\'] = train_data[\\'loan_status\\'].astype(str) + \\'_\\' + train_data[\\'rate_quartile\\'].astype(str)\\n        test_data[\\'multi_class\\'] = test_data[\\'loan_status\\'].astype(str) + \\'_\\' + test_data[\\'rate_quartile\\'].astype(str)\\n    \\n    # Encode to numeric\\n    from sklearn.preprocessing import LabelEncoder\\n    le = LabelEncoder()\\n    all_classes = pd.concat([train_data[\\'multi_class\\'], test_data[\\'multi_class\\']])\\n    le.fit(all_classes)\\n    \\n    train_data[\\'target\\'] = le.transform(train_data[\\'multi_class\\'])\\n    test_data[\\'target\\'] = le.transform(test_data[\\'multi_class\\'])\\n    \\n    print(f\"Created {len(le.classes_)} classes: {le.classes_}\")\\n    \\n    # Define forget set based on original criteria but use new target\\n    rate_threshold = train_data[\\'loan_int_rate\\'].quantile(config[\\'forget_percentile\\'])\\n    percent_income_threshold = train_data[\\'loan_percent_income\\'].quantile(config[\\'forget_percentile\\'])\\n    loan_amnt_threshold = train_data[\\'loan_amnt\\'].quantile(config[\\'forget_percentile\\'])\\n\\n    forget = train_data[(train_data[\\'loan_int_rate\\'] >= rate_threshold) |\\n                (train_data[\\'loan_percent_income\\'] >= percent_income_threshold) |\\n                (train_data[\\'loan_amnt\\'] >= loan_amnt_threshold)]\\n\\n    X_forget = forget.drop(columns=[\\'loan_status\\', \\'multi_class\\', \\'target\\'])\\n    if \\'rate_quartile\\' in X_forget.columns:\\n        X_forget = X_forget.drop(columns=[\\'rate_quartile\\'])\\n    Y_forget = forget[\\'target\\']\\n\\n    target = LogisticRegression(C=10000, max_iter=10000)\\n\\n    X = train_data.drop([\\'loan_status\\', \\'multi_class\\', \\'target\\'], axis=1)\\n    if \\'rate_quartile\\' in X.columns:\\n        X = X.drop([\\'rate_quartile\\'], axis=1)\\n    Y = train_data[\\'target\\']  # Use multi-class target\\n\\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=config[\\'random_seed\\'])\\n\\n    X_train, X_test, Y_train, Y_test = train_test_split(\\n        X_train, Y_train,\\n        train_size=900,\\n        random_state=config[\\'random_seed\\'],\\n        stratify=Y_train\\n    )\\n    \\n    X_train_scale = scaler.fit_transform(X_train)\\n    X_test_scale = scaler.transform(X_test)\\n\\n    target.fit(X_train_scale, Y_train)\\n    \\n    unlearn_scaler = StandardScaler()\\n    keep = train_data.drop(forget.index)\\n\\n    unlearn = LogisticRegression(C=10000, max_iter=10000)\\n\\n    X_unlearn = keep.drop([\\'loan_status\\', \\'multi_class\\', \\'target\\'], axis=1)\\n    if \\'rate_quartile\\' in X_unlearn.columns:\\n        X_unlearn = X_unlearn.drop([\\'rate_quartile\\'], axis=1)\\n    Y_unlearn = keep[\\'target\\']  # Use multi-class target\\n\\n    X_train_unlearn, X_test_unlearn, Y_train_unlearn, Y_test_unlearn = train_test_split(\\n        X_unlearn, Y_unlearn, test_size=.2, random_state=config[\\'random_seed\\'])\\n\\n    X_train_unlearn, X_test_unlearn, Y_train_unlearn, Y_test_unlearn = train_test_split(\\n        X_train_unlearn, Y_train_unlearn,\\n        train_size=900,\\n        random_state=config[\\'random_seed\\'],\\n        stratify=Y_train_unlearn\\n    )\\n\\n    X_train_unlearn_scale = unlearn_scaler.fit_transform(X_train_unlearn)\\n    X_test_unlearn_scale = unlearn_scaler.transform(X_test_unlearn)\\n\\n    unlearn.fit(X_train_unlearn_scale, Y_train_unlearn)\\n    X_forget_scaled = unlearn_scaler.transform(X_forget)\\n\\n    predictions = target.predict(X_forget_scaled)\\n    predictions_unlearn = unlearn.predict(X_forget_scaled)\\n\\n    # Shadow model setup\\n    num_shadow_models = config[\\'num_shadow_models\\']\\n    chunks = int(len(test_data)/num_shadow_models)\\n    shuffled_df = test_data.sample(frac=1, random_state=config[\\'random_seed\\']).reset_index(drop=True)\\n    shadow_sets = []\\n\\n    for num in range(num_shadow_models):\\n        start_index = int(chunks*num)\\n        end_index = int(start_index+chunks)\\n\\n        shadow_train, shadow_test = train_test_split(\\n            shuffled_df[start_index:end_index], test_size=.5, random_state=config[\\'random_seed\\'])\\n        shadow_sets.append((shadow_train, shadow_test))\\n\\n    shadow_models = []\\n    shadow_scaled_data = []\\n    shadow_scalers = []\\n    \\n    for num in range(num_shadow_models):\\n        shadow_scaler = StandardScaler()\\n        \\n        shadow_train = shadow_sets[num][0]\\n        X_shadow_train = shadow_train.drop([\\'loan_status\\', \\'multi_class\\', \\'target\\'], axis=1)\\n        if \\'rate_quartile\\' in X_shadow_train.columns:\\n            X_shadow_train = X_shadow_train.drop([\\'rate_quartile\\'], axis=1)\\n        Y_shadow_train = shadow_train[\\'target\\']  # Use multi-class target\\n\\n        X_shadow_train_scaled = shadow_scaler.fit_transform(X_shadow_train)\\n\\n        i = LogisticRegression(C=10000, max_iter=10000)\\n        i.fit(X_shadow_train_scaled, Y_shadow_train)\\n\\n        shadow_scalers.append(shadow_scaler)\\n        shadow_scaled_data.append((X_shadow_train_scaled, Y_shadow_train))\\n        shadow_models.append(i)\\n\\n    # MODIFIED: Use raw probability vectors instead of engineered features\\n    member_feature = []\\n    member_label = []\\n\\n    for num in range(num_shadow_models):\\n        model = shadow_models[num]\\n        scaled_data = shadow_scaled_data[num][0]\\n        Y_data = shadow_scaled_data[num][1]\\n\\n        results = model.predict_proba(scaled_data)\\n        \\n        # CHANGE: Use raw probability vectors directly (no engineered features)\\n        attack_features = results  # Shape: (n_samples, n_classes)\\n        \\n        member_feature.append(attack_features)\\n        member_label.append(np.ones(len(attack_features)))\\n\\n    non_member_feature = []\\n    non_member_label = []\\n\\n    for num in range(num_shadow_models):\\n        model = shadow_models[num]\\n        test_set = shadow_sets[num][1]\\n        scaler = shadow_scalers[num]\\n\\n        X_test = test_set.drop([\\'loan_status\\', \\'multi_class\\', \\'target\\'], axis=1)\\n        if \\'rate_quartile\\' in X_test.columns:\\n            X_test = X_test.drop([\\'rate_quartile\\'], axis=1)\\n        Y_data_test = test_set[\\'target\\']  # Use multi-class target\\n        X_test_scaled = scaler.transform(X_test)\\n\\n        results = model.predict_proba(X_test_scaled)\\n        \\n        # CHANGE: Use raw probability vectors directly (no engineered features)\\n        attack_features = results  # Shape: (n_samples, n_classes)\\n        \\n        non_member_feature.append(attack_features)\\n        non_member_label.append(np.zeros(len(attack_features)))\\n\\n    X_attack = np.vstack(member_feature + non_member_feature)\\n    y_attack = np.hstack(member_label + non_member_label)\\n    attack_scaler = StandardScaler()\\n\\n    X_attack_scale = attack_scaler.fit_transform(X_attack)\\n\\n    attack = LogisticRegression(max_iter=1000)\\n    attack.fit(X_attack_scale, y_attack)\\n    \\n    # MODIFIED: Evaluate target model with raw probability vectors\\n    target_results = target.predict_proba(X_forget_scaled)\\n    \\n    # CHANGE: Use raw probability vectors directly\\n    target_attack_features = target_results  # Shape: (n_samples, n_classes)\\n    \\n    target_attack_features_scaled = attack_scaler.transform(target_attack_features)\\n    \\n    # MODIFIED: Evaluate unlearn model with raw probability vectors  \\n    unlearn_results = unlearn.predict_proba(X_forget_scaled)\\n    \\n    # CHANGE: Use raw probability vectors directly\\n    unlearn_attack_features = unlearn_results  # Shape: (n_samples, n_classes)\\n    \\n    unlearn_attack_features_scaled = attack_scaler.transform(unlearn_attack_features)\\n    \\n    target_attack_predictions = attack.predict(target_attack_features_scaled)\\n    target_attack_accuracy = accuracy_score(np.ones(len(target_attack_predictions)), target_attack_predictions)\\n    \\n    unlearn_attack_predictions = attack.predict(unlearn_attack_features_scaled)\\n    unlearn_attack_accuracy = accuracy_score(np.ones(len(unlearn_attack_predictions)), unlearn_attack_predictions)\\n\\n    retain_metrics_original = calculate_model_metrics(target, scaler.transform(X_test_scale), Y_test, \\'original_retain\\')\\n    retain_metrics_unlearned = calculate_model_metrics(unlearn, X_test_unlearn_scale, Y_test_unlearn, \\'unlearned_retain\\')\\n    forget_metrics_original = calculate_model_metrics(target, scaler.transform(X_forget), Y_forget, \\'original_forget\\')\\n    forget_metrics_unlearned = calculate_model_metrics(unlearn, X_forget_scaled, Y_forget, \\'unlearned_forget\\')\\n\\n    # Add LabelEncoder to return for reference\\n    return {\\n        \\'attack_model\\': attack,\\n        \\'attack_scaler\\': attack_scaler,\\n        \\'target_model\\': target,\\n        \\'unlearned_model\\': unlearn,\\n        \\'target_attack_features_scaled\\': target_attack_features_scaled,\\n        \\'forget_set\\': forget,\\n        \\'target_accuracy\\': target_attack_accuracy,\\n        \\'unlearn_accuracy\\': unlearn_attack_accuracy,\\n        \\'retain_metrics_original\\': retain_metrics_original,\\n        \\'retain_metrics_unlearned\\': retain_metrics_unlearned,\\n        \\'forget_metrics_original\\': forget_metrics_original,\\n        \\'forget_metrics_unlearned\\': forget_metrics_unlearned,\\n        \\'label_encoder\\': le,\\n        \\'num_classes\\': len(le.classes_)\\n    }'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#raw vector bt multi class\n",
    "'''def run_pipeline(config):\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    train_data, test_data = train_test_split(loan_data, test_size=0.4, random_state=config['random_seed'], stratify=loan_data['loan_status'])\n",
    "\n",
    "    # CREATE MULTI-CLASS TARGET: Convert loan_status + loan_grade into multi-class\n",
    "    # Assume you have loan_grade column with values like 'A', 'B', 'C', 'D', etc.\n",
    "    \n",
    "    # Option 1: Combine loan_status with another categorical feature\n",
    "    if 'loan_grade' in train_data.columns:\n",
    "        # Create 4-6 classes by combining loan_status (0,1) with loan_grade (A,B,C)\n",
    "        train_data['multi_class'] = train_data['loan_status'].astype(str) + '_' + train_data['loan_grade'].astype(str)\n",
    "        test_data['multi_class'] = test_data['loan_status'].astype(str) + '_' + test_data['loan_grade'].astype(str)\n",
    "    else:\n",
    "        # Option 2: Create classes based on loan_int_rate quartiles\n",
    "        train_data['rate_quartile'] = pd.qcut(train_data['loan_int_rate'], q=4, labels=['Low', 'Med', 'High', 'VHigh'])\n",
    "        test_data['rate_quartile'] = pd.qcut(test_data['loan_int_rate'], q=4, labels=['Low', 'Med', 'High', 'VHigh'])\n",
    "        \n",
    "        # Combine loan_status with rate quartiles for 8 classes\n",
    "        train_data['multi_class'] = train_data['loan_status'].astype(str) + '_' + train_data['rate_quartile'].astype(str)\n",
    "        test_data['multi_class'] = test_data['loan_status'].astype(str) + '_' + test_data['rate_quartile'].astype(str)\n",
    "    \n",
    "    # Encode to numeric\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    all_classes = pd.concat([train_data['multi_class'], test_data['multi_class']])\n",
    "    le.fit(all_classes)\n",
    "    \n",
    "    train_data['target'] = le.transform(train_data['multi_class'])\n",
    "    test_data['target'] = le.transform(test_data['multi_class'])\n",
    "    \n",
    "    print(f\"Created {len(le.classes_)} classes: {le.classes_}\")\n",
    "    \n",
    "    # Define forget set based on original criteria but use new target\n",
    "    rate_threshold = train_data['loan_int_rate'].quantile(config['forget_percentile'])\n",
    "    percent_income_threshold = train_data['loan_percent_income'].quantile(config['forget_percentile'])\n",
    "    loan_amnt_threshold = train_data['loan_amnt'].quantile(config['forget_percentile'])\n",
    "\n",
    "    forget = train_data[(train_data['loan_int_rate'] >= rate_threshold) |\n",
    "                (train_data['loan_percent_income'] >= percent_income_threshold) |\n",
    "                (train_data['loan_amnt'] >= loan_amnt_threshold)]\n",
    "\n",
    "    X_forget = forget.drop(columns=['loan_status', 'multi_class', 'target'])\n",
    "    if 'rate_quartile' in X_forget.columns:\n",
    "        X_forget = X_forget.drop(columns=['rate_quartile'])\n",
    "    Y_forget = forget['target']\n",
    "\n",
    "    target = LogisticRegression(C=10000, max_iter=10000)\n",
    "\n",
    "    X = train_data.drop(['loan_status', 'multi_class', 'target'], axis=1)\n",
    "    if 'rate_quartile' in X.columns:\n",
    "        X = X.drop(['rate_quartile'], axis=1)\n",
    "    Y = train_data['target']  # Use multi-class target\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=config['random_seed'])\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X_train, Y_train,\n",
    "        train_size=900,\n",
    "        random_state=config['random_seed'],\n",
    "        stratify=Y_train\n",
    "    )\n",
    "    \n",
    "    X_train_scale = scaler.fit_transform(X_train)\n",
    "    X_test_scale = scaler.transform(X_test)\n",
    "\n",
    "    target.fit(X_train_scale, Y_train)\n",
    "    \n",
    "    unlearn_scaler = StandardScaler()\n",
    "    keep = train_data.drop(forget.index)\n",
    "\n",
    "    unlearn = LogisticRegression(C=10000, max_iter=10000)\n",
    "\n",
    "    X_unlearn = keep.drop(['loan_status', 'multi_class', 'target'], axis=1)\n",
    "    if 'rate_quartile' in X_unlearn.columns:\n",
    "        X_unlearn = X_unlearn.drop(['rate_quartile'], axis=1)\n",
    "    Y_unlearn = keep['target']  # Use multi-class target\n",
    "\n",
    "    X_train_unlearn, X_test_unlearn, Y_train_unlearn, Y_test_unlearn = train_test_split(\n",
    "        X_unlearn, Y_unlearn, test_size=.2, random_state=config['random_seed'])\n",
    "\n",
    "    X_train_unlearn, X_test_unlearn, Y_train_unlearn, Y_test_unlearn = train_test_split(\n",
    "        X_train_unlearn, Y_train_unlearn,\n",
    "        train_size=900,\n",
    "        random_state=config['random_seed'],\n",
    "        stratify=Y_train_unlearn\n",
    "    )\n",
    "\n",
    "    X_train_unlearn_scale = unlearn_scaler.fit_transform(X_train_unlearn)\n",
    "    X_test_unlearn_scale = unlearn_scaler.transform(X_test_unlearn)\n",
    "\n",
    "    unlearn.fit(X_train_unlearn_scale, Y_train_unlearn)\n",
    "    X_forget_scaled = unlearn_scaler.transform(X_forget)\n",
    "\n",
    "    predictions = target.predict(X_forget_scaled)\n",
    "    predictions_unlearn = unlearn.predict(X_forget_scaled)\n",
    "\n",
    "    # Shadow model setup\n",
    "    num_shadow_models = config['num_shadow_models']\n",
    "    chunks = int(len(test_data)/num_shadow_models)\n",
    "    shuffled_df = test_data.sample(frac=1, random_state=config['random_seed']).reset_index(drop=True)\n",
    "    shadow_sets = []\n",
    "\n",
    "    for num in range(num_shadow_models):\n",
    "        start_index = int(chunks*num)\n",
    "        end_index = int(start_index+chunks)\n",
    "\n",
    "        shadow_train, shadow_test = train_test_split(\n",
    "            shuffled_df[start_index:end_index], test_size=.5, random_state=config['random_seed'])\n",
    "        shadow_sets.append((shadow_train, shadow_test))\n",
    "\n",
    "    shadow_models = []\n",
    "    shadow_scaled_data = []\n",
    "    shadow_scalers = []\n",
    "    \n",
    "    for num in range(num_shadow_models):\n",
    "        shadow_scaler = StandardScaler()\n",
    "        \n",
    "        shadow_train = shadow_sets[num][0]\n",
    "        X_shadow_train = shadow_train.drop(['loan_status', 'multi_class', 'target'], axis=1)\n",
    "        if 'rate_quartile' in X_shadow_train.columns:\n",
    "            X_shadow_train = X_shadow_train.drop(['rate_quartile'], axis=1)\n",
    "        Y_shadow_train = shadow_train['target']  # Use multi-class target\n",
    "\n",
    "        X_shadow_train_scaled = shadow_scaler.fit_transform(X_shadow_train)\n",
    "\n",
    "        i = LogisticRegression(C=10000, max_iter=10000)\n",
    "        i.fit(X_shadow_train_scaled, Y_shadow_train)\n",
    "\n",
    "        shadow_scalers.append(shadow_scaler)\n",
    "        shadow_scaled_data.append((X_shadow_train_scaled, Y_shadow_train))\n",
    "        shadow_models.append(i)\n",
    "\n",
    "    # MODIFIED: Use raw probability vectors instead of engineered features\n",
    "    member_feature = []\n",
    "    member_label = []\n",
    "\n",
    "    for num in range(num_shadow_models):\n",
    "        model = shadow_models[num]\n",
    "        scaled_data = shadow_scaled_data[num][0]\n",
    "        Y_data = shadow_scaled_data[num][1]\n",
    "\n",
    "        results = model.predict_proba(scaled_data)\n",
    "        \n",
    "        # CHANGE: Use raw probability vectors directly (no engineered features)\n",
    "        attack_features = results  # Shape: (n_samples, n_classes)\n",
    "        \n",
    "        member_feature.append(attack_features)\n",
    "        member_label.append(np.ones(len(attack_features)))\n",
    "\n",
    "    non_member_feature = []\n",
    "    non_member_label = []\n",
    "\n",
    "    for num in range(num_shadow_models):\n",
    "        model = shadow_models[num]\n",
    "        test_set = shadow_sets[num][1]\n",
    "        scaler = shadow_scalers[num]\n",
    "\n",
    "        X_test = test_set.drop(['loan_status', 'multi_class', 'target'], axis=1)\n",
    "        if 'rate_quartile' in X_test.columns:\n",
    "            X_test = X_test.drop(['rate_quartile'], axis=1)\n",
    "        Y_data_test = test_set['target']  # Use multi-class target\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        results = model.predict_proba(X_test_scaled)\n",
    "        \n",
    "        # CHANGE: Use raw probability vectors directly (no engineered features)\n",
    "        attack_features = results  # Shape: (n_samples, n_classes)\n",
    "        \n",
    "        non_member_feature.append(attack_features)\n",
    "        non_member_label.append(np.zeros(len(attack_features)))\n",
    "\n",
    "    X_attack = np.vstack(member_feature + non_member_feature)\n",
    "    y_attack = np.hstack(member_label + non_member_label)\n",
    "    attack_scaler = StandardScaler()\n",
    "\n",
    "    X_attack_scale = attack_scaler.fit_transform(X_attack)\n",
    "\n",
    "    attack = LogisticRegression(max_iter=1000)\n",
    "    attack.fit(X_attack_scale, y_attack)\n",
    "    \n",
    "    # MODIFIED: Evaluate target model with raw probability vectors\n",
    "    target_results = target.predict_proba(X_forget_scaled)\n",
    "    \n",
    "    # CHANGE: Use raw probability vectors directly\n",
    "    target_attack_features = target_results  # Shape: (n_samples, n_classes)\n",
    "    \n",
    "    target_attack_features_scaled = attack_scaler.transform(target_attack_features)\n",
    "    \n",
    "    # MODIFIED: Evaluate unlearn model with raw probability vectors  \n",
    "    unlearn_results = unlearn.predict_proba(X_forget_scaled)\n",
    "    \n",
    "    # CHANGE: Use raw probability vectors directly\n",
    "    unlearn_attack_features = unlearn_results  # Shape: (n_samples, n_classes)\n",
    "    \n",
    "    unlearn_attack_features_scaled = attack_scaler.transform(unlearn_attack_features)\n",
    "    \n",
    "    target_attack_predictions = attack.predict(target_attack_features_scaled)\n",
    "    target_attack_accuracy = accuracy_score(np.ones(len(target_attack_predictions)), target_attack_predictions)\n",
    "    \n",
    "    unlearn_attack_predictions = attack.predict(unlearn_attack_features_scaled)\n",
    "    unlearn_attack_accuracy = accuracy_score(np.ones(len(unlearn_attack_predictions)), unlearn_attack_predictions)\n",
    "\n",
    "    retain_metrics_original = calculate_model_metrics(target, scaler.transform(X_test_scale), Y_test, 'original_retain')\n",
    "    retain_metrics_unlearned = calculate_model_metrics(unlearn, X_test_unlearn_scale, Y_test_unlearn, 'unlearned_retain')\n",
    "    forget_metrics_original = calculate_model_metrics(target, scaler.transform(X_forget), Y_forget, 'original_forget')\n",
    "    forget_metrics_unlearned = calculate_model_metrics(unlearn, X_forget_scaled, Y_forget, 'unlearned_forget')\n",
    "\n",
    "    # Add LabelEncoder to return for reference\n",
    "    return {\n",
    "        'attack_model': attack,\n",
    "        'attack_scaler': attack_scaler,\n",
    "        'target_model': target,\n",
    "        'unlearned_model': unlearn,\n",
    "        'target_attack_features_scaled': target_attack_features_scaled,\n",
    "        'forget_set': forget,\n",
    "        'target_accuracy': target_attack_accuracy,\n",
    "        'unlearn_accuracy': unlearn_attack_accuracy,\n",
    "        'retain_metrics_original': retain_metrics_original,\n",
    "        'retain_metrics_unlearned': retain_metrics_unlearned,\n",
    "        'forget_metrics_original': forget_metrics_original,\n",
    "        'forget_metrics_unlearned': forget_metrics_unlearned,\n",
    "        'label_encoder': le,\n",
    "        'num_classes': len(le.classes_)\n",
    "    }'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def run_pipeline(config):\\n    scaler = StandardScaler()\\n\\n    train_data, test_data = train_test_split(loan_data, test_size=0.4, random_state=config[\\'random_seed\\'], stratify=loan_data[\\'loan_status\\'])\\n\\n    # CREATE MULTI-CLASS TARGET: Convert loan_status + loan_grade into multi-class\\n    # Assume you have loan_grade column with values like \\'A\\', \\'B\\', \\'C\\', \\'D\\', etc.\\n    \\n    # Option 1: Combine loan_status with another categorical feature\\n    if \\'loan_grade\\' in train_data.columns:\\n        # Create 4-6 classes by combining loan_status (0,1) with loan_grade (A,B,C)\\n        train_data[\\'multi_class\\'] = train_data[\\'loan_status\\'].astype(str) + \\'_\\' + train_data[\\'loan_grade\\'].astype(str)\\n        test_data[\\'multi_class\\'] = test_data[\\'loan_status\\'].astype(str) + \\'_\\' + test_data[\\'loan_grade\\'].astype(str)\\n    else:\\n        # Option 2: Create classes based on loan_int_rate quartiles\\n        train_data[\\'rate_quartile\\'] = pd.qcut(train_data[\\'loan_int_rate\\'], q=4, labels=[\\'Low\\', \\'Med\\', \\'High\\', \\'VHigh\\'])\\n        test_data[\\'rate_quartile\\'] = pd.qcut(test_data[\\'loan_int_rate\\'], q=4, labels=[\\'Low\\', \\'Med\\', \\'High\\', \\'VHigh\\'])\\n        \\n        # Combine loan_status with rate quartiles for 8 classes\\n        train_data[\\'multi_class\\'] = train_data[\\'loan_status\\'].astype(str) + \\'_\\' + train_data[\\'rate_quartile\\'].astype(str)\\n        test_data[\\'multi_class\\'] = test_data[\\'loan_status\\'].astype(str) + \\'_\\' + test_data[\\'rate_quartile\\'].astype(str)\\n    \\n    # Encode to numeric\\n    from sklearn.preprocessing import LabelEncoder\\n    le = LabelEncoder()\\n    all_classes = pd.concat([train_data[\\'multi_class\\'], test_data[\\'multi_class\\']])\\n    le.fit(all_classes)\\n    \\n    train_data[\\'target\\'] = le.transform(train_data[\\'multi_class\\'])\\n    test_data[\\'target\\'] = le.transform(test_data[\\'multi_class\\'])\\n    \\n    print(f\"Created {len(le.classes_)} classes: {le.classes_}\")\\n    \\n    # Define forget set based on original criteria but use new target\\n    rate_threshold = train_data[\\'loan_int_rate\\'].quantile(config[\\'forget_percentile\\'])\\n    percent_income_threshold = train_data[\\'loan_percent_income\\'].quantile(config[\\'forget_percentile\\'])\\n    loan_amnt_threshold = train_data[\\'loan_amnt\\'].quantile(config[\\'forget_percentile\\'])\\n\\n    forget = train_data[(train_data[\\'loan_int_rate\\'] >= rate_threshold) |\\n                (train_data[\\'loan_percent_income\\'] >= percent_income_threshold) |\\n                (train_data[\\'loan_amnt\\'] >= loan_amnt_threshold)]\\n\\n    X_forget = forget.drop(columns=[\\'loan_status\\', \\'multi_class\\', \\'target\\'])\\n    if \\'rate_quartile\\' in X_forget.columns:\\n        X_forget = X_forget.drop(columns=[\\'rate_quartile\\'])\\n    Y_forget = forget[\\'target\\']\\n\\n    target = LogisticRegression(C=10000, max_iter=10000)\\n\\n    X = train_data.drop([\\'loan_status\\', \\'multi_class\\', \\'target\\'], axis=1)\\n    if \\'rate_quartile\\' in X.columns:\\n        X = X.drop([\\'rate_quartile\\'], axis=1)\\n    Y = train_data[\\'target\\']  # Use multi-class target\\n\\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=config[\\'random_seed\\'])\\n\\n    X_train, X_test, Y_train, Y_test = train_test_split(\\n        X_train, Y_train,\\n        train_size=900,\\n        random_state=config[\\'random_seed\\'],\\n        stratify=Y_train\\n    )\\n    \\n    X_train_scale = scaler.fit_transform(X_train)\\n    X_test_scale = scaler.transform(X_test)\\n\\n    target.fit(X_train_scale, Y_train)\\n    \\n    unlearn_scaler = StandardScaler()\\n    keep = train_data.drop(forget.index)\\n\\n    unlearn = LogisticRegression(C=10000, max_iter=10000)\\n\\n    X_unlearn = keep.drop([\\'loan_status\\', \\'multi_class\\', \\'target\\'], axis=1)\\n    if \\'rate_quartile\\' in X_unlearn.columns:\\n        X_unlearn = X_unlearn.drop([\\'rate_quartile\\'], axis=1)\\n    Y_unlearn = keep[\\'target\\']  # Use multi-class target\\n\\n    X_train_unlearn, X_test_unlearn, Y_train_unlearn, Y_test_unlearn = train_test_split(\\n        X_unlearn, Y_unlearn, test_size=.2, random_state=config[\\'random_seed\\'])\\n\\n    X_train_unlearn, X_test_unlearn, Y_train_unlearn, Y_test_unlearn = train_test_split(\\n        X_train_unlearn, Y_train_unlearn,\\n        train_size=900,\\n        random_state=config[\\'random_seed\\'],\\n        stratify=Y_train_unlearn\\n    )\\n\\n    X_train_unlearn_scale = unlearn_scaler.fit_transform(X_train_unlearn)\\n    X_test_unlearn_scale = unlearn_scaler.transform(X_test_unlearn)\\n\\n    unlearn.fit(X_train_unlearn_scale, Y_train_unlearn)\\n    X_forget_scaled = unlearn_scaler.transform(X_forget)\\n\\n    predictions = target.predict(X_forget_scaled)\\n    predictions_unlearn = unlearn.predict(X_forget_scaled)\\n\\n    # Shadow model setup\\n    num_shadow_models = config[\\'num_shadow_models\\']\\n    chunks = int(len(test_data)/num_shadow_models)\\n    shuffled_df = test_data.sample(frac=1, random_state=config[\\'random_seed\\']).reset_index(drop=True)\\n    shadow_sets = []\\n\\n    for num in range(num_shadow_models):\\n        start_index = int(chunks*num)\\n        end_index = int(start_index+chunks)\\n\\n        shadow_train, shadow_test = train_test_split(\\n            shuffled_df[start_index:end_index], test_size=.5, random_state=config[\\'random_seed\\'])\\n        shadow_sets.append((shadow_train, shadow_test))\\n\\n    shadow_models = []\\n    shadow_scaled_data = []\\n    shadow_scalers = []\\n    \\n    for num in range(num_shadow_models):\\n        shadow_scaler = StandardScaler()\\n        \\n        shadow_train = shadow_sets[num][0]\\n        X_shadow_train = shadow_train.drop([\\'loan_status\\', \\'multi_class\\', \\'target\\'], axis=1)\\n        if \\'rate_quartile\\' in X_shadow_train.columns:\\n            X_shadow_train = X_shadow_train.drop([\\'rate_quartile\\'], axis=1)\\n        Y_shadow_train = shadow_train[\\'target\\']  # Use multi-class target\\n\\n        X_shadow_train_scaled = shadow_scaler.fit_transform(X_shadow_train)\\n\\n        i = LogisticRegression(C=10000, max_iter=10000)\\n        i.fit(X_shadow_train_scaled, Y_shadow_train)\\n\\n        shadow_scalers.append(shadow_scaler)\\n        shadow_scaled_data.append((X_shadow_train_scaled, Y_shadow_train))\\n        shadow_models.append(i)\\n\\n    # BACK TO ENGINEERED FEATURES: Use confidence, entropy, loss, etc. (but keep multi-class)\\n    member_feature = []\\n    member_label = []\\n\\n    for num in range(num_shadow_models):\\n        model = shadow_models[num]\\n        scaled_data = shadow_scaled_data[num][0]\\n        Y_data = shadow_scaled_data[num][1]\\n\\n        results = model.predict_proba(scaled_data)\\n\\n        # ENGINEERED FEATURES (like your original approach)\\n        max_confidence = np.max(results, axis=1)\\n        entropy = -np.sum(results * np.log(results + 1e-8), axis=1)\\n        predictions = model.predict(scaled_data)\\n        true_class_proba = results[np.arange(len(Y_data)), Y_data]\\n        correctness = (predictions == Y_data).astype(int)\\n        loss = -np.log(true_class_proba + 1e-8)\\n\\n        attack_features = np.column_stack([\\n            max_confidence,\\n            entropy,\\n            true_class_proba,\\n            loss\\n        ])\\n        \\n        member_feature.append(attack_features)\\n        member_label.append(np.ones(len(attack_features)))\\n\\n    non_member_feature = []\\n    non_member_label = []\\n\\n    for num in range(num_shadow_models):\\n        model = shadow_models[num]\\n        test_set = shadow_sets[num][1]\\n        scaler = shadow_scalers[num]\\n\\n        X_test = test_set.drop([\\'loan_status\\', \\'multi_class\\', \\'target\\'], axis=1)\\n        if \\'rate_quartile\\' in X_test.columns:\\n            X_test = X_test.drop([\\'rate_quartile\\'], axis=1)\\n        Y_data_test = test_set[\\'target\\']  # Use multi-class target\\n        X_test_scaled = scaler.transform(X_test)\\n\\n        results = model.predict_proba(X_test_scaled)\\n\\n        # ENGINEERED FEATURES (like your original approach)\\n        max_confidence = np.max(results, axis=1)\\n        entropy = -np.sum(results * np.log(results + 1e-8), axis=1)\\n        predictions = model.predict(X_test_scaled)\\n        true_class_proba = results[np.arange(len(Y_data_test)), Y_data_test]\\n        correctness = (predictions == Y_data_test).astype(int)\\n        loss = -np.log(true_class_proba + 1e-8)\\n\\n        attack_features = np.column_stack([\\n            max_confidence,\\n            entropy,\\n            true_class_proba,\\n            loss\\n        ])\\n        \\n        non_member_feature.append(attack_features)\\n        non_member_label.append(np.zeros(len(attack_features)))\\n\\n    X_attack = np.vstack(member_feature + non_member_feature)\\n    y_attack = np.hstack(member_label + non_member_label)\\n    attack_scaler = StandardScaler()\\n\\n    X_attack_scale = attack_scaler.fit_transform(X_attack)\\n\\n    attack = LogisticRegression(max_iter=1000)\\n    attack.fit(X_attack_scale, y_attack)\\n    \\n    # BACK TO ENGINEERED FEATURES: Evaluate target model with engineered features\\n    target_results = target.predict_proba(X_forget_scaled)\\n    \\n    # ENGINEERED FEATURES for target model\\n    max_confidence = np.max(target_results, axis=1)\\n    entropy = -np.sum(target_results * np.log(target_results + 1e-8), axis=1)\\n    target_predictions = target.predict(X_forget_scaled)\\n    true_class_proba = target_results[np.arange(len(Y_forget)), Y_forget]\\n    correctness = (target_predictions == Y_forget).astype(int)\\n    loss = -np.log(true_class_proba + 1e-8)\\n\\n    target_attack_features = np.column_stack([\\n        max_confidence,\\n        entropy,\\n        true_class_proba,\\n        loss\\n    ])\\n    \\n    target_attack_features_scaled = attack_scaler.transform(target_attack_features)\\n    \\n    # BACK TO ENGINEERED FEATURES: Evaluate unlearn model with engineered features  \\n    unlearn_results = unlearn.predict_proba(X_forget_scaled)\\n    \\n    # ENGINEERED FEATURES for unlearn model\\n    max_confidence = np.max(unlearn_results, axis=1)\\n    entropy = -np.sum(unlearn_results * np.log(unlearn_results + 1e-8), axis=1)\\n    unlearn_predictions = unlearn.predict(X_forget_scaled)\\n    true_class_proba = unlearn_results[np.arange(len(Y_forget)), Y_forget]\\n    correctness = (unlearn_predictions == Y_forget).astype(int)\\n    loss = -np.log(true_class_proba + 1e-8)\\n\\n    unlearn_attack_features = np.column_stack([\\n        max_confidence,\\n        entropy,\\n        true_class_proba,\\n        loss\\n    ])\\n    \\n    unlearn_attack_features_scaled = attack_scaler.transform(unlearn_attack_features)\\n    \\n    target_attack_predictions = attack.predict(target_attack_features_scaled)\\n    target_attack_accuracy = accuracy_score(np.ones(len(target_attack_predictions)), target_attack_predictions)\\n    \\n    unlearn_attack_predictions = attack.predict(unlearn_attack_features_scaled)\\n    unlearn_attack_accuracy = accuracy_score(np.ones(len(unlearn_attack_predictions)), unlearn_attack_predictions)\\n\\n    retain_metrics_original = calculate_model_metrics(target, scaler.transform(X_test_scale), Y_test, \\'original_retain\\')\\n    retain_metrics_unlearned = calculate_model_metrics(unlearn, X_test_unlearn_scale, Y_test_unlearn, \\'unlearned_retain\\')\\n    forget_metrics_original = calculate_model_metrics(target, scaler.transform(X_forget), Y_forget, \\'original_forget\\')\\n    forget_metrics_unlearned = calculate_model_metrics(unlearn, X_forget_scaled, Y_forget, \\'unlearned_forget\\')\\n\\n    # Add LabelEncoder to return for reference\\n    return {\\n        \\'attack_model\\': attack,\\n        \\'attack_scaler\\': attack_scaler,\\n        \\'target_model\\': target,\\n        \\'unlearned_model\\': unlearn,\\n        \\'target_attack_features_scaled\\': target_attack_features_scaled,\\n        \\'forget_set\\': forget,\\n        \\'target_accuracy\\': target_attack_accuracy,\\n        \\'unlearn_accuracy\\': unlearn_attack_accuracy,\\n        \\'retain_metrics_original\\': retain_metrics_original,\\n        \\'retain_metrics_unlearned\\': retain_metrics_unlearned,\\n        \\'forget_metrics_original\\': forget_metrics_original,\\n        \\'forget_metrics_unlearned\\': forget_metrics_unlearned,\\n        \\'label_encoder\\': le,\\n        \\'num_classes\\': len(le.classes_)\\n    }'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#engeineered features mut=lti class\n",
    "'''def run_pipeline(config):\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    train_data, test_data = train_test_split(loan_data, test_size=0.4, random_state=config['random_seed'], stratify=loan_data['loan_status'])\n",
    "\n",
    "    # CREATE MULTI-CLASS TARGET: Convert loan_status + loan_grade into multi-class\n",
    "    # Assume you have loan_grade column with values like 'A', 'B', 'C', 'D', etc.\n",
    "    \n",
    "    # Option 1: Combine loan_status with another categorical feature\n",
    "    if 'loan_grade' in train_data.columns:\n",
    "        # Create 4-6 classes by combining loan_status (0,1) with loan_grade (A,B,C)\n",
    "        train_data['multi_class'] = train_data['loan_status'].astype(str) + '_' + train_data['loan_grade'].astype(str)\n",
    "        test_data['multi_class'] = test_data['loan_status'].astype(str) + '_' + test_data['loan_grade'].astype(str)\n",
    "    else:\n",
    "        # Option 2: Create classes based on loan_int_rate quartiles\n",
    "        train_data['rate_quartile'] = pd.qcut(train_data['loan_int_rate'], q=4, labels=['Low', 'Med', 'High', 'VHigh'])\n",
    "        test_data['rate_quartile'] = pd.qcut(test_data['loan_int_rate'], q=4, labels=['Low', 'Med', 'High', 'VHigh'])\n",
    "        \n",
    "        # Combine loan_status with rate quartiles for 8 classes\n",
    "        train_data['multi_class'] = train_data['loan_status'].astype(str) + '_' + train_data['rate_quartile'].astype(str)\n",
    "        test_data['multi_class'] = test_data['loan_status'].astype(str) + '_' + test_data['rate_quartile'].astype(str)\n",
    "    \n",
    "    # Encode to numeric\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    all_classes = pd.concat([train_data['multi_class'], test_data['multi_class']])\n",
    "    le.fit(all_classes)\n",
    "    \n",
    "    train_data['target'] = le.transform(train_data['multi_class'])\n",
    "    test_data['target'] = le.transform(test_data['multi_class'])\n",
    "    \n",
    "    print(f\"Created {len(le.classes_)} classes: {le.classes_}\")\n",
    "    \n",
    "    # Define forget set based on original criteria but use new target\n",
    "    rate_threshold = train_data['loan_int_rate'].quantile(config['forget_percentile'])\n",
    "    percent_income_threshold = train_data['loan_percent_income'].quantile(config['forget_percentile'])\n",
    "    loan_amnt_threshold = train_data['loan_amnt'].quantile(config['forget_percentile'])\n",
    "\n",
    "    forget = train_data[(train_data['loan_int_rate'] >= rate_threshold) |\n",
    "                (train_data['loan_percent_income'] >= percent_income_threshold) |\n",
    "                (train_data['loan_amnt'] >= loan_amnt_threshold)]\n",
    "\n",
    "    X_forget = forget.drop(columns=['loan_status', 'multi_class', 'target'])\n",
    "    if 'rate_quartile' in X_forget.columns:\n",
    "        X_forget = X_forget.drop(columns=['rate_quartile'])\n",
    "    Y_forget = forget['target']\n",
    "\n",
    "    target = LogisticRegression(C=10000, max_iter=10000)\n",
    "\n",
    "    X = train_data.drop(['loan_status', 'multi_class', 'target'], axis=1)\n",
    "    if 'rate_quartile' in X.columns:\n",
    "        X = X.drop(['rate_quartile'], axis=1)\n",
    "    Y = train_data['target']  # Use multi-class target\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=config['random_seed'])\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X_train, Y_train,\n",
    "        train_size=900,\n",
    "        random_state=config['random_seed'],\n",
    "        stratify=Y_train\n",
    "    )\n",
    "    \n",
    "    X_train_scale = scaler.fit_transform(X_train)\n",
    "    X_test_scale = scaler.transform(X_test)\n",
    "\n",
    "    target.fit(X_train_scale, Y_train)\n",
    "    \n",
    "    unlearn_scaler = StandardScaler()\n",
    "    keep = train_data.drop(forget.index)\n",
    "\n",
    "    unlearn = LogisticRegression(C=10000, max_iter=10000)\n",
    "\n",
    "    X_unlearn = keep.drop(['loan_status', 'multi_class', 'target'], axis=1)\n",
    "    if 'rate_quartile' in X_unlearn.columns:\n",
    "        X_unlearn = X_unlearn.drop(['rate_quartile'], axis=1)\n",
    "    Y_unlearn = keep['target']  # Use multi-class target\n",
    "\n",
    "    X_train_unlearn, X_test_unlearn, Y_train_unlearn, Y_test_unlearn = train_test_split(\n",
    "        X_unlearn, Y_unlearn, test_size=.2, random_state=config['random_seed'])\n",
    "\n",
    "    X_train_unlearn, X_test_unlearn, Y_train_unlearn, Y_test_unlearn = train_test_split(\n",
    "        X_train_unlearn, Y_train_unlearn,\n",
    "        train_size=900,\n",
    "        random_state=config['random_seed'],\n",
    "        stratify=Y_train_unlearn\n",
    "    )\n",
    "\n",
    "    X_train_unlearn_scale = unlearn_scaler.fit_transform(X_train_unlearn)\n",
    "    X_test_unlearn_scale = unlearn_scaler.transform(X_test_unlearn)\n",
    "\n",
    "    unlearn.fit(X_train_unlearn_scale, Y_train_unlearn)\n",
    "    X_forget_scaled = unlearn_scaler.transform(X_forget)\n",
    "\n",
    "    predictions = target.predict(X_forget_scaled)\n",
    "    predictions_unlearn = unlearn.predict(X_forget_scaled)\n",
    "\n",
    "    # Shadow model setup\n",
    "    num_shadow_models = config['num_shadow_models']\n",
    "    chunks = int(len(test_data)/num_shadow_models)\n",
    "    shuffled_df = test_data.sample(frac=1, random_state=config['random_seed']).reset_index(drop=True)\n",
    "    shadow_sets = []\n",
    "\n",
    "    for num in range(num_shadow_models):\n",
    "        start_index = int(chunks*num)\n",
    "        end_index = int(start_index+chunks)\n",
    "\n",
    "        shadow_train, shadow_test = train_test_split(\n",
    "            shuffled_df[start_index:end_index], test_size=.5, random_state=config['random_seed'])\n",
    "        shadow_sets.append((shadow_train, shadow_test))\n",
    "\n",
    "    shadow_models = []\n",
    "    shadow_scaled_data = []\n",
    "    shadow_scalers = []\n",
    "    \n",
    "    for num in range(num_shadow_models):\n",
    "        shadow_scaler = StandardScaler()\n",
    "        \n",
    "        shadow_train = shadow_sets[num][0]\n",
    "        X_shadow_train = shadow_train.drop(['loan_status', 'multi_class', 'target'], axis=1)\n",
    "        if 'rate_quartile' in X_shadow_train.columns:\n",
    "            X_shadow_train = X_shadow_train.drop(['rate_quartile'], axis=1)\n",
    "        Y_shadow_train = shadow_train['target']  # Use multi-class target\n",
    "\n",
    "        X_shadow_train_scaled = shadow_scaler.fit_transform(X_shadow_train)\n",
    "\n",
    "        i = LogisticRegression(C=10000, max_iter=10000)\n",
    "        i.fit(X_shadow_train_scaled, Y_shadow_train)\n",
    "\n",
    "        shadow_scalers.append(shadow_scaler)\n",
    "        shadow_scaled_data.append((X_shadow_train_scaled, Y_shadow_train))\n",
    "        shadow_models.append(i)\n",
    "\n",
    "    # BACK TO ENGINEERED FEATURES: Use confidence, entropy, loss, etc. (but keep multi-class)\n",
    "    member_feature = []\n",
    "    member_label = []\n",
    "\n",
    "    for num in range(num_shadow_models):\n",
    "        model = shadow_models[num]\n",
    "        scaled_data = shadow_scaled_data[num][0]\n",
    "        Y_data = shadow_scaled_data[num][1]\n",
    "\n",
    "        results = model.predict_proba(scaled_data)\n",
    "\n",
    "        # ENGINEERED FEATURES (like your original approach)\n",
    "        max_confidence = np.max(results, axis=1)\n",
    "        entropy = -np.sum(results * np.log(results + 1e-8), axis=1)\n",
    "        predictions = model.predict(scaled_data)\n",
    "        true_class_proba = results[np.arange(len(Y_data)), Y_data]\n",
    "        correctness = (predictions == Y_data).astype(int)\n",
    "        loss = -np.log(true_class_proba + 1e-8)\n",
    "\n",
    "        attack_features = np.column_stack([\n",
    "            max_confidence,\n",
    "            entropy,\n",
    "            true_class_proba,\n",
    "            loss\n",
    "        ])\n",
    "        \n",
    "        member_feature.append(attack_features)\n",
    "        member_label.append(np.ones(len(attack_features)))\n",
    "\n",
    "    non_member_feature = []\n",
    "    non_member_label = []\n",
    "\n",
    "    for num in range(num_shadow_models):\n",
    "        model = shadow_models[num]\n",
    "        test_set = shadow_sets[num][1]\n",
    "        scaler = shadow_scalers[num]\n",
    "\n",
    "        X_test = test_set.drop(['loan_status', 'multi_class', 'target'], axis=1)\n",
    "        if 'rate_quartile' in X_test.columns:\n",
    "            X_test = X_test.drop(['rate_quartile'], axis=1)\n",
    "        Y_data_test = test_set['target']  # Use multi-class target\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        results = model.predict_proba(X_test_scaled)\n",
    "\n",
    "        # ENGINEERED FEATURES (like your original approach)\n",
    "        max_confidence = np.max(results, axis=1)\n",
    "        entropy = -np.sum(results * np.log(results + 1e-8), axis=1)\n",
    "        predictions = model.predict(X_test_scaled)\n",
    "        true_class_proba = results[np.arange(len(Y_data_test)), Y_data_test]\n",
    "        correctness = (predictions == Y_data_test).astype(int)\n",
    "        loss = -np.log(true_class_proba + 1e-8)\n",
    "\n",
    "        attack_features = np.column_stack([\n",
    "            max_confidence,\n",
    "            entropy,\n",
    "            true_class_proba,\n",
    "            loss\n",
    "        ])\n",
    "        \n",
    "        non_member_feature.append(attack_features)\n",
    "        non_member_label.append(np.zeros(len(attack_features)))\n",
    "\n",
    "    X_attack = np.vstack(member_feature + non_member_feature)\n",
    "    y_attack = np.hstack(member_label + non_member_label)\n",
    "    attack_scaler = StandardScaler()\n",
    "\n",
    "    X_attack_scale = attack_scaler.fit_transform(X_attack)\n",
    "\n",
    "    attack = LogisticRegression(max_iter=1000)\n",
    "    attack.fit(X_attack_scale, y_attack)\n",
    "    \n",
    "    # BACK TO ENGINEERED FEATURES: Evaluate target model with engineered features\n",
    "    target_results = target.predict_proba(X_forget_scaled)\n",
    "    \n",
    "    # ENGINEERED FEATURES for target model\n",
    "    max_confidence = np.max(target_results, axis=1)\n",
    "    entropy = -np.sum(target_results * np.log(target_results + 1e-8), axis=1)\n",
    "    target_predictions = target.predict(X_forget_scaled)\n",
    "    true_class_proba = target_results[np.arange(len(Y_forget)), Y_forget]\n",
    "    correctness = (target_predictions == Y_forget).astype(int)\n",
    "    loss = -np.log(true_class_proba + 1e-8)\n",
    "\n",
    "    target_attack_features = np.column_stack([\n",
    "        max_confidence,\n",
    "        entropy,\n",
    "        true_class_proba,\n",
    "        loss\n",
    "    ])\n",
    "    \n",
    "    target_attack_features_scaled = attack_scaler.transform(target_attack_features)\n",
    "    \n",
    "    # BACK TO ENGINEERED FEATURES: Evaluate unlearn model with engineered features  \n",
    "    unlearn_results = unlearn.predict_proba(X_forget_scaled)\n",
    "    \n",
    "    # ENGINEERED FEATURES for unlearn model\n",
    "    max_confidence = np.max(unlearn_results, axis=1)\n",
    "    entropy = -np.sum(unlearn_results * np.log(unlearn_results + 1e-8), axis=1)\n",
    "    unlearn_predictions = unlearn.predict(X_forget_scaled)\n",
    "    true_class_proba = unlearn_results[np.arange(len(Y_forget)), Y_forget]\n",
    "    correctness = (unlearn_predictions == Y_forget).astype(int)\n",
    "    loss = -np.log(true_class_proba + 1e-8)\n",
    "\n",
    "    unlearn_attack_features = np.column_stack([\n",
    "        max_confidence,\n",
    "        entropy,\n",
    "        true_class_proba,\n",
    "        loss\n",
    "    ])\n",
    "    \n",
    "    unlearn_attack_features_scaled = attack_scaler.transform(unlearn_attack_features)\n",
    "    \n",
    "    target_attack_predictions = attack.predict(target_attack_features_scaled)\n",
    "    target_attack_accuracy = accuracy_score(np.ones(len(target_attack_predictions)), target_attack_predictions)\n",
    "    \n",
    "    unlearn_attack_predictions = attack.predict(unlearn_attack_features_scaled)\n",
    "    unlearn_attack_accuracy = accuracy_score(np.ones(len(unlearn_attack_predictions)), unlearn_attack_predictions)\n",
    "\n",
    "    retain_metrics_original = calculate_model_metrics(target, scaler.transform(X_test_scale), Y_test, 'original_retain')\n",
    "    retain_metrics_unlearned = calculate_model_metrics(unlearn, X_test_unlearn_scale, Y_test_unlearn, 'unlearned_retain')\n",
    "    forget_metrics_original = calculate_model_metrics(target, scaler.transform(X_forget), Y_forget, 'original_forget')\n",
    "    forget_metrics_unlearned = calculate_model_metrics(unlearn, X_forget_scaled, Y_forget, 'unlearned_forget')\n",
    "\n",
    "    # Add LabelEncoder to return for reference\n",
    "    return {\n",
    "        'attack_model': attack,\n",
    "        'attack_scaler': attack_scaler,\n",
    "        'target_model': target,\n",
    "        'unlearned_model': unlearn,\n",
    "        'target_attack_features_scaled': target_attack_features_scaled,\n",
    "        'forget_set': forget,\n",
    "        'target_accuracy': target_attack_accuracy,\n",
    "        'unlearn_accuracy': unlearn_attack_accuracy,\n",
    "        'retain_metrics_original': retain_metrics_original,\n",
    "        'retain_metrics_unlearned': retain_metrics_unlearned,\n",
    "        'forget_metrics_original': forget_metrics_original,\n",
    "        'forget_metrics_unlearned': forget_metrics_unlearned,\n",
    "        'label_encoder': le,\n",
    "        'num_classes': len(le.classes_)\n",
    "    }'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def run_pipeline(config):\\n    scaler = StandardScaler()\\n\\n    train_data, test_data = train_test_split(loan_data, test_size=0.4, random_state=config[\\'random_seed\\'], stratify=loan_data[\\'loan_status\\'])\\n\\n    # CREATE MULTI-CLASS TARGET: Convert loan_status + loan_grade into multi-class\\n    # Assume you have loan_grade column with values like \\'A\\', \\'B\\', \\'C\\', \\'D\\', etc.\\n    \\n    # Option 1: Combine loan_status with another categorical feature\\n    if \\'loan_grade\\' in train_data.columns:\\n        # Create 4-6 classes by combining loan_status (0,1) with loan_grade (A,B,C)\\n        train_data[\\'multi_class\\'] = train_data[\\'loan_status\\'].astype(str) + \\'_\\' + train_data[\\'loan_grade\\'].astype(str)\\n        test_data[\\'multi_class\\'] = test_data[\\'loan_status\\'].astype(str) + \\'_\\' + test_data[\\'loan_grade\\'].astype(str)\\n    else:\\n        # Option 2: Create classes based on loan_int_rate quartiles\\n        train_data[\\'rate_quartile\\'] = pd.qcut(train_data[\\'loan_int_rate\\'], q=4, labels=[\\'Low\\', \\'Med\\', \\'High\\', \\'VHigh\\'])\\n        test_data[\\'rate_quartile\\'] = pd.qcut(test_data[\\'loan_int_rate\\'], q=4, labels=[\\'Low\\', \\'Med\\', \\'High\\', \\'VHigh\\'])\\n        \\n        # Combine loan_status with rate quartiles for 8 classes\\n        train_data[\\'multi_class\\'] = train_data[\\'loan_status\\'].astype(str) + \\'_\\' + train_data[\\'rate_quartile\\'].astype(str)\\n        test_data[\\'multi_class\\'] = test_data[\\'loan_status\\'].astype(str) + \\'_\\' + test_data[\\'rate_quartile\\'].astype(str)\\n    \\n    # Encode to numeric\\n    from sklearn.preprocessing import LabelEncoder\\n    le = LabelEncoder()\\n    all_classes = pd.concat([train_data[\\'multi_class\\'], test_data[\\'multi_class\\']])\\n    le.fit(all_classes)\\n    \\n    train_data[\\'target\\'] = le.transform(train_data[\\'multi_class\\'])\\n    test_data[\\'target\\'] = le.transform(test_data[\\'multi_class\\'])\\n    \\n    print(f\"Created {len(le.classes_)} classes: {le.classes_}\")\\n    \\n    # Define forget set based on original criteria but use new target\\n    rate_threshold = train_data[\\'loan_int_rate\\'].quantile(config[\\'forget_percentile\\'])\\n    percent_income_threshold = train_data[\\'loan_percent_income\\'].quantile(config[\\'forget_percentile\\'])\\n    loan_amnt_threshold = train_data[\\'loan_amnt\\'].quantile(config[\\'forget_percentile\\'])\\n\\n    forget = train_data[(train_data[\\'loan_int_rate\\'] >= rate_threshold) |\\n                (train_data[\\'loan_percent_income\\'] >= percent_income_threshold) |\\n                (train_data[\\'loan_amnt\\'] >= loan_amnt_threshold)]\\n\\n    X_forget = forget.drop(columns=[\\'loan_status\\', \\'multi_class\\', \\'target\\'])\\n    if \\'rate_quartile\\' in X_forget.columns:\\n        X_forget = X_forget.drop(columns=[\\'rate_quartile\\'])\\n    Y_forget = forget[\\'target\\']\\n\\n    target = LogisticRegression(C=10000, max_iter=10000)\\n\\n    X = train_data.drop([\\'loan_status\\', \\'multi_class\\', \\'target\\'], axis=1)\\n    if \\'rate_quartile\\' in X.columns:\\n        X = X.drop([\\'rate_quartile\\'], axis=1)\\n    Y = train_data[\\'target\\']  # Use multi-class target\\n\\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=config[\\'random_seed\\'])\\n\\n    X_train, X_test, Y_train, Y_test = train_test_split(\\n        X_train, Y_train,\\n        train_size=900,\\n        random_state=config[\\'random_seed\\'],\\n        stratify=Y_train\\n    )\\n    \\n    X_train_scale = scaler.fit_transform(X_train)\\n    X_test_scale = scaler.transform(X_test)\\n\\n    target.fit(X_train_scale, Y_train)\\n    \\n    unlearn_scaler = StandardScaler()\\n    keep = train_data.drop(forget.index)\\n\\n    unlearn = LogisticRegression(C=10000, max_iter=10000)\\n\\n    X_unlearn = keep.drop([\\'loan_status\\', \\'multi_class\\', \\'target\\'], axis=1)\\n    if \\'rate_quartile\\' in X_unlearn.columns:\\n        X_unlearn = X_unlearn.drop([\\'rate_quartile\\'], axis=1)\\n    Y_unlearn = keep[\\'target\\']  # Use multi-class target\\n\\n    X_train_unlearn, X_test_unlearn, Y_train_unlearn, Y_test_unlearn = train_test_split(\\n        X_unlearn, Y_unlearn, test_size=.2, random_state=config[\\'random_seed\\'])\\n\\n    X_train_unlearn, X_test_unlearn, Y_train_unlearn, Y_test_unlearn = train_test_split(\\n        X_train_unlearn, Y_train_unlearn,\\n        train_size=900,\\n        random_state=config[\\'random_seed\\'],\\n        stratify=Y_train_unlearn\\n    )\\n\\n    X_train_unlearn_scale = unlearn_scaler.fit_transform(X_train_unlearn)\\n    X_test_unlearn_scale = unlearn_scaler.transform(X_test_unlearn)\\n\\n    unlearn.fit(X_train_unlearn_scale, Y_train_unlearn)\\n    X_forget_scaled = unlearn_scaler.transform(X_forget)\\n\\n    predictions = target.predict(X_forget_scaled)\\n    predictions_unlearn = unlearn.predict(X_forget_scaled)\\n\\n    # Shadow model setup\\n    num_shadow_models = config[\\'num_shadow_models\\']\\n    chunks = int(len(test_data)/num_shadow_models)\\n    shuffled_df = test_data.sample(frac=1, random_state=config[\\'random_seed\\']).reset_index(drop=True)\\n    shadow_sets = []\\n\\n    for num in range(num_shadow_models):\\n        start_index = int(chunks*num)\\n        end_index = int(start_index+chunks)\\n\\n        shadow_train, shadow_test = train_test_split(\\n            shuffled_df[start_index:end_index], test_size=.5, random_state=config[\\'random_seed\\'])\\n        shadow_sets.append((shadow_train, shadow_test))\\n\\n    shadow_models = []\\n    shadow_scaled_data = []\\n    shadow_scalers = []\\n    \\n    for num in range(num_shadow_models):\\n        shadow_scaler = StandardScaler()\\n        \\n        shadow_train = shadow_sets[num][0]\\n        X_shadow_train = shadow_train.drop([\\'loan_status\\', \\'multi_class\\', \\'target\\'], axis=1)\\n        if \\'rate_quartile\\' in X_shadow_train.columns:\\n            X_shadow_train = X_shadow_train.drop([\\'rate_quartile\\'], axis=1)\\n        Y_shadow_train = shadow_train[\\'target\\']  # Use multi-class target\\n\\n        X_shadow_train_scaled = shadow_scaler.fit_transform(X_shadow_train)\\n\\n        i = LogisticRegression(C=10000, max_iter=10000)\\n        i.fit(X_shadow_train_scaled, Y_shadow_train)\\n\\n        shadow_scalers.append(shadow_scaler)\\n        shadow_scaled_data.append((X_shadow_train_scaled, Y_shadow_train))\\n        shadow_models.append(i)\\n\\n    # SHOKRI APPROACH: Train separate attack models per class\\n    # Collect member and non-member data per class\\n    class_member_features = {}\\n    class_member_labels = {}\\n    class_non_member_features = {}\\n    class_non_member_labels = {}\\n    \\n    # Initialize dictionaries for each class\\n    unique_classes = np.unique(np.concatenate([data[1] for data in shadow_scaled_data]))\\n    for class_label in unique_classes:\\n        class_member_features[class_label] = []\\n        class_member_labels[class_label] = []\\n        class_non_member_features[class_label] = []\\n        class_non_member_labels[class_label] = []\\n\\n    # Collect member data (training data from shadow models) PER CLASS\\n    for num in range(num_shadow_models):\\n        model = shadow_models[num]\\n        scaled_data = shadow_scaled_data[num][0]\\n        Y_data = shadow_scaled_data[num][1]\\n\\n        results = model.predict_proba(scaled_data)\\n\\n        # ENGINEERED FEATURES (like your original approach)\\n        max_confidence = np.max(results, axis=1)\\n        entropy = -np.sum(results * np.log(results + 1e-8), axis=1)\\n        predictions = model.predict(scaled_data)\\n        true_class_proba = results[np.arange(len(Y_data)), Y_data]\\n        correctness = (predictions == Y_data).astype(int)\\n        loss = -np.log(true_class_proba + 1e-8)\\n\\n        attack_features = np.column_stack([\\n            max_confidence,\\n            entropy,\\n            true_class_proba,\\n            loss\\n        ])\\n        \\n        # Group by true class\\n        for class_label in unique_classes:\\n            class_mask = (Y_data == class_label)\\n            if np.sum(class_mask) > 0:\\n                class_member_features[class_label].append(attack_features[class_mask])\\n                class_member_labels[class_label].append(np.ones(np.sum(class_mask)))\\n\\n    # Collect non-member data (test data from shadow models) PER CLASS\\n    for num in range(num_shadow_models):\\n        model = shadow_models[num]\\n        test_set = shadow_sets[num][1]\\n        scaler = shadow_scalers[num]\\n\\n        X_test = test_set.drop([\\'loan_status\\', \\'multi_class\\', \\'target\\'], axis=1)\\n        if \\'rate_quartile\\' in X_test.columns:\\n            X_test = X_test.drop([\\'rate_quartile\\'], axis=1)\\n        Y_data_test = test_set[\\'target\\']  # Use multi-class target\\n        X_test_scaled = scaler.transform(X_test)\\n\\n        results = model.predict_proba(X_test_scaled)\\n\\n        # ENGINEERED FEATURES (like your original approach)\\n        max_confidence = np.max(results, axis=1)\\n        entropy = -np.sum(results * np.log(results + 1e-8), axis=1)\\n        predictions = model.predict(X_test_scaled)\\n        true_class_proba = results[np.arange(len(Y_data_test)), Y_data_test]\\n        correctness = (predictions == Y_data_test).astype(int)\\n        loss = -np.log(true_class_proba + 1e-8)\\n\\n        attack_features = np.column_stack([\\n            max_confidence,\\n            entropy,\\n            true_class_proba,\\n            loss\\n        ])\\n        \\n        # Group by true class\\n        for class_label in unique_classes:\\n            class_mask = (Y_data_test == class_label)\\n            if np.sum(class_mask) > 0:\\n                class_non_member_features[class_label].append(attack_features[class_mask])\\n                class_non_member_labels[class_label].append(np.zeros(np.sum(class_mask)))\\n\\n    # Train separate attack models per class (SHOKRI APPROACH)\\n    attack_models = {}\\n    attack_scalers = {}\\n\\n    for class_label in unique_classes:\\n        print(f\"Training attack model for class {class_label}\")\\n        \\n        if class_member_features[class_label] and class_non_member_features[class_label]:\\n            # Combine member and non-member data for this class\\n            X_attack_class = np.vstack(class_member_features[class_label] + class_non_member_features[class_label])\\n            y_attack_class = np.hstack(class_member_labels[class_label] + class_non_member_labels[class_label])\\n\\n            # Train/test split for this class\\n            X_train_attack, X_test_attack, y_train_attack, y_test_attack = train_test_split(\\n                X_attack_class, y_attack_class, test_size=0.3, random_state=config[\\'random_seed\\'], \\n                stratify=y_attack_class\\n            )\\n\\n            # Scale and train attack model for this class\\n            attack_scaler_class = StandardScaler()\\n            X_train_attack_scaled = attack_scaler_class.fit_transform(X_train_attack)\\n            X_test_attack_scaled = attack_scaler_class.transform(X_test_attack)\\n\\n            attack_class = LogisticRegression(max_iter=1000)\\n            attack_class.fit(X_train_attack_scaled, y_train_attack)\\n\\n            print(f\"Class {class_label} attack accuracy: {attack_class.score(X_test_attack_scaled, y_test_attack):.3f}\")\\n\\n            attack_models[class_label] = attack_class\\n            attack_scalers[class_label] = attack_scaler_class\\n        else:\\n            print(f\"Insufficient data for class {class_label}\")\\n\\n    # Remove old single attack model code\\n    # X_attack = np.vstack(member_feature + non_member_feature)\\n    # y_attack = np.hstack(member_label + non_member_label)\\n    # attack_scaler = StandardScaler()\\n    # X_attack_scale = attack_scaler.fit_transform(X_attack)\\n    # attack = LogisticRegression(max_iter=1000)\\n    # attack.fit(X_attack_scale, y_attack)\\n    \\n    # SHOKRI EVALUATION: Use per-class attack models\\n    def evaluate_per_class_attack(model, X_scaled, Y_true, attack_models, attack_scalers, model_name):\\n        results = model.predict_proba(X_scaled)\\n        \\n        # ENGINEERED FEATURES for evaluation\\n        max_confidence = np.max(results, axis=1)\\n        entropy = -np.sum(results * np.log(results + 1e-8), axis=1)\\n        predictions = model.predict(X_scaled)\\n        true_class_proba = results[np.arange(len(Y_true)), Y_true]\\n        correctness = (predictions == Y_true).astype(int)\\n        loss = -np.log(true_class_proba + 1e-8)\\n\\n        attack_features = np.column_stack([\\n            max_confidence,\\n            entropy,\\n            true_class_proba,\\n            loss\\n        ])\\n        \\n        attack_predictions = []\\n        class_accuracies = {}\\n        \\n        for i, true_class in enumerate(Y_true):\\n            if true_class in attack_models:\\n                class_attack = attack_models[true_class]\\n                class_scaler = attack_scalers[true_class]\\n                \\n                sample_features = attack_features[i:i+1]  # Single sample\\n                sample_scaled = class_scaler.transform(sample_features)\\n                prediction = class_attack.predict(sample_scaled)[0]\\n                attack_predictions.append(prediction)\\n            else:\\n                attack_predictions.append(0)  # Default if no attack model for class\\n        \\n        # Calculate per-class accuracies\\n        for class_label in attack_models.keys():\\n            class_mask = (Y_true == class_label)\\n            if np.sum(class_mask) > 0:\\n                class_preds = np.array(attack_predictions)[class_mask]\\n                # For target model, we expect all predictions to be 1 (member)\\n                # For unlearn model, we expect predictions to be closer to 0 (non-member)\\n                class_accuracy = np.mean(class_preds)\\n                class_accuracies[class_label] = class_accuracy\\n                print(f\"{model_name} - Class {class_label} attack accuracy: {class_accuracy:.3f}\")\\n        \\n        overall_accuracy = np.mean(attack_predictions)\\n        print(f\"{model_name} - Overall attack accuracy: {overall_accuracy:.3f}\")\\n        \\n        return overall_accuracy, class_accuracies\\n\\n    target_attack_accuracy, target_class_accuracies = evaluate_per_class_attack(\\n        target, X_forget_scaled, Y_forget, attack_models, attack_scalers, \"Target\"\\n    )\\n    \\n    unlearn_attack_accuracy, unlearn_class_accuracies = evaluate_per_class_attack(\\n        unlearn, X_forget_scaled, Y_forget, attack_models, attack_scalers, \"Unlearn\"\\n    )\\n\\n    retain_metrics_original = calculate_model_metrics(target, scaler.transform(X_test_scale), Y_test, \\'original_retain\\')\\n    retain_metrics_unlearned = calculate_model_metrics(unlearn, X_test_unlearn_scale, Y_test_unlearn, \\'unlearned_retain\\')\\n    forget_metrics_original = calculate_model_metrics(target, scaler.transform(X_forget), Y_forget, \\'original_forget\\')\\n    forget_metrics_unlearned = calculate_model_metrics(unlearn, X_forget_scaled, Y_forget, \\'unlearned_forget\\')\\n\\n    # Add per-class results to return\\n    return {\\n        \\'attack_models\\': attack_models,  # Now a dict of per-class models\\n        \\'attack_scalers\\': attack_scalers,  # Now a dict of per-class scalers\\n        \\'target_model\\': target,\\n        \\'unlearned_model\\': unlearn,\\n        \\'forget_set\\': forget,\\n        \\'target_accuracy\\': target_attack_accuracy,\\n        \\'unlearn_accuracy\\': unlearn_attack_accuracy,\\n        \\'target_class_accuracies\\': target_class_accuracies,\\n        \\'unlearn_class_accuracies\\': unlearn_class_accuracies,\\n        \\'retain_metrics_original\\': retain_metrics_original,\\n        \\'retain_metrics_unlearned\\': retain_metrics_unlearned,\\n        \\'forget_metrics_original\\': forget_metrics_original,\\n        \\'forget_metrics_unlearned\\': forget_metrics_unlearned,\\n        \\'label_encoder\\': le,\\n        \\'num_classes\\': len(le.classes_)\\n    }'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#per class engineered features multi class\n",
    "'''def run_pipeline(config):\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    train_data, test_data = train_test_split(loan_data, test_size=0.4, random_state=config['random_seed'], stratify=loan_data['loan_status'])\n",
    "\n",
    "    # CREATE MULTI-CLASS TARGET: Convert loan_status + loan_grade into multi-class\n",
    "    # Assume you have loan_grade column with values like 'A', 'B', 'C', 'D', etc.\n",
    "    \n",
    "    # Option 1: Combine loan_status with another categorical feature\n",
    "    if 'loan_grade' in train_data.columns:\n",
    "        # Create 4-6 classes by combining loan_status (0,1) with loan_grade (A,B,C)\n",
    "        train_data['multi_class'] = train_data['loan_status'].astype(str) + '_' + train_data['loan_grade'].astype(str)\n",
    "        test_data['multi_class'] = test_data['loan_status'].astype(str) + '_' + test_data['loan_grade'].astype(str)\n",
    "    else:\n",
    "        # Option 2: Create classes based on loan_int_rate quartiles\n",
    "        train_data['rate_quartile'] = pd.qcut(train_data['loan_int_rate'], q=4, labels=['Low', 'Med', 'High', 'VHigh'])\n",
    "        test_data['rate_quartile'] = pd.qcut(test_data['loan_int_rate'], q=4, labels=['Low', 'Med', 'High', 'VHigh'])\n",
    "        \n",
    "        # Combine loan_status with rate quartiles for 8 classes\n",
    "        train_data['multi_class'] = train_data['loan_status'].astype(str) + '_' + train_data['rate_quartile'].astype(str)\n",
    "        test_data['multi_class'] = test_data['loan_status'].astype(str) + '_' + test_data['rate_quartile'].astype(str)\n",
    "    \n",
    "    # Encode to numeric\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    all_classes = pd.concat([train_data['multi_class'], test_data['multi_class']])\n",
    "    le.fit(all_classes)\n",
    "    \n",
    "    train_data['target'] = le.transform(train_data['multi_class'])\n",
    "    test_data['target'] = le.transform(test_data['multi_class'])\n",
    "    \n",
    "    print(f\"Created {len(le.classes_)} classes: {le.classes_}\")\n",
    "    \n",
    "    # Define forget set based on original criteria but use new target\n",
    "    rate_threshold = train_data['loan_int_rate'].quantile(config['forget_percentile'])\n",
    "    percent_income_threshold = train_data['loan_percent_income'].quantile(config['forget_percentile'])\n",
    "    loan_amnt_threshold = train_data['loan_amnt'].quantile(config['forget_percentile'])\n",
    "\n",
    "    forget = train_data[(train_data['loan_int_rate'] >= rate_threshold) |\n",
    "                (train_data['loan_percent_income'] >= percent_income_threshold) |\n",
    "                (train_data['loan_amnt'] >= loan_amnt_threshold)]\n",
    "\n",
    "    X_forget = forget.drop(columns=['loan_status', 'multi_class', 'target'])\n",
    "    if 'rate_quartile' in X_forget.columns:\n",
    "        X_forget = X_forget.drop(columns=['rate_quartile'])\n",
    "    Y_forget = forget['target']\n",
    "\n",
    "    target = LogisticRegression(C=10000, max_iter=10000)\n",
    "\n",
    "    X = train_data.drop(['loan_status', 'multi_class', 'target'], axis=1)\n",
    "    if 'rate_quartile' in X.columns:\n",
    "        X = X.drop(['rate_quartile'], axis=1)\n",
    "    Y = train_data['target']  # Use multi-class target\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=config['random_seed'])\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X_train, Y_train,\n",
    "        train_size=900,\n",
    "        random_state=config['random_seed'],\n",
    "        stratify=Y_train\n",
    "    )\n",
    "    \n",
    "    X_train_scale = scaler.fit_transform(X_train)\n",
    "    X_test_scale = scaler.transform(X_test)\n",
    "\n",
    "    target.fit(X_train_scale, Y_train)\n",
    "    \n",
    "    unlearn_scaler = StandardScaler()\n",
    "    keep = train_data.drop(forget.index)\n",
    "\n",
    "    unlearn = LogisticRegression(C=10000, max_iter=10000)\n",
    "\n",
    "    X_unlearn = keep.drop(['loan_status', 'multi_class', 'target'], axis=1)\n",
    "    if 'rate_quartile' in X_unlearn.columns:\n",
    "        X_unlearn = X_unlearn.drop(['rate_quartile'], axis=1)\n",
    "    Y_unlearn = keep['target']  # Use multi-class target\n",
    "\n",
    "    X_train_unlearn, X_test_unlearn, Y_train_unlearn, Y_test_unlearn = train_test_split(\n",
    "        X_unlearn, Y_unlearn, test_size=.2, random_state=config['random_seed'])\n",
    "\n",
    "    X_train_unlearn, X_test_unlearn, Y_train_unlearn, Y_test_unlearn = train_test_split(\n",
    "        X_train_unlearn, Y_train_unlearn,\n",
    "        train_size=900,\n",
    "        random_state=config['random_seed'],\n",
    "        stratify=Y_train_unlearn\n",
    "    )\n",
    "\n",
    "    X_train_unlearn_scale = unlearn_scaler.fit_transform(X_train_unlearn)\n",
    "    X_test_unlearn_scale = unlearn_scaler.transform(X_test_unlearn)\n",
    "\n",
    "    unlearn.fit(X_train_unlearn_scale, Y_train_unlearn)\n",
    "    X_forget_scaled = unlearn_scaler.transform(X_forget)\n",
    "\n",
    "    predictions = target.predict(X_forget_scaled)\n",
    "    predictions_unlearn = unlearn.predict(X_forget_scaled)\n",
    "\n",
    "    # Shadow model setup\n",
    "    num_shadow_models = config['num_shadow_models']\n",
    "    chunks = int(len(test_data)/num_shadow_models)\n",
    "    shuffled_df = test_data.sample(frac=1, random_state=config['random_seed']).reset_index(drop=True)\n",
    "    shadow_sets = []\n",
    "\n",
    "    for num in range(num_shadow_models):\n",
    "        start_index = int(chunks*num)\n",
    "        end_index = int(start_index+chunks)\n",
    "\n",
    "        shadow_train, shadow_test = train_test_split(\n",
    "            shuffled_df[start_index:end_index], test_size=.5, random_state=config['random_seed'])\n",
    "        shadow_sets.append((shadow_train, shadow_test))\n",
    "\n",
    "    shadow_models = []\n",
    "    shadow_scaled_data = []\n",
    "    shadow_scalers = []\n",
    "    \n",
    "    for num in range(num_shadow_models):\n",
    "        shadow_scaler = StandardScaler()\n",
    "        \n",
    "        shadow_train = shadow_sets[num][0]\n",
    "        X_shadow_train = shadow_train.drop(['loan_status', 'multi_class', 'target'], axis=1)\n",
    "        if 'rate_quartile' in X_shadow_train.columns:\n",
    "            X_shadow_train = X_shadow_train.drop(['rate_quartile'], axis=1)\n",
    "        Y_shadow_train = shadow_train['target']  # Use multi-class target\n",
    "\n",
    "        X_shadow_train_scaled = shadow_scaler.fit_transform(X_shadow_train)\n",
    "\n",
    "        i = LogisticRegression(C=10000, max_iter=10000)\n",
    "        i.fit(X_shadow_train_scaled, Y_shadow_train)\n",
    "\n",
    "        shadow_scalers.append(shadow_scaler)\n",
    "        shadow_scaled_data.append((X_shadow_train_scaled, Y_shadow_train))\n",
    "        shadow_models.append(i)\n",
    "\n",
    "    # SHOKRI APPROACH: Train separate attack models per class\n",
    "    # Collect member and non-member data per class\n",
    "    class_member_features = {}\n",
    "    class_member_labels = {}\n",
    "    class_non_member_features = {}\n",
    "    class_non_member_labels = {}\n",
    "    \n",
    "    # Initialize dictionaries for each class\n",
    "    unique_classes = np.unique(np.concatenate([data[1] for data in shadow_scaled_data]))\n",
    "    for class_label in unique_classes:\n",
    "        class_member_features[class_label] = []\n",
    "        class_member_labels[class_label] = []\n",
    "        class_non_member_features[class_label] = []\n",
    "        class_non_member_labels[class_label] = []\n",
    "\n",
    "    # Collect member data (training data from shadow models) PER CLASS\n",
    "    for num in range(num_shadow_models):\n",
    "        model = shadow_models[num]\n",
    "        scaled_data = shadow_scaled_data[num][0]\n",
    "        Y_data = shadow_scaled_data[num][1]\n",
    "\n",
    "        results = model.predict_proba(scaled_data)\n",
    "\n",
    "        # ENGINEERED FEATURES (like your original approach)\n",
    "        max_confidence = np.max(results, axis=1)\n",
    "        entropy = -np.sum(results * np.log(results + 1e-8), axis=1)\n",
    "        predictions = model.predict(scaled_data)\n",
    "        true_class_proba = results[np.arange(len(Y_data)), Y_data]\n",
    "        correctness = (predictions == Y_data).astype(int)\n",
    "        loss = -np.log(true_class_proba + 1e-8)\n",
    "\n",
    "        attack_features = np.column_stack([\n",
    "            max_confidence,\n",
    "            entropy,\n",
    "            true_class_proba,\n",
    "            loss\n",
    "        ])\n",
    "        \n",
    "        # Group by true class\n",
    "        for class_label in unique_classes:\n",
    "            class_mask = (Y_data == class_label)\n",
    "            if np.sum(class_mask) > 0:\n",
    "                class_member_features[class_label].append(attack_features[class_mask])\n",
    "                class_member_labels[class_label].append(np.ones(np.sum(class_mask)))\n",
    "\n",
    "    # Collect non-member data (test data from shadow models) PER CLASS\n",
    "    for num in range(num_shadow_models):\n",
    "        model = shadow_models[num]\n",
    "        test_set = shadow_sets[num][1]\n",
    "        scaler = shadow_scalers[num]\n",
    "\n",
    "        X_test = test_set.drop(['loan_status', 'multi_class', 'target'], axis=1)\n",
    "        if 'rate_quartile' in X_test.columns:\n",
    "            X_test = X_test.drop(['rate_quartile'], axis=1)\n",
    "        Y_data_test = test_set['target']  # Use multi-class target\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        results = model.predict_proba(X_test_scaled)\n",
    "\n",
    "        # ENGINEERED FEATURES (like your original approach)\n",
    "        max_confidence = np.max(results, axis=1)\n",
    "        entropy = -np.sum(results * np.log(results + 1e-8), axis=1)\n",
    "        predictions = model.predict(X_test_scaled)\n",
    "        true_class_proba = results[np.arange(len(Y_data_test)), Y_data_test]\n",
    "        correctness = (predictions == Y_data_test).astype(int)\n",
    "        loss = -np.log(true_class_proba + 1e-8)\n",
    "\n",
    "        attack_features = np.column_stack([\n",
    "            max_confidence,\n",
    "            entropy,\n",
    "            true_class_proba,\n",
    "            loss\n",
    "        ])\n",
    "        \n",
    "        # Group by true class\n",
    "        for class_label in unique_classes:\n",
    "            class_mask = (Y_data_test == class_label)\n",
    "            if np.sum(class_mask) > 0:\n",
    "                class_non_member_features[class_label].append(attack_features[class_mask])\n",
    "                class_non_member_labels[class_label].append(np.zeros(np.sum(class_mask)))\n",
    "\n",
    "    # Train separate attack models per class (SHOKRI APPROACH)\n",
    "    attack_models = {}\n",
    "    attack_scalers = {}\n",
    "\n",
    "    for class_label in unique_classes:\n",
    "        print(f\"Training attack model for class {class_label}\")\n",
    "        \n",
    "        if class_member_features[class_label] and class_non_member_features[class_label]:\n",
    "            # Combine member and non-member data for this class\n",
    "            X_attack_class = np.vstack(class_member_features[class_label] + class_non_member_features[class_label])\n",
    "            y_attack_class = np.hstack(class_member_labels[class_label] + class_non_member_labels[class_label])\n",
    "\n",
    "            # Train/test split for this class\n",
    "            X_train_attack, X_test_attack, y_train_attack, y_test_attack = train_test_split(\n",
    "                X_attack_class, y_attack_class, test_size=0.3, random_state=config['random_seed'], \n",
    "                stratify=y_attack_class\n",
    "            )\n",
    "\n",
    "            # Scale and train attack model for this class\n",
    "            attack_scaler_class = StandardScaler()\n",
    "            X_train_attack_scaled = attack_scaler_class.fit_transform(X_train_attack)\n",
    "            X_test_attack_scaled = attack_scaler_class.transform(X_test_attack)\n",
    "\n",
    "            attack_class = LogisticRegression(max_iter=1000)\n",
    "            attack_class.fit(X_train_attack_scaled, y_train_attack)\n",
    "\n",
    "            print(f\"Class {class_label} attack accuracy: {attack_class.score(X_test_attack_scaled, y_test_attack):.3f}\")\n",
    "\n",
    "            attack_models[class_label] = attack_class\n",
    "            attack_scalers[class_label] = attack_scaler_class\n",
    "        else:\n",
    "            print(f\"Insufficient data for class {class_label}\")\n",
    "\n",
    "    # Remove old single attack model code\n",
    "    # X_attack = np.vstack(member_feature + non_member_feature)\n",
    "    # y_attack = np.hstack(member_label + non_member_label)\n",
    "    # attack_scaler = StandardScaler()\n",
    "    # X_attack_scale = attack_scaler.fit_transform(X_attack)\n",
    "    # attack = LogisticRegression(max_iter=1000)\n",
    "    # attack.fit(X_attack_scale, y_attack)\n",
    "    \n",
    "    # SHOKRI EVALUATION: Use per-class attack models\n",
    "    def evaluate_per_class_attack(model, X_scaled, Y_true, attack_models, attack_scalers, model_name):\n",
    "        results = model.predict_proba(X_scaled)\n",
    "        \n",
    "        # ENGINEERED FEATURES for evaluation\n",
    "        max_confidence = np.max(results, axis=1)\n",
    "        entropy = -np.sum(results * np.log(results + 1e-8), axis=1)\n",
    "        predictions = model.predict(X_scaled)\n",
    "        true_class_proba = results[np.arange(len(Y_true)), Y_true]\n",
    "        correctness = (predictions == Y_true).astype(int)\n",
    "        loss = -np.log(true_class_proba + 1e-8)\n",
    "\n",
    "        attack_features = np.column_stack([\n",
    "            max_confidence,\n",
    "            entropy,\n",
    "            true_class_proba,\n",
    "            loss\n",
    "        ])\n",
    "        \n",
    "        attack_predictions = []\n",
    "        class_accuracies = {}\n",
    "        \n",
    "        for i, true_class in enumerate(Y_true):\n",
    "            if true_class in attack_models:\n",
    "                class_attack = attack_models[true_class]\n",
    "                class_scaler = attack_scalers[true_class]\n",
    "                \n",
    "                sample_features = attack_features[i:i+1]  # Single sample\n",
    "                sample_scaled = class_scaler.transform(sample_features)\n",
    "                prediction = class_attack.predict(sample_scaled)[0]\n",
    "                attack_predictions.append(prediction)\n",
    "            else:\n",
    "                attack_predictions.append(0)  # Default if no attack model for class\n",
    "        \n",
    "        # Calculate per-class accuracies\n",
    "        for class_label in attack_models.keys():\n",
    "            class_mask = (Y_true == class_label)\n",
    "            if np.sum(class_mask) > 0:\n",
    "                class_preds = np.array(attack_predictions)[class_mask]\n",
    "                # For target model, we expect all predictions to be 1 (member)\n",
    "                # For unlearn model, we expect predictions to be closer to 0 (non-member)\n",
    "                class_accuracy = np.mean(class_preds)\n",
    "                class_accuracies[class_label] = class_accuracy\n",
    "                print(f\"{model_name} - Class {class_label} attack accuracy: {class_accuracy:.3f}\")\n",
    "        \n",
    "        overall_accuracy = np.mean(attack_predictions)\n",
    "        print(f\"{model_name} - Overall attack accuracy: {overall_accuracy:.3f}\")\n",
    "        \n",
    "        return overall_accuracy, class_accuracies\n",
    "\n",
    "    target_attack_accuracy, target_class_accuracies = evaluate_per_class_attack(\n",
    "        target, X_forget_scaled, Y_forget, attack_models, attack_scalers, \"Target\"\n",
    "    )\n",
    "    \n",
    "    unlearn_attack_accuracy, unlearn_class_accuracies = evaluate_per_class_attack(\n",
    "        unlearn, X_forget_scaled, Y_forget, attack_models, attack_scalers, \"Unlearn\"\n",
    "    )\n",
    "\n",
    "    retain_metrics_original = calculate_model_metrics(target, scaler.transform(X_test_scale), Y_test, 'original_retain')\n",
    "    retain_metrics_unlearned = calculate_model_metrics(unlearn, X_test_unlearn_scale, Y_test_unlearn, 'unlearned_retain')\n",
    "    forget_metrics_original = calculate_model_metrics(target, scaler.transform(X_forget), Y_forget, 'original_forget')\n",
    "    forget_metrics_unlearned = calculate_model_metrics(unlearn, X_forget_scaled, Y_forget, 'unlearned_forget')\n",
    "\n",
    "    # Add per-class results to return\n",
    "    return {\n",
    "        'attack_models': attack_models,  # Now a dict of per-class models\n",
    "        'attack_scalers': attack_scalers,  # Now a dict of per-class scalers\n",
    "        'target_model': target,\n",
    "        'unlearned_model': unlearn,\n",
    "        'forget_set': forget,\n",
    "        'target_accuracy': target_attack_accuracy,\n",
    "        'unlearn_accuracy': unlearn_attack_accuracy,\n",
    "        'target_class_accuracies': target_class_accuracies,\n",
    "        'unlearn_class_accuracies': unlearn_class_accuracies,\n",
    "        'retain_metrics_original': retain_metrics_original,\n",
    "        'retain_metrics_unlearned': retain_metrics_unlearned,\n",
    "        'forget_metrics_original': forget_metrics_original,\n",
    "        'forget_metrics_unlearned': forget_metrics_unlearned,\n",
    "        'label_encoder': le,\n",
    "        'num_classes': len(le.classes_)\n",
    "    }'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def run_pipeline(config):\\n    scaler = StandardScaler()\\n\\n    train_data, test_data = train_test_split(loan_data, test_size=0.4, random_state=config[\\'random_seed\\'], stratify=loan_data[\\'loan_status\\'])\\n\\n    # CREATE MULTI-CLASS TARGET: Convert loan_status + loan_grade into multi-class\\n    # Assume you have loan_grade column with values like \\'A\\', \\'B\\', \\'C\\', \\'D\\', etc.\\n    \\n    # Option 1: Combine loan_status with another categorical feature\\n    if \\'loan_grade\\' in train_data.columns:\\n        # Create 4-6 classes by combining loan_status (0,1) with loan_grade (A,B,C)\\n        train_data[\\'multi_class\\'] = train_data[\\'loan_status\\'].astype(str) + \\'_\\' + train_data[\\'loan_grade\\'].astype(str)\\n        test_data[\\'multi_class\\'] = test_data[\\'loan_status\\'].astype(str) + \\'_\\' + test_data[\\'loan_grade\\'].astype(str)\\n    else:\\n        # Option 2: Create classes based on loan_int_rate quartiles\\n        train_data[\\'rate_quartile\\'] = pd.qcut(train_data[\\'loan_int_rate\\'], q=4, labels=[\\'Low\\', \\'Med\\', \\'High\\', \\'VHigh\\'])\\n        test_data[\\'rate_quartile\\'] = pd.qcut(test_data[\\'loan_int_rate\\'], q=4, labels=[\\'Low\\', \\'Med\\', \\'High\\', \\'VHigh\\'])\\n        \\n        # Combine loan_status with rate quartiles for 8 classes\\n        train_data[\\'multi_class\\'] = train_data[\\'loan_status\\'].astype(str) + \\'_\\' + train_data[\\'rate_quartile\\'].astype(str)\\n        test_data[\\'multi_class\\'] = test_data[\\'loan_status\\'].astype(str) + \\'_\\' + test_data[\\'rate_quartile\\'].astype(str)\\n    \\n    # Encode to numeric\\n    from sklearn.preprocessing import LabelEncoder\\n    le = LabelEncoder()\\n    all_classes = pd.concat([train_data[\\'multi_class\\'], test_data[\\'multi_class\\']])\\n    le.fit(all_classes)\\n    \\n    train_data[\\'target\\'] = le.transform(train_data[\\'multi_class\\'])\\n    test_data[\\'target\\'] = le.transform(test_data[\\'multi_class\\'])\\n    \\n    print(f\"Created {len(le.classes_)} classes: {le.classes_}\")\\n    \\n    # Define forget set based on original criteria but use new target\\n    rate_threshold = train_data[\\'loan_int_rate\\'].quantile(config[\\'forget_percentile\\'])\\n    percent_income_threshold = train_data[\\'loan_percent_income\\'].quantile(config[\\'forget_percentile\\'])\\n    loan_amnt_threshold = train_data[\\'loan_amnt\\'].quantile(config[\\'forget_percentile\\'])\\n\\n    forget = train_data[(train_data[\\'loan_int_rate\\'] >= rate_threshold) |\\n                (train_data[\\'loan_percent_income\\'] >= percent_income_threshold) |\\n                (train_data[\\'loan_amnt\\'] >= loan_amnt_threshold)]\\n\\n    X_forget = forget.drop(columns=[\\'loan_status\\', \\'multi_class\\', \\'target\\'])\\n    if \\'rate_quartile\\' in X_forget.columns:\\n        X_forget = X_forget.drop(columns=[\\'rate_quartile\\'])\\n    Y_forget = forget[\\'target\\']\\n\\n    target = LogisticRegression(C=10000, max_iter=10000)\\n\\n    X = train_data.drop([\\'loan_status\\', \\'multi_class\\', \\'target\\'], axis=1)\\n    if \\'rate_quartile\\' in X.columns:\\n        X = X.drop([\\'rate_quartile\\'], axis=1)\\n    Y = train_data[\\'target\\']  # Use multi-class target\\n\\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=config[\\'random_seed\\'])\\n\\n    X_train, X_test, Y_train, Y_test = train_test_split(\\n        X_train, Y_train,\\n        train_size=900,\\n        random_state=config[\\'random_seed\\'],\\n        stratify=Y_train\\n    )\\n    \\n    X_train_scale = scaler.fit_transform(X_train)\\n    X_test_scale = scaler.transform(X_test)\\n\\n    target.fit(X_train_scale, Y_train)\\n    \\n    unlearn_scaler = StandardScaler()\\n    keep = train_data.drop(forget.index)\\n\\n    unlearn = LogisticRegression(C=10000, max_iter=10000)\\n\\n    X_unlearn = keep.drop([\\'loan_status\\', \\'multi_class\\', \\'target\\'], axis=1)\\n    if \\'rate_quartile\\' in X_unlearn.columns:\\n        X_unlearn = X_unlearn.drop([\\'rate_quartile\\'], axis=1)\\n    Y_unlearn = keep[\\'target\\']  # Use multi-class target\\n\\n    X_train_unlearn, X_test_unlearn, Y_train_unlearn, Y_test_unlearn = train_test_split(\\n        X_unlearn, Y_unlearn, test_size=.2, random_state=config[\\'random_seed\\'])\\n\\n    X_train_unlearn, X_test_unlearn, Y_train_unlearn, Y_test_unlearn = train_test_split(\\n        X_train_unlearn, Y_train_unlearn,\\n        train_size=900,\\n        random_state=config[\\'random_seed\\'],\\n        stratify=Y_train_unlearn\\n    )\\n\\n    X_train_unlearn_scale = unlearn_scaler.fit_transform(X_train_unlearn)\\n    X_test_unlearn_scale = unlearn_scaler.transform(X_test_unlearn)\\n\\n    unlearn.fit(X_train_unlearn_scale, Y_train_unlearn)\\n    X_forget_scaled = unlearn_scaler.transform(X_forget)\\n\\n    predictions = target.predict(X_forget_scaled)\\n    predictions_unlearn = unlearn.predict(X_forget_scaled)\\n\\n    # Shadow model setup\\n    num_shadow_models = config[\\'num_shadow_models\\']\\n    chunks = int(len(test_data)/num_shadow_models)\\n    shuffled_df = test_data.sample(frac=1, random_state=config[\\'random_seed\\']).reset_index(drop=True)\\n    shadow_sets = []\\n\\n    for num in range(num_shadow_models):\\n        start_index = int(chunks*num)\\n        end_index = int(start_index+chunks)\\n\\n        shadow_train, shadow_test = train_test_split(\\n            shuffled_df[start_index:end_index], test_size=.5, random_state=config[\\'random_seed\\'])\\n        shadow_sets.append((shadow_train, shadow_test))\\n\\n    shadow_models = []\\n    shadow_scaled_data = []\\n    shadow_scalers = []\\n    \\n    for num in range(num_shadow_models):\\n        shadow_scaler = StandardScaler()\\n        \\n        shadow_train = shadow_sets[num][0]\\n        X_shadow_train = shadow_train.drop([\\'loan_status\\', \\'multi_class\\', \\'target\\'], axis=1)\\n        if \\'rate_quartile\\' in X_shadow_train.columns:\\n            X_shadow_train = X_shadow_train.drop([\\'rate_quartile\\'], axis=1)\\n        Y_shadow_train = shadow_train[\\'target\\']  # Use multi-class target\\n\\n        X_shadow_train_scaled = shadow_scaler.fit_transform(X_shadow_train)\\n\\n        i = LogisticRegression(C=10000, max_iter=10000)\\n        i.fit(X_shadow_train_scaled, Y_shadow_train)\\n\\n        shadow_scalers.append(shadow_scaler)\\n        shadow_scaled_data.append((X_shadow_train_scaled, Y_shadow_train))\\n        shadow_models.append(i)\\n\\n    # SHOKRI APPROACH: Train separate attack models per class (WITH RAW VECTORS)\\n    # Collect member and non-member data per class\\n    class_member_features = {}\\n    class_member_labels = {}\\n    class_non_member_features = {}\\n    class_non_member_labels = {}\\n    \\n    # Initialize dictionaries for each class\\n    unique_classes = np.unique(np.concatenate([data[1] for data in shadow_scaled_data]))\\n    for class_label in unique_classes:\\n        class_member_features[class_label] = []\\n        class_member_labels[class_label] = []\\n        class_non_member_features[class_label] = []\\n        class_non_member_labels[class_label] = []\\n\\n    # Collect member data (training data from shadow models) PER CLASS\\n    for num in range(num_shadow_models):\\n        model = shadow_models[num]\\n        scaled_data = shadow_scaled_data[num][0]\\n        Y_data = shadow_scaled_data[num][1]\\n\\n        results = model.predict_proba(scaled_data)\\n\\n        # RAW PROBABILITY VECTORS (instead of engineered features)\\n        attack_features = results  # Shape: (n_samples, n_classes)\\n        \\n        # Group by true class\\n        for class_label in unique_classes:\\n            class_mask = (Y_data == class_label)\\n            if np.sum(class_mask) > 0:\\n                class_member_features[class_label].append(attack_features[class_mask])\\n                class_member_labels[class_label].append(np.ones(np.sum(class_mask)))\\n\\n    # Collect non-member data (test data from shadow models) PER CLASS\\n    for num in range(num_shadow_models):\\n        model = shadow_models[num]\\n        test_set = shadow_sets[num][1]\\n        scaler = shadow_scalers[num]\\n\\n        X_test = test_set.drop([\\'loan_status\\', \\'multi_class\\', \\'target\\'], axis=1)\\n        if \\'rate_quartile\\' in X_test.columns:\\n            X_test = X_test.drop([\\'rate_quartile\\'], axis=1)\\n        Y_data_test = test_set[\\'target\\']  # Use multi-class target\\n        X_test_scaled = scaler.transform(X_test)\\n\\n        results = model.predict_proba(X_test_scaled)\\n\\n        # RAW PROBABILITY VECTORS (instead of engineered features)\\n        attack_features = results  # Shape: (n_samples, n_classes)\\n        \\n        # Group by true class\\n        for class_label in unique_classes:\\n            class_mask = (Y_data_test == class_label)\\n            if np.sum(class_mask) > 0:\\n                class_non_member_features[class_label].append(attack_features[class_mask])\\n                class_non_member_labels[class_label].append(np.zeros(np.sum(class_mask)))\\n\\n    # Train separate attack models per class (SHOKRI APPROACH WITH RAW VECTORS)\\n    attack_models = {}\\n    attack_scalers = {}\\n\\n    for class_label in unique_classes:\\n        print(f\"Training attack model for class {class_label}\")\\n        \\n        if class_member_features[class_label] and class_non_member_features[class_label]:\\n            # Combine member and non-member data for this class\\n            X_attack_class = np.vstack(class_member_features[class_label] + class_non_member_features[class_label])\\n            y_attack_class = np.hstack(class_member_labels[class_label] + class_non_member_labels[class_label])\\n\\n            # Train/test split for this class\\n            X_train_attack, X_test_attack, y_train_attack, y_test_attack = train_test_split(\\n                X_attack_class, y_attack_class, test_size=0.3, random_state=config[\\'random_seed\\'], \\n                stratify=y_attack_class\\n            )\\n\\n            # Scale and train attack model for this class\\n            attack_scaler_class = StandardScaler()\\n            X_train_attack_scaled = attack_scaler_class.fit_transform(X_train_attack)\\n            X_test_attack_scaled = attack_scaler_class.transform(X_test_attack)\\n\\n            attack_class = LogisticRegression(max_iter=1000)\\n            attack_class.fit(X_train_attack_scaled, y_train_attack)\\n\\n            print(f\"Class {class_label} attack accuracy: {attack_class.score(X_test_attack_scaled, y_test_attack):.3f}\")\\n\\n            attack_models[class_label] = attack_class\\n            attack_scalers[class_label] = attack_scaler_class\\n        else:\\n            print(f\"Insufficient data for class {class_label}\")\\n    \\n    # SHOKRI EVALUATION: Use per-class attack models (WITH RAW VECTORS)\\n    def evaluate_per_class_attack(model, X_scaled, Y_true, attack_models, attack_scalers, model_name):\\n        results = model.predict_proba(X_scaled)\\n        \\n        # RAW PROBABILITY VECTORS for evaluation (instead of engineered features)\\n        attack_features = results  # Shape: (n_samples, n_classes)\\n        \\n        attack_predictions = []\\n        class_accuracies = {}\\n        \\n        for i, true_class in enumerate(Y_true):\\n            if true_class in attack_models:\\n                class_attack = attack_models[true_class]\\n                class_scaler = attack_scalers[true_class]\\n                \\n                sample_features = attack_features[i:i+1]  # Single sample\\n                sample_scaled = class_scaler.transform(sample_features)\\n                prediction = class_attack.predict(sample_scaled)[0]\\n                attack_predictions.append(prediction)\\n            else:\\n                attack_predictions.append(0)  # Default if no attack model for class\\n        \\n        # Calculate per-class accuracies\\n        for class_label in attack_models.keys():\\n            class_mask = (Y_true == class_label)\\n            if np.sum(class_mask) > 0:\\n                class_preds = np.array(attack_predictions)[class_mask]\\n                # For target model, we expect all predictions to be 1 (member)\\n                # For unlearn model, we expect predictions to be closer to 0 (non-member)\\n                class_accuracy = np.mean(class_preds)\\n                class_accuracies[class_label] = class_accuracy\\n                print(f\"{model_name} - Class {class_label} attack accuracy: {class_accuracy:.3f}\")\\n        \\n        overall_accuracy = np.mean(attack_predictions)\\n        print(f\"{model_name} - Overall attack accuracy: {overall_accuracy:.3f}\")\\n        \\n        return overall_accuracy, class_accuracies\\n\\n    target_attack_accuracy, target_class_accuracies = evaluate_per_class_attack(\\n        target, X_forget_scaled, Y_forget, attack_models, attack_scalers, \"Target\"\\n    )\\n    \\n    unlearn_attack_accuracy, unlearn_class_accuracies = evaluate_per_class_attack(\\n        unlearn, X_forget_scaled, Y_forget, attack_models, attack_scalers, \"Unlearn\"\\n    )\\n\\n    retain_metrics_original = calculate_model_metrics(target, scaler.transform(X_test_scale), Y_test, \\'original_retain\\')\\n    retain_metrics_unlearned = calculate_model_metrics(unlearn, X_test_unlearn_scale, Y_test_unlearn, \\'unlearned_retain\\')\\n    forget_metrics_original = calculate_model_metrics(target, scaler.transform(X_forget), Y_forget, \\'original_forget\\')\\n    forget_metrics_unlearned = calculate_model_metrics(unlearn, X_forget_scaled, Y_forget, \\'unlearned_forget\\')\\n\\n    # Add per-class results to return\\n    return {\\n        \\'attack_models\\': attack_models,  # Now a dict of per-class models\\n        \\'attack_scalers\\': attack_scalers,  # Now a dict of per-class scalers\\n        \\'target_model\\': target,\\n        \\'unlearned_model\\': unlearn,\\n        \\'forget_set\\': forget,\\n        \\'target_accuracy\\': target_attack_accuracy,\\n        \\'unlearn_accuracy\\': unlearn_attack_accuracy,\\n        \\'target_class_accuracies\\': target_class_accuracies,\\n        \\'unlearn_class_accuracies\\': unlearn_class_accuracies,\\n        \\'retain_metrics_original\\': retain_metrics_original,\\n        \\'retain_metrics_unlearned\\': retain_metrics_unlearned,\\n        \\'forget_metrics_original\\': forget_metrics_original,\\n        \\'forget_metrics_unlearned\\': forget_metrics_unlearned,\\n        \\'label_encoder\\': le,\\n        \\'num_classes\\': len(le.classes_)\\n    }'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#per class multi class raw\n",
    "'''def run_pipeline(config):\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    train_data, test_data = train_test_split(loan_data, test_size=0.4, random_state=config['random_seed'], stratify=loan_data['loan_status'])\n",
    "\n",
    "    # CREATE MULTI-CLASS TARGET: Convert loan_status + loan_grade into multi-class\n",
    "    # Assume you have loan_grade column with values like 'A', 'B', 'C', 'D', etc.\n",
    "    \n",
    "    # Option 1: Combine loan_status with another categorical feature\n",
    "    if 'loan_grade' in train_data.columns:\n",
    "        # Create 4-6 classes by combining loan_status (0,1) with loan_grade (A,B,C)\n",
    "        train_data['multi_class'] = train_data['loan_status'].astype(str) + '_' + train_data['loan_grade'].astype(str)\n",
    "        test_data['multi_class'] = test_data['loan_status'].astype(str) + '_' + test_data['loan_grade'].astype(str)\n",
    "    else:\n",
    "        # Option 2: Create classes based on loan_int_rate quartiles\n",
    "        train_data['rate_quartile'] = pd.qcut(train_data['loan_int_rate'], q=4, labels=['Low', 'Med', 'High', 'VHigh'])\n",
    "        test_data['rate_quartile'] = pd.qcut(test_data['loan_int_rate'], q=4, labels=['Low', 'Med', 'High', 'VHigh'])\n",
    "        \n",
    "        # Combine loan_status with rate quartiles for 8 classes\n",
    "        train_data['multi_class'] = train_data['loan_status'].astype(str) + '_' + train_data['rate_quartile'].astype(str)\n",
    "        test_data['multi_class'] = test_data['loan_status'].astype(str) + '_' + test_data['rate_quartile'].astype(str)\n",
    "    \n",
    "    # Encode to numeric\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    all_classes = pd.concat([train_data['multi_class'], test_data['multi_class']])\n",
    "    le.fit(all_classes)\n",
    "    \n",
    "    train_data['target'] = le.transform(train_data['multi_class'])\n",
    "    test_data['target'] = le.transform(test_data['multi_class'])\n",
    "    \n",
    "    print(f\"Created {len(le.classes_)} classes: {le.classes_}\")\n",
    "    \n",
    "    # Define forget set based on original criteria but use new target\n",
    "    rate_threshold = train_data['loan_int_rate'].quantile(config['forget_percentile'])\n",
    "    percent_income_threshold = train_data['loan_percent_income'].quantile(config['forget_percentile'])\n",
    "    loan_amnt_threshold = train_data['loan_amnt'].quantile(config['forget_percentile'])\n",
    "\n",
    "    forget = train_data[(train_data['loan_int_rate'] >= rate_threshold) |\n",
    "                (train_data['loan_percent_income'] >= percent_income_threshold) |\n",
    "                (train_data['loan_amnt'] >= loan_amnt_threshold)]\n",
    "\n",
    "    X_forget = forget.drop(columns=['loan_status', 'multi_class', 'target'])\n",
    "    if 'rate_quartile' in X_forget.columns:\n",
    "        X_forget = X_forget.drop(columns=['rate_quartile'])\n",
    "    Y_forget = forget['target']\n",
    "\n",
    "    target = LogisticRegression(C=10000, max_iter=10000)\n",
    "\n",
    "    X = train_data.drop(['loan_status', 'multi_class', 'target'], axis=1)\n",
    "    if 'rate_quartile' in X.columns:\n",
    "        X = X.drop(['rate_quartile'], axis=1)\n",
    "    Y = train_data['target']  # Use multi-class target\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=config['random_seed'])\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X_train, Y_train,\n",
    "        train_size=900,\n",
    "        random_state=config['random_seed'],\n",
    "        stratify=Y_train\n",
    "    )\n",
    "    \n",
    "    X_train_scale = scaler.fit_transform(X_train)\n",
    "    X_test_scale = scaler.transform(X_test)\n",
    "\n",
    "    target.fit(X_train_scale, Y_train)\n",
    "    \n",
    "    unlearn_scaler = StandardScaler()\n",
    "    keep = train_data.drop(forget.index)\n",
    "\n",
    "    unlearn = LogisticRegression(C=10000, max_iter=10000)\n",
    "\n",
    "    X_unlearn = keep.drop(['loan_status', 'multi_class', 'target'], axis=1)\n",
    "    if 'rate_quartile' in X_unlearn.columns:\n",
    "        X_unlearn = X_unlearn.drop(['rate_quartile'], axis=1)\n",
    "    Y_unlearn = keep['target']  # Use multi-class target\n",
    "\n",
    "    X_train_unlearn, X_test_unlearn, Y_train_unlearn, Y_test_unlearn = train_test_split(\n",
    "        X_unlearn, Y_unlearn, test_size=.2, random_state=config['random_seed'])\n",
    "\n",
    "    X_train_unlearn, X_test_unlearn, Y_train_unlearn, Y_test_unlearn = train_test_split(\n",
    "        X_train_unlearn, Y_train_unlearn,\n",
    "        train_size=900,\n",
    "        random_state=config['random_seed'],\n",
    "        stratify=Y_train_unlearn\n",
    "    )\n",
    "\n",
    "    X_train_unlearn_scale = unlearn_scaler.fit_transform(X_train_unlearn)\n",
    "    X_test_unlearn_scale = unlearn_scaler.transform(X_test_unlearn)\n",
    "\n",
    "    unlearn.fit(X_train_unlearn_scale, Y_train_unlearn)\n",
    "    X_forget_scaled = unlearn_scaler.transform(X_forget)\n",
    "\n",
    "    predictions = target.predict(X_forget_scaled)\n",
    "    predictions_unlearn = unlearn.predict(X_forget_scaled)\n",
    "\n",
    "    # Shadow model setup\n",
    "    num_shadow_models = config['num_shadow_models']\n",
    "    chunks = int(len(test_data)/num_shadow_models)\n",
    "    shuffled_df = test_data.sample(frac=1, random_state=config['random_seed']).reset_index(drop=True)\n",
    "    shadow_sets = []\n",
    "\n",
    "    for num in range(num_shadow_models):\n",
    "        start_index = int(chunks*num)\n",
    "        end_index = int(start_index+chunks)\n",
    "\n",
    "        shadow_train, shadow_test = train_test_split(\n",
    "            shuffled_df[start_index:end_index], test_size=.5, random_state=config['random_seed'])\n",
    "        shadow_sets.append((shadow_train, shadow_test))\n",
    "\n",
    "    shadow_models = []\n",
    "    shadow_scaled_data = []\n",
    "    shadow_scalers = []\n",
    "    \n",
    "    for num in range(num_shadow_models):\n",
    "        shadow_scaler = StandardScaler()\n",
    "        \n",
    "        shadow_train = shadow_sets[num][0]\n",
    "        X_shadow_train = shadow_train.drop(['loan_status', 'multi_class', 'target'], axis=1)\n",
    "        if 'rate_quartile' in X_shadow_train.columns:\n",
    "            X_shadow_train = X_shadow_train.drop(['rate_quartile'], axis=1)\n",
    "        Y_shadow_train = shadow_train['target']  # Use multi-class target\n",
    "\n",
    "        X_shadow_train_scaled = shadow_scaler.fit_transform(X_shadow_train)\n",
    "\n",
    "        i = LogisticRegression(C=10000, max_iter=10000)\n",
    "        i.fit(X_shadow_train_scaled, Y_shadow_train)\n",
    "\n",
    "        shadow_scalers.append(shadow_scaler)\n",
    "        shadow_scaled_data.append((X_shadow_train_scaled, Y_shadow_train))\n",
    "        shadow_models.append(i)\n",
    "\n",
    "    # SHOKRI APPROACH: Train separate attack models per class (WITH RAW VECTORS)\n",
    "    # Collect member and non-member data per class\n",
    "    class_member_features = {}\n",
    "    class_member_labels = {}\n",
    "    class_non_member_features = {}\n",
    "    class_non_member_labels = {}\n",
    "    \n",
    "    # Initialize dictionaries for each class\n",
    "    unique_classes = np.unique(np.concatenate([data[1] for data in shadow_scaled_data]))\n",
    "    for class_label in unique_classes:\n",
    "        class_member_features[class_label] = []\n",
    "        class_member_labels[class_label] = []\n",
    "        class_non_member_features[class_label] = []\n",
    "        class_non_member_labels[class_label] = []\n",
    "\n",
    "    # Collect member data (training data from shadow models) PER CLASS\n",
    "    for num in range(num_shadow_models):\n",
    "        model = shadow_models[num]\n",
    "        scaled_data = shadow_scaled_data[num][0]\n",
    "        Y_data = shadow_scaled_data[num][1]\n",
    "\n",
    "        results = model.predict_proba(scaled_data)\n",
    "\n",
    "        # RAW PROBABILITY VECTORS (instead of engineered features)\n",
    "        attack_features = results  # Shape: (n_samples, n_classes)\n",
    "        \n",
    "        # Group by true class\n",
    "        for class_label in unique_classes:\n",
    "            class_mask = (Y_data == class_label)\n",
    "            if np.sum(class_mask) > 0:\n",
    "                class_member_features[class_label].append(attack_features[class_mask])\n",
    "                class_member_labels[class_label].append(np.ones(np.sum(class_mask)))\n",
    "\n",
    "    # Collect non-member data (test data from shadow models) PER CLASS\n",
    "    for num in range(num_shadow_models):\n",
    "        model = shadow_models[num]\n",
    "        test_set = shadow_sets[num][1]\n",
    "        scaler = shadow_scalers[num]\n",
    "\n",
    "        X_test = test_set.drop(['loan_status', 'multi_class', 'target'], axis=1)\n",
    "        if 'rate_quartile' in X_test.columns:\n",
    "            X_test = X_test.drop(['rate_quartile'], axis=1)\n",
    "        Y_data_test = test_set['target']  # Use multi-class target\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        results = model.predict_proba(X_test_scaled)\n",
    "\n",
    "        # RAW PROBABILITY VECTORS (instead of engineered features)\n",
    "        attack_features = results  # Shape: (n_samples, n_classes)\n",
    "        \n",
    "        # Group by true class\n",
    "        for class_label in unique_classes:\n",
    "            class_mask = (Y_data_test == class_label)\n",
    "            if np.sum(class_mask) > 0:\n",
    "                class_non_member_features[class_label].append(attack_features[class_mask])\n",
    "                class_non_member_labels[class_label].append(np.zeros(np.sum(class_mask)))\n",
    "\n",
    "    # Train separate attack models per class (SHOKRI APPROACH WITH RAW VECTORS)\n",
    "    attack_models = {}\n",
    "    attack_scalers = {}\n",
    "\n",
    "    for class_label in unique_classes:\n",
    "        print(f\"Training attack model for class {class_label}\")\n",
    "        \n",
    "        if class_member_features[class_label] and class_non_member_features[class_label]:\n",
    "            # Combine member and non-member data for this class\n",
    "            X_attack_class = np.vstack(class_member_features[class_label] + class_non_member_features[class_label])\n",
    "            y_attack_class = np.hstack(class_member_labels[class_label] + class_non_member_labels[class_label])\n",
    "\n",
    "            # Train/test split for this class\n",
    "            X_train_attack, X_test_attack, y_train_attack, y_test_attack = train_test_split(\n",
    "                X_attack_class, y_attack_class, test_size=0.3, random_state=config['random_seed'], \n",
    "                stratify=y_attack_class\n",
    "            )\n",
    "\n",
    "            # Scale and train attack model for this class\n",
    "            attack_scaler_class = StandardScaler()\n",
    "            X_train_attack_scaled = attack_scaler_class.fit_transform(X_train_attack)\n",
    "            X_test_attack_scaled = attack_scaler_class.transform(X_test_attack)\n",
    "\n",
    "            attack_class = LogisticRegression(max_iter=1000)\n",
    "            attack_class.fit(X_train_attack_scaled, y_train_attack)\n",
    "\n",
    "            print(f\"Class {class_label} attack accuracy: {attack_class.score(X_test_attack_scaled, y_test_attack):.3f}\")\n",
    "\n",
    "            attack_models[class_label] = attack_class\n",
    "            attack_scalers[class_label] = attack_scaler_class\n",
    "        else:\n",
    "            print(f\"Insufficient data for class {class_label}\")\n",
    "    \n",
    "    # SHOKRI EVALUATION: Use per-class attack models (WITH RAW VECTORS)\n",
    "    def evaluate_per_class_attack(model, X_scaled, Y_true, attack_models, attack_scalers, model_name):\n",
    "        results = model.predict_proba(X_scaled)\n",
    "        \n",
    "        # RAW PROBABILITY VECTORS for evaluation (instead of engineered features)\n",
    "        attack_features = results  # Shape: (n_samples, n_classes)\n",
    "        \n",
    "        attack_predictions = []\n",
    "        class_accuracies = {}\n",
    "        \n",
    "        for i, true_class in enumerate(Y_true):\n",
    "            if true_class in attack_models:\n",
    "                class_attack = attack_models[true_class]\n",
    "                class_scaler = attack_scalers[true_class]\n",
    "                \n",
    "                sample_features = attack_features[i:i+1]  # Single sample\n",
    "                sample_scaled = class_scaler.transform(sample_features)\n",
    "                prediction = class_attack.predict(sample_scaled)[0]\n",
    "                attack_predictions.append(prediction)\n",
    "            else:\n",
    "                attack_predictions.append(0)  # Default if no attack model for class\n",
    "        \n",
    "        # Calculate per-class accuracies\n",
    "        for class_label in attack_models.keys():\n",
    "            class_mask = (Y_true == class_label)\n",
    "            if np.sum(class_mask) > 0:\n",
    "                class_preds = np.array(attack_predictions)[class_mask]\n",
    "                # For target model, we expect all predictions to be 1 (member)\n",
    "                # For unlearn model, we expect predictions to be closer to 0 (non-member)\n",
    "                class_accuracy = np.mean(class_preds)\n",
    "                class_accuracies[class_label] = class_accuracy\n",
    "                print(f\"{model_name} - Class {class_label} attack accuracy: {class_accuracy:.3f}\")\n",
    "        \n",
    "        overall_accuracy = np.mean(attack_predictions)\n",
    "        print(f\"{model_name} - Overall attack accuracy: {overall_accuracy:.3f}\")\n",
    "        \n",
    "        return overall_accuracy, class_accuracies\n",
    "\n",
    "    target_attack_accuracy, target_class_accuracies = evaluate_per_class_attack(\n",
    "        target, X_forget_scaled, Y_forget, attack_models, attack_scalers, \"Target\"\n",
    "    )\n",
    "    \n",
    "    unlearn_attack_accuracy, unlearn_class_accuracies = evaluate_per_class_attack(\n",
    "        unlearn, X_forget_scaled, Y_forget, attack_models, attack_scalers, \"Unlearn\"\n",
    "    )\n",
    "\n",
    "    retain_metrics_original = calculate_model_metrics(target, scaler.transform(X_test_scale), Y_test, 'original_retain')\n",
    "    retain_metrics_unlearned = calculate_model_metrics(unlearn, X_test_unlearn_scale, Y_test_unlearn, 'unlearned_retain')\n",
    "    forget_metrics_original = calculate_model_metrics(target, scaler.transform(X_forget), Y_forget, 'original_forget')\n",
    "    forget_metrics_unlearned = calculate_model_metrics(unlearn, X_forget_scaled, Y_forget, 'unlearned_forget')\n",
    "\n",
    "    # Add per-class results to return\n",
    "    return {\n",
    "        'attack_models': attack_models,  # Now a dict of per-class models\n",
    "        'attack_scalers': attack_scalers,  # Now a dict of per-class scalers\n",
    "        'target_model': target,\n",
    "        'unlearned_model': unlearn,\n",
    "        'forget_set': forget,\n",
    "        'target_accuracy': target_attack_accuracy,\n",
    "        'unlearn_accuracy': unlearn_attack_accuracy,\n",
    "        'target_class_accuracies': target_class_accuracies,\n",
    "        'unlearn_class_accuracies': unlearn_class_accuracies,\n",
    "        'retain_metrics_original': retain_metrics_original,\n",
    "        'retain_metrics_unlearned': retain_metrics_unlearned,\n",
    "        'forget_metrics_original': forget_metrics_original,\n",
    "        'forget_metrics_unlearned': forget_metrics_unlearned,\n",
    "        'label_encoder': le,\n",
    "        'num_classes': len(le.classes_)\n",
    "    }'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def calculate_model_metrics(model, X_scaled, y_true, model_name):\\n    predictions = model.predict(X_scaled)\\n    probabilities = model.predict_proba(X_scaled)\\n    \\n    # Determine if binary or multi-class\\n    n_classes = len(np.unique(y_true))\\n    \\n    if n_classes == 2:\\n        # Binary classification - use original logic\\n        probs_positive = probabilities[:, 1]  \\n        metrics = {\\n            f'{model_name}_accuracy': accuracy_score(y_true, predictions),\\n            f'{model_name}_f1': f1_score(y_true, predictions),\\n            f'{model_name}_auc': roc_auc_score(y_true, probs_positive)\\n        }\\n    else:\\n        # Multi-class classification - use macro averaging\\n        metrics = {\\n            f'{model_name}_accuracy': accuracy_score(y_true, predictions),\\n            f'{model_name}_f1': f1_score(y_true, predictions, average='macro'),\\n            f'{model_name}_auc': roc_auc_score(y_true, probabilities, multi_class='ovr', average='macro')\\n        }\\n    \\n    return metrics\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def calculate_model_metrics(model, X_scaled, y_true, model_name):\n",
    "    predictions = model.predict(X_scaled)\n",
    "    probabilities = model.predict_proba(X_scaled)\n",
    "    \n",
    "    # Determine if binary or multi-class\n",
    "    n_classes = len(np.unique(y_true))\n",
    "    \n",
    "    if n_classes == 2:\n",
    "        # Binary classification - use original logic\n",
    "        probs_positive = probabilities[:, 1]  \n",
    "        metrics = {\n",
    "            f'{model_name}_accuracy': accuracy_score(y_true, predictions),\n",
    "            f'{model_name}_f1': f1_score(y_true, predictions),\n",
    "            f'{model_name}_auc': roc_auc_score(y_true, probs_positive)\n",
    "        }\n",
    "    else:\n",
    "        # Multi-class classification - use macro averaging\n",
    "        metrics = {\n",
    "            f'{model_name}_accuracy': accuracy_score(y_true, predictions),\n",
    "            f'{model_name}_f1': f1_score(y_true, predictions, average='macro'),\n",
    "            f'{model_name}_auc': roc_auc_score(y_true, probabilities, multi_class='ovr', average='macro')\n",
    "        }\n",
    "    \n",
    "    return metrics'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training attack model for class 0\n",
      "Class 0 attack accuracy: 0.504\n",
      "Training attack model for class 1\n",
      "Class 1 attack accuracy: 0.531\n",
      "Target - Class 0 attack accuracy: 0.760\n",
      "Target - Class 1 attack accuracy: 0.181\n",
      "Target - Overall attack accuracy: 0.497\n",
      "Unlearn - Class 0 attack accuracy: 0.798\n",
      "Unlearn - Class 1 attack accuracy: 0.278\n",
      "Unlearn - Overall attack accuracy: 0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training attack model for class 0\n",
      "Class 0 attack accuracy: 0.504\n",
      "Training attack model for class 1\n",
      "Class 1 attack accuracy: 0.531\n",
      "Target - Class 0 attack accuracy: 0.756\n",
      "Target - Class 1 attack accuracy: 0.186\n",
      "Target - Overall attack accuracy: 0.478\n",
      "Unlearn - Class 0 attack accuracy: 0.836\n",
      "Unlearn - Class 1 attack accuracy: 0.235\n",
      "Unlearn - Overall attack accuracy: 0.543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training attack model for class 0\n",
      "Class 0 attack accuracy: 0.504\n",
      "Training attack model for class 1\n",
      "Class 1 attack accuracy: 0.531\n",
      "Target - Class 0 attack accuracy: 0.757\n",
      "Target - Class 1 attack accuracy: 0.183\n",
      "Target - Overall attack accuracy: 0.462\n",
      "Unlearn - Class 0 attack accuracy: 0.815\n",
      "Unlearn - Class 1 attack accuracy: 0.410\n",
      "Unlearn - Overall attack accuracy: 0.607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training attack model for class 0\n",
      "Class 0 attack accuracy: 0.504\n",
      "Training attack model for class 1\n",
      "Class 1 attack accuracy: 0.531\n",
      "Target - Class 0 attack accuracy: 0.763\n",
      "Target - Class 1 attack accuracy: 0.190\n",
      "Target - Overall attack accuracy: 0.461\n",
      "Unlearn - Class 0 attack accuracy: 0.804\n",
      "Unlearn - Class 1 attack accuracy: 0.415\n",
      "Unlearn - Overall attack accuracy: 0.599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training attack model for class 0\n",
      "Class 0 attack accuracy: 0.504\n",
      "Training attack model for class 1\n",
      "Class 1 attack accuracy: 0.531\n",
      "Target - Class 0 attack accuracy: 0.763\n",
      "Target - Class 1 attack accuracy: 0.235\n",
      "Target - Overall attack accuracy: 0.492\n",
      "Unlearn - Class 0 attack accuracy: 0.808\n",
      "Unlearn - Class 1 attack accuracy: 0.339\n",
      "Unlearn - Overall attack accuracy: 0.567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training attack model for class 0\n",
      "Class 0 attack accuracy: 0.504\n",
      "Training attack model for class 1\n",
      "Class 1 attack accuracy: 0.531\n",
      "Target - Class 0 attack accuracy: 0.762\n",
      "Target - Class 1 attack accuracy: 0.225\n",
      "Target - Overall attack accuracy: 0.455\n",
      "Unlearn - Class 0 attack accuracy: 0.821\n",
      "Unlearn - Class 1 attack accuracy: 0.343\n",
      "Unlearn - Overall attack accuracy: 0.548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training attack model for class 0\n",
      "Class 0 attack accuracy: 0.504\n",
      "Training attack model for class 1\n",
      "Class 1 attack accuracy: 0.531\n",
      "Target - Class 0 attack accuracy: 0.761\n",
      "Target - Class 1 attack accuracy: 0.241\n",
      "Target - Overall attack accuracy: 0.466\n",
      "Unlearn - Class 0 attack accuracy: 0.782\n",
      "Unlearn - Class 1 attack accuracy: 0.272\n",
      "Unlearn - Overall attack accuracy: 0.493\n",
      "  percentile  forget_size original_attack unlearned_attack improvement\n",
      "0       85th         9362           49.7%            56.1%       -6.4%\n",
      "1       87th         8368           47.8%            54.3%       -6.6%\n",
      "2       89th         7243           46.2%            60.7%      -14.5%\n",
      "3       91th         6244           46.1%            59.9%      -13.8%\n",
      "4       93th         5387           49.2%            56.7%       -7.5%\n",
      "5       95th         3635           45.5%            54.8%       -9.3%\n",
      "6       97th         2400           46.6%            49.3%       -2.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "scenarios = [\n",
    "    { 'random_seed':42, 'num_shadow_models':10, 'forget_percentile': 0.85},\n",
    "    { 'random_seed':42, 'num_shadow_models':10, 'forget_percentile': 0.87},\n",
    "    { 'random_seed':42, 'num_shadow_models':10, 'forget_percentile': 0.89},\n",
    "    { 'random_seed':42, 'num_shadow_models':10, 'forget_percentile': 0.91},\n",
    "    { 'random_seed':42, 'num_shadow_models':10, 'forget_percentile': 0.93},\n",
    "    { 'random_seed':42, 'num_shadow_models':10, 'forget_percentile': 0.95},\n",
    "    { 'random_seed':42, 'num_shadow_models':10, 'forget_percentile': 0.97}\n",
    "]\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for scenario in scenarios:\n",
    "    results = run_pipeline(scenario)\n",
    "    all_results.append({\n",
    "        'percentile': f\"{scenario['forget_percentile']*100:.0f}th\",\n",
    "        'forget_size': len(results['forget_set']),\n",
    "        'original_attack': f\"{results['target_accuracy']*100:.1f}%\",\n",
    "        'unlearned_attack': f\"{results['unlearn_accuracy']*100:.1f}%\",\n",
    "        'improvement': f\"{(results['target_accuracy'] - results['unlearn_accuracy']) * 100:.1f}%\"\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(all_results)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training attack model for class 0\n",
      "Class 0 attack accuracy: 0.504\n",
      "Training attack model for class 1\n",
      "Class 1 attack accuracy: 0.531\n",
      "Target - Class 0 attack accuracy: 0.760\n",
      "Target - Class 1 attack accuracy: 0.181\n",
      "Target - Overall attack accuracy: 0.497\n",
      "Unlearn - Class 0 attack accuracy: 0.798\n",
      "Unlearn - Class 1 attack accuracy: 0.278\n",
      "Unlearn - Overall attack accuracy: 0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training attack model for class 0\n",
      "Class 0 attack accuracy: 0.504\n",
      "Training attack model for class 1\n",
      "Class 1 attack accuracy: 0.531\n",
      "Target - Class 0 attack accuracy: 0.760\n",
      "Target - Class 1 attack accuracy: 0.185\n",
      "Target - Overall attack accuracy: 0.453\n",
      "Unlearn - Class 0 attack accuracy: 0.859\n",
      "Unlearn - Class 1 attack accuracy: 0.337\n",
      "Unlearn - Overall attack accuracy: 0.581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training attack model for class 0\n",
      "Class 0 attack accuracy: 0.504\n",
      "Training attack model for class 1\n",
      "Class 1 attack accuracy: 0.531\n",
      "Target - Class 0 attack accuracy: 0.762\n",
      "Target - Class 1 attack accuracy: 0.225\n",
      "Target - Overall attack accuracy: 0.455\n",
      "Unlearn - Class 0 attack accuracy: 0.821\n",
      "Unlearn - Class 1 attack accuracy: 0.343\n",
      "Unlearn - Overall attack accuracy: 0.548\n",
      "  percentile original_attack unlearned_attack improvement\n",
      "0       85th           49.7%            56.1%       -6.4%\n",
      "1       90th           45.3%            58.1%      -12.7%\n",
      "2       95th           45.5%            54.8%       -9.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "scenarios = [\n",
    "    {'random_seed': 42, 'forget_percentile': 0.85, 'num_shadow_models': 10},\n",
    "    { 'random_seed': 42,'forget_percentile': 0.90,'num_shadow_models': 10 },\n",
    "    {'random_seed': 42,'forget_percentile': 0.95, 'num_shadow_models': 10}\n",
    "]\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for scenario in scenarios:\n",
    "    results = run_pipeline(scenario)\n",
    "    all_results.append({\n",
    "    'percentile': f\"{scenario['forget_percentile']*100:.0f}th\",\n",
    "    #'forget_size': len(results['forget_set']),\n",
    "    'original_attack': f\"{results['target_accuracy']*100:.1f}%\",\n",
    "    'unlearned_attack': f\"{results['unlearn_accuracy']*100:.1f}%\",\n",
    "    'improvement': f\"{(results['target_accuracy']-results['unlearn_accuracy'])*100:.1f}%\",\n",
    "\n",
    "\n",
    "   #'retain_accuracy_original': f\"{results['retain_metrics_original']['original_retain_accuracy']*100:.1f}%\",\n",
    "    #'retain_f1_original': f\"{results['retain_metrics_original']['original_retain_f1']*100:.1f}%\",\n",
    "    #'retain_auc_original': f\"{results['retain_metrics_original']['original_retain_auc']*100:.1f}%\",\n",
    "\n",
    "\n",
    "    #'retain_accuracy_unlearned': f\"{results['retain_metrics_unlearned']['unlearned_retain_accuracy']*100:.1f}%\",\n",
    "    #'retain_f1_unlearned': f\"{results['retain_metrics_unlearned']['unlearned_retain_f1']*100:.1f}%\",\n",
    "    #'retain_auc_unlearned': f\"{results['retain_metrics_unlearned']['unlearned_retain_auc']*100:.1f}%\",\n",
    "    \n",
    "\n",
    "    #'forget_accuracy_original': f\"{results['forget_metrics_original']['original_forget_accuracy']*100:.1f}%\",\n",
    "    #'forget_f1_original': f\"{results['forget_metrics_original']['original_forget_f1']*100:.1f}%\",\n",
    "    #'forget_auc_original': f\"{results['forget_metrics_original']['original_forget_auc']*100:.1f}%\",\n",
    "    \n",
    "    #'forget_accuracy_unlearned': f\"{results['forget_metrics_unlearned']['unlearned_forget_accuracy']*100:.1f}%\",\n",
    "    #'forget_f1_unlearned': f\"{results['forget_metrics_unlearned']['unlearned_forget_f1']*100:.1f}%\",\n",
    "    #'forget_auc_unlearned': f\"{results['forget_metrics_unlearned']['unlearned_forget_auc']*100:.1f}%\",\n",
    "\n",
    "})\n",
    "\n",
    "df = pd.DataFrame(all_results)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training attack model for class 0\n",
      "Class 0 attack accuracy: 0.490\n",
      "Training attack model for class 1\n",
      "Class 1 attack accuracy: 0.507\n",
      "Target - Class 0 attack accuracy: 0.169\n",
      "Target - Class 1 attack accuracy: 0.864\n",
      "Target - Overall attack accuracy: 0.447\n",
      "Unlearn - Class 0 attack accuracy: 0.256\n",
      "Unlearn - Class 1 attack accuracy: 0.089\n",
      "Unlearn - Overall attack accuracy: 0.190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training attack model for class 0\n",
      "Class 0 attack accuracy: 0.504\n",
      "Training attack model for class 1\n",
      "Class 1 attack accuracy: 0.531\n",
      "Target - Class 0 attack accuracy: 0.753\n",
      "Target - Class 1 attack accuracy: 0.150\n",
      "Target - Overall attack accuracy: 0.512\n",
      "Unlearn - Class 0 attack accuracy: 0.824\n",
      "Unlearn - Class 1 attack accuracy: 0.245\n",
      "Unlearn - Overall attack accuracy: 0.593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training attack model for class 0\n",
      "Class 0 attack accuracy: 0.506\n",
      "Training attack model for class 1\n",
      "Class 1 attack accuracy: 0.517\n",
      "Target - Class 0 attack accuracy: 0.754\n",
      "Target - Class 1 attack accuracy: 0.285\n",
      "Target - Overall attack accuracy: 0.567\n",
      "Unlearn - Class 0 attack accuracy: 0.972\n",
      "Unlearn - Class 1 attack accuracy: 0.630\n",
      "Unlearn - Overall attack accuracy: 0.836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training attack model for class 0\n",
      "Class 0 attack accuracy: 0.490\n",
      "Training attack model for class 1\n",
      "Class 1 attack accuracy: 0.507\n",
      "Target - Class 0 attack accuracy: 0.169\n",
      "Target - Class 1 attack accuracy: 0.864\n",
      "Target - Overall attack accuracy: 0.447\n",
      "Unlearn - Class 0 attack accuracy: 0.256\n",
      "Unlearn - Class 1 attack accuracy: 0.089\n",
      "Unlearn - Overall attack accuracy: 0.190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training attack model for class 0\n",
      "Class 0 attack accuracy: 0.504\n",
      "Training attack model for class 1\n",
      "Class 1 attack accuracy: 0.531\n",
      "Target - Class 0 attack accuracy: 0.753\n",
      "Target - Class 1 attack accuracy: 0.150\n",
      "Target - Overall attack accuracy: 0.512\n",
      "Unlearn - Class 0 attack accuracy: 0.824\n",
      "Unlearn - Class 1 attack accuracy: 0.245\n",
      "Unlearn - Overall attack accuracy: 0.593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training attack model for class 0\n",
      "Class 0 attack accuracy: 0.506\n",
      "Training attack model for class 1\n",
      "Class 1 attack accuracy: 0.517\n",
      "Target - Class 0 attack accuracy: 0.754\n",
      "Target - Class 1 attack accuracy: 0.285\n",
      "Target - Overall attack accuracy: 0.567\n",
      "Unlearn - Class 0 attack accuracy: 0.972\n",
      "Unlearn - Class 1 attack accuracy: 0.630\n",
      "Unlearn - Overall attack accuracy: 0.836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training attack model for class 0\n",
      "Class 0 attack accuracy: 0.490\n",
      "Training attack model for class 1\n",
      "Class 1 attack accuracy: 0.507\n",
      "Target - Class 0 attack accuracy: 0.169\n",
      "Target - Class 1 attack accuracy: 0.864\n",
      "Target - Overall attack accuracy: 0.447\n",
      "Unlearn - Class 0 attack accuracy: 0.256\n",
      "Unlearn - Class 1 attack accuracy: 0.089\n",
      "Unlearn - Overall attack accuracy: 0.190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training attack model for class 0\n",
      "Class 0 attack accuracy: 0.504\n",
      "Training attack model for class 1\n",
      "Class 1 attack accuracy: 0.531\n",
      "Target - Class 0 attack accuracy: 0.753\n",
      "Target - Class 1 attack accuracy: 0.150\n",
      "Target - Overall attack accuracy: 0.512\n",
      "Unlearn - Class 0 attack accuracy: 0.824\n",
      "Unlearn - Class 1 attack accuracy: 0.245\n",
      "Unlearn - Overall attack accuracy: 0.593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training attack model for class 0\n",
      "Class 0 attack accuracy: 0.506\n",
      "Training attack model for class 1\n",
      "Class 1 attack accuracy: 0.517\n",
      "Target - Class 0 attack accuracy: 0.754\n",
      "Target - Class 1 attack accuracy: 0.285\n",
      "Target - Overall attack accuracy: 0.567\n",
      "Unlearn - Class 0 attack accuracy: 0.972\n",
      "Unlearn - Class 1 attack accuracy: 0.630\n",
      "Unlearn - Overall attack accuracy: 0.836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training attack model for class 0\n",
      "Class 0 attack accuracy: 0.490\n",
      "Training attack model for class 1\n",
      "Class 1 attack accuracy: 0.507\n",
      "Target - Class 0 attack accuracy: 0.169\n",
      "Target - Class 1 attack accuracy: 0.864\n",
      "Target - Overall attack accuracy: 0.447\n",
      "Unlearn - Class 0 attack accuracy: 0.256\n",
      "Unlearn - Class 1 attack accuracy: 0.089\n",
      "Unlearn - Overall attack accuracy: 0.190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training attack model for class 0\n",
      "Class 0 attack accuracy: 0.504\n",
      "Training attack model for class 1\n",
      "Class 1 attack accuracy: 0.531\n",
      "Target - Class 0 attack accuracy: 0.753\n",
      "Target - Class 1 attack accuracy: 0.150\n",
      "Target - Overall attack accuracy: 0.512\n",
      "Unlearn - Class 0 attack accuracy: 0.824\n",
      "Unlearn - Class 1 attack accuracy: 0.245\n",
      "Unlearn - Overall attack accuracy: 0.593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training attack model for class 0\n",
      "Class 0 attack accuracy: 0.506\n",
      "Training attack model for class 1\n",
      "Class 1 attack accuracy: 0.517\n",
      "Target - Class 0 attack accuracy: 0.754\n",
      "Target - Class 1 attack accuracy: 0.285\n",
      "Target - Overall attack accuracy: 0.567\n",
      "Unlearn - Class 0 attack accuracy: 0.972\n",
      "Unlearn - Class 1 attack accuracy: 0.630\n",
      "Unlearn - Overall attack accuracy: 0.836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training attack model for class 0\n",
      "Class 0 attack accuracy: 0.490\n",
      "Training attack model for class 1\n",
      "Class 1 attack accuracy: 0.507\n",
      "Target - Class 0 attack accuracy: 0.169\n",
      "Target - Class 1 attack accuracy: 0.864\n",
      "Target - Overall attack accuracy: 0.447\n",
      "Unlearn - Class 0 attack accuracy: 0.256\n",
      "Unlearn - Class 1 attack accuracy: 0.089\n",
      "Unlearn - Overall attack accuracy: 0.190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training attack model for class 0\n",
      "Class 0 attack accuracy: 0.504\n",
      "Training attack model for class 1\n",
      "Class 1 attack accuracy: 0.531\n",
      "Target - Class 0 attack accuracy: 0.753\n",
      "Target - Class 1 attack accuracy: 0.150\n",
      "Target - Overall attack accuracy: 0.512\n",
      "Unlearn - Class 0 attack accuracy: 0.824\n",
      "Unlearn - Class 1 attack accuracy: 0.245\n",
      "Unlearn - Overall attack accuracy: 0.593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training attack model for class 0\n",
      "Class 0 attack accuracy: 0.506\n",
      "Training attack model for class 1\n",
      "Class 1 attack accuracy: 0.517\n",
      "Target - Class 0 attack accuracy: 0.754\n",
      "Target - Class 1 attack accuracy: 0.285\n",
      "Target - Overall attack accuracy: 0.567\n",
      "Unlearn - Class 0 attack accuracy: 0.972\n",
      "Unlearn - Class 1 attack accuracy: 0.630\n",
      "Unlearn - Overall attack accuracy: 0.836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training attack model for class 0\n",
      "Class 0 attack accuracy: 0.490\n",
      "Training attack model for class 1\n",
      "Class 1 attack accuracy: 0.507\n",
      "Target - Class 0 attack accuracy: 0.187\n",
      "Target - Class 1 attack accuracy: 0.843\n",
      "Target - Overall attack accuracy: 0.486\n",
      "Unlearn - Class 0 attack accuracy: 0.315\n",
      "Unlearn - Class 1 attack accuracy: 0.049\n",
      "Unlearn - Overall attack accuracy: 0.194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training attack model for class 0\n",
      "Class 0 attack accuracy: 0.504\n",
      "Training attack model for class 1\n",
      "Class 1 attack accuracy: 0.531\n",
      "Target - Class 0 attack accuracy: 0.760\n",
      "Target - Class 1 attack accuracy: 0.181\n",
      "Target - Overall attack accuracy: 0.497\n",
      "Unlearn - Class 0 attack accuracy: 0.798\n",
      "Unlearn - Class 1 attack accuracy: 0.278\n",
      "Unlearn - Overall attack accuracy: 0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training attack model for class 0\n",
      "Class 0 attack accuracy: 0.506\n",
      "Training attack model for class 1\n",
      "Class 1 attack accuracy: 0.517\n",
      "Target - Class 0 attack accuracy: 0.759\n",
      "Target - Class 1 attack accuracy: 0.338\n",
      "Target - Overall attack accuracy: 0.567\n",
      "Unlearn - Class 0 attack accuracy: 0.950\n",
      "Unlearn - Class 1 attack accuracy: 0.736\n",
      "Unlearn - Overall attack accuracy: 0.853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training attack model for class 0\n",
      "Class 0 attack accuracy: 0.490\n",
      "Training attack model for class 1\n",
      "Class 1 attack accuracy: 0.507\n",
      "Target - Class 0 attack accuracy: 0.187\n",
      "Target - Class 1 attack accuracy: 0.843\n",
      "Target - Overall attack accuracy: 0.486\n",
      "Unlearn - Class 0 attack accuracy: 0.315\n",
      "Unlearn - Class 1 attack accuracy: 0.049\n",
      "Unlearn - Overall attack accuracy: 0.194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training attack model for class 0\n",
      "Class 0 attack accuracy: 0.504\n",
      "Training attack model for class 1\n",
      "Class 1 attack accuracy: 0.531\n",
      "Target - Class 0 attack accuracy: 0.760\n",
      "Target - Class 1 attack accuracy: 0.181\n",
      "Target - Overall attack accuracy: 0.497\n",
      "Unlearn - Class 0 attack accuracy: 0.798\n",
      "Unlearn - Class 1 attack accuracy: 0.278\n",
      "Unlearn - Overall attack accuracy: 0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training attack model for class 0\n",
      "Class 0 attack accuracy: 0.506\n",
      "Training attack model for class 1\n",
      "Class 1 attack accuracy: 0.517\n",
      "Target - Class 0 attack accuracy: 0.759\n",
      "Target - Class 1 attack accuracy: 0.338\n",
      "Target - Overall attack accuracy: 0.567\n",
      "Unlearn - Class 0 attack accuracy: 0.950\n",
      "Unlearn - Class 1 attack accuracy: 0.736\n",
      "Unlearn - Overall attack accuracy: 0.853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training attack model for class 0\n",
      "Class 0 attack accuracy: 0.490\n",
      "Training attack model for class 1\n",
      "Class 1 attack accuracy: 0.507\n",
      "Target - Class 0 attack accuracy: 0.187\n",
      "Target - Class 1 attack accuracy: 0.843\n",
      "Target - Overall attack accuracy: 0.486\n",
      "Unlearn - Class 0 attack accuracy: 0.315\n",
      "Unlearn - Class 1 attack accuracy: 0.049\n",
      "Unlearn - Overall attack accuracy: 0.194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training attack model for class 0\n",
      "Class 0 attack accuracy: 0.504\n",
      "Training attack model for class 1\n",
      "Class 1 attack accuracy: 0.531\n",
      "Target - Class 0 attack accuracy: 0.760\n",
      "Target - Class 1 attack accuracy: 0.181\n",
      "Target - Overall attack accuracy: 0.497\n",
      "Unlearn - Class 0 attack accuracy: 0.798\n",
      "Unlearn - Class 1 attack accuracy: 0.278\n",
      "Unlearn - Overall attack accuracy: 0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training attack model for class 0\n",
      "Class 0 attack accuracy: 0.506\n",
      "Training attack model for class 1\n",
      "Class 1 attack accuracy: 0.517\n",
      "Target - Class 0 attack accuracy: 0.759\n",
      "Target - Class 1 attack accuracy: 0.338\n",
      "Target - Overall attack accuracy: 0.567\n",
      "Unlearn - Class 0 attack accuracy: 0.950\n",
      "Unlearn - Class 1 attack accuracy: 0.736\n",
      "Unlearn - Overall attack accuracy: 0.853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training attack model for class 0\n",
      "Class 0 attack accuracy: 0.490\n",
      "Training attack model for class 1\n",
      "Class 1 attack accuracy: 0.507\n",
      "Target - Class 0 attack accuracy: 0.187\n",
      "Target - Class 1 attack accuracy: 0.843\n",
      "Target - Overall attack accuracy: 0.486\n",
      "Unlearn - Class 0 attack accuracy: 0.315\n",
      "Unlearn - Class 1 attack accuracy: 0.049\n",
      "Unlearn - Overall attack accuracy: 0.194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training attack model for class 0\n",
      "Class 0 attack accuracy: 0.504\n",
      "Training attack model for class 1\n",
      "Class 1 attack accuracy: 0.531\n",
      "Target - Class 0 attack accuracy: 0.760\n",
      "Target - Class 1 attack accuracy: 0.181\n",
      "Target - Overall attack accuracy: 0.497\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, config \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(configs):\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m         \n\u001b[1;32m     18\u001b[0m         \u001b[38;5;66;03m# Run your pipeline\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m         result \u001b[38;5;241m=\u001b[39m run_pipeline(config)\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;66;03m# Store results with config info\u001b[39;00m\n\u001b[1;32m     22\u001b[0m         all_results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     23\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpercentile\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforget_percentile\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.0f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mth\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     24\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m'\u001b[39m: config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_seed\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforget_set_size\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforget_set\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     31\u001b[0m         })\n",
      "Cell \u001b[0;32mIn[54], line 277\u001b[0m, in \u001b[0;36mrun_pipeline\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m overall_accuracy, class_accuracies\n\u001b[1;32m    273\u001b[0m target_attack_accuracy, target_class_accuracies \u001b[38;5;241m=\u001b[39m evaluate_per_class_attack(\n\u001b[1;32m    274\u001b[0m     target, X_forget_scaled, Y_forget, attack_models, attack_scalers, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    275\u001b[0m )\n\u001b[0;32m--> 277\u001b[0m unlearn_attack_accuracy, unlearn_class_accuracies \u001b[38;5;241m=\u001b[39m evaluate_per_class_attack(\n\u001b[1;32m    278\u001b[0m     unlearn, X_forget_scaled, Y_forget, attack_models, attack_scalers, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnlearn\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m )\n\u001b[1;32m    281\u001b[0m \u001b[38;5;66;03m# Calculate metrics using binary-compatible function\u001b[39;00m\n\u001b[1;32m    282\u001b[0m retain_metrics_original \u001b[38;5;241m=\u001b[39m calculate_model_metrics(target, scaler\u001b[38;5;241m.\u001b[39mtransform(X_test_scale), Y_test, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal_retain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[54], line 251\u001b[0m, in \u001b[0;36mrun_pipeline.<locals>.evaluate_per_class_attack\u001b[0;34m(model, X_scaled, Y_true, attack_models, attack_scalers, model_name)\u001b[0m\n\u001b[1;32m    248\u001b[0m class_scaler \u001b[38;5;241m=\u001b[39m attack_scalers[true_class]\n\u001b[1;32m    250\u001b[0m sample_features \u001b[38;5;241m=\u001b[39m attack_features[i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Single sample\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m sample_scaled \u001b[38;5;241m=\u001b[39m class_scaler\u001b[38;5;241m.\u001b[39mtransform(sample_features)\n\u001b[1;32m    252\u001b[0m prediction \u001b[38;5;241m=\u001b[39m class_attack\u001b[38;5;241m.\u001b[39mpredict(sample_scaled)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    253\u001b[0m attack_predictions\u001b[38;5;241m.\u001b[39mappend(prediction)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    319\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:1045\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m   1042\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1044\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[0;32m-> 1045\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m   1046\u001b[0m     X,\n\u001b[1;32m   1047\u001b[0m     reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1048\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1049\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m   1050\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mFLOAT_DTYPES,\n\u001b[1;32m   1051\u001b[0m     force_writeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1052\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1053\u001b[0m )\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[1;32m   1056\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:1072\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1064\u001b[0m     _assert_all_finite(\n\u001b[1;32m   1065\u001b[0m         array,\n\u001b[1;32m   1066\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m   1067\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m   1068\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1069\u001b[0m     )\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m-> 1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m   1073\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n\u001b[1;32m   1074\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmay_share_memory(array, array_orig):\n\u001b[1;32m   1075\u001b[0m             array \u001b[38;5;241m=\u001b[39m _asarray_with_order(\n\u001b[1;32m   1076\u001b[0m                 array, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, xp\u001b[38;5;241m=\u001b[39mxp\n\u001b[1;32m   1077\u001b[0m             )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_array_api.py:179\u001b[0m, in \u001b[0;36m_is_numpy_namespace\u001b[0;34m(xp)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_is_numpy_namespace\u001b[39m(xp):\n\u001b[1;32m    178\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return True if xp is backed by NumPy.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m _NUMPY_NAMESPACE_NAMES\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_array_api.py:373\u001b[0m, in \u001b[0;36m_NumPyAPIWrapper.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[0;32m--> 373\u001b[0m     attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(numpy, name)\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# Support device kwargs and make sure they are on the CPU\u001b[39;00m\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_CREATION_FUNCS:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "configs = []\n",
    "for percentile in [0.80, 0.85, 0.90, 0.95]:\n",
    "    for seed in [42, 123, 456, 789, 999]:\n",
    "        for n_shadows in [5, 10, 15]:\n",
    "            configs.append({\n",
    "                'forget_percentile': percentile,\n",
    "                'random_seed': 42, \n",
    "                'num_shadow_models': n_shadows,\n",
    "                'training_size': 900\n",
    "            })\n",
    "\n",
    "all_results = []\n",
    "failed_runs = []\n",
    "\n",
    "for i, config in enumerate(configs):\n",
    "    try:\n",
    "        \n",
    "        # Run your pipeline\n",
    "        result = run_pipeline(config)\n",
    "        \n",
    "        # Store results with config info\n",
    "        all_results.append({\n",
    "            'percentile': f\"{config['forget_percentile']*100:.0f}th\",\n",
    "            'seed': config['random_seed'],\n",
    "            'n_shadows': config['num_shadow_models'],\n",
    "            'target_attack_acc': result['target_accuracy'],\n",
    "            'unlearn_attack_acc': result['unlearn_accuracy'],\n",
    "            'improvement': result['target_accuracy'] - result['unlearn_accuracy'],\n",
    "            'non_member_detection': 1 - result['unlearn_accuracy'],\n",
    "            'forget_set_size': len(result['forget_set'])\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"FAILED: {config} - Error: {e}\")\n",
    "        failed_runs.append({'config': config, 'error': str(e)})\n",
    "\n",
    "# Convert to DataFrame for analysis\n",
    "df_results = pd.DataFrame(all_results)\n",
    "print(f\"Completed: {len(all_results)} successful, {len(failed_runs)} failed\")\n",
    "\n",
    "# Quick analysis\n",
    "print(\"\\nSummary by percentile:\")\n",
    "print(df_results.groupby('percentile')['improvement'].agg(['mean', 'min', 'max']))\n",
    "\n",
    "# Run all combinations and analyze patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 attack accuracy: 0.507\n",
      "Class 1 attack accuracy: 0.506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 attack accuracy: 0.507\n",
      "Class 1 attack accuracy: 0.506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 attack accuracy: 0.507\n",
      "Class 1 attack accuracy: 0.506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 attack accuracy: 0.507\n",
      "Class 1 attack accuracy: 0.506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 attack accuracy: 0.507\n",
      "Class 1 attack accuracy: 0.506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 attack accuracy: 0.507\n",
      "Class 1 attack accuracy: 0.506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 attack accuracy: 0.507\n",
      "Class 1 attack accuracy: 0.506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 attack accuracy: 0.507\n",
      "Class 1 attack accuracy: 0.506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 attack accuracy: 0.507\n",
      "Class 1 attack accuracy: 0.506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def analyze_forget_set_effects():\n",
    "    percentiles = [ .81,.83,0.85, 0.87, 0.89, 0.91, 0.93, 0.95, 0.97]\n",
    "    results = []\n",
    "        \n",
    "    for p in percentiles:\n",
    "        config = {\n",
    "                'forget_percentile': p,\n",
    "                'random_seed': 42,  # Keep consistent for comparison\n",
    "                'num_shadow_models': 10,\n",
    "                'training_size': 900\n",
    "            }\n",
    "            \n",
    "        result = run_pipeline(config)\n",
    "            \n",
    "        results.append({\n",
    "                'percentile': f\"{p*100:.0f}th\",\n",
    "                'forget_size': len(result['forget_set']),\n",
    "                'privacy_gain': (result['target_accuracy'] - result['unlearn_accuracy']) * 100,\n",
    "                'target_acc': result['target_accuracy'] * 100,\n",
    "                'unlearn_acc': result['unlearn_accuracy'] * 100\n",
    "        })\n",
    "        \n",
    "    return results\n",
    "\n",
    "# Run the analysis\n",
    "results = analyze_forget_set_effects()\n",
    "\n",
    "# Extract data for plotting\n",
    "forget_sizes = [r['forget_size'] for r in results]\n",
    "privacy_gains = [r['privacy_gain'] for r in results]\n",
    "percentiles = [r['percentile'] for r in results]\n",
    "\n",
    "# Create your plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(forget_sizes, privacy_gains, 'bo-', linewidth=2, markersize=8)\n",
    "plt.xlabel('Forget Set Size')\n",
    "plt.ylabel('Privacy Gain (% Attack Accuracy Drop)')\n",
    "plt.title('Privacy vs Forget Set Size')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "for i, (x, y, label) in enumerate(zip(forget_sizes, privacy_gains, percentiles)):\n",
    "    plt.annotate(label, (x, y), xytext=(5, 5), textcoords='offset points')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 attack accuracy: 0.508\n",
      "Class 1 attack accuracy: 0.502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 attack accuracy: 0.509\n",
      "Class 1 attack accuracy: 0.499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 attack accuracy: 0.502\n",
      "Class 1 attack accuracy: 0.503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 attack accuracy: 0.507\n",
      "Class 1 attack accuracy: 0.506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 attack accuracy: 0.503\n",
      "Class 1 attack accuracy: 0.490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 attack accuracy: 0.505\n",
      "Class 1 attack accuracy: 0.540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 attack accuracy: 0.497\n",
      "Class 1 attack accuracy: 0.515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 attack accuracy: 0.508\n",
      "Class 1 attack accuracy: 0.547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 attack accuracy: 0.506\n",
      "Class 1 attack accuracy: 0.542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 attack accuracy: 0.499\n",
      "Class 1 attack accuracy: 0.515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 attack accuracy: 0.495\n",
      "Class 1 attack accuracy: 0.527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 attack accuracy: 0.501\n",
      "Class 1 attack accuracy: 0.529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 attack accuracy: 0.500\n",
      "Class 1 attack accuracy: 0.530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 attack accuracy: 0.511\n",
      "Class 1 attack accuracy: 0.514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 attack accuracy: 0.497\n",
      "Class 1 attack accuracy: 0.536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 attack accuracy: 0.499\n",
      "Class 1 attack accuracy: 0.543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 attack accuracy: 0.504\n",
      "Class 1 attack accuracy: 0.550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 attack accuracy: 0.511\n",
      "Class 1 attack accuracy: 0.552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 attack accuracy: 0.510\n",
      "Class 1 attack accuracy: 0.557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 attack accuracy: 0.504\n",
      "Class 1 attack accuracy: 0.535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 attack accuracy: 0.510\n",
      "Class 1 attack accuracy: 0.515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 attack accuracy: 0.499\n",
      "Class 1 attack accuracy: 0.547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 attack accuracy: 0.508\n",
      "Class 1 attack accuracy: 0.545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shadow Model Count Analysis:\n",
      "==================================================\n",
      " 6 models:  26.2% privacy gain, Target:  78.9%, Unlearn:  52.7%\n",
      " 7 models:  18.8% privacy gain, Target:  63.5%, Unlearn:  44.7%\n",
      " 8 models:  30.0% privacy gain, Target:  77.8%, Unlearn:  47.7%\n",
      "10 models:  24.0% privacy gain, Target:  71.2%, Unlearn:  47.2%\n",
      "12 models:  26.7% privacy gain, Target:  78.8%, Unlearn:  52.1%\n",
      "14 models:   2.8% privacy gain, Target:  45.2%, Unlearn:  42.4%\n",
      "16 models:  28.2% privacy gain, Target:  78.4%, Unlearn:  50.2%\n",
      "18 models:  31.1% privacy gain, Target:  76.7%, Unlearn:  45.6%\n",
      "20 models:  30.6% privacy gain, Target:  77.3%, Unlearn:  46.7%\n",
      "22 models:  27.2% privacy gain, Target:  78.6%, Unlearn:  51.4%\n",
      "24 models:  29.3% privacy gain, Target:  78.1%, Unlearn:  48.8%\n",
      "26 models:  24.3% privacy gain, Target:  79.0%, Unlearn:  54.7%\n",
      "28 models:  28.6% privacy gain, Target:  78.3%, Unlearn:  49.8%\n",
      "30 models:  29.1% privacy gain, Target:  78.1%, Unlearn:  49.0%\n",
      "32 models:  29.6% privacy gain, Target:  78.0%, Unlearn:  48.4%\n",
      "34 models:  29.7% privacy gain, Target:  77.8%, Unlearn:  48.1%\n",
      "36 models:  28.0% privacy gain, Target:  78.5%, Unlearn:  50.5%\n",
      "38 models:  30.0% privacy gain, Target:  77.8%, Unlearn:  47.8%\n",
      "40 models:  28.3% privacy gain, Target:  78.4%, Unlearn:  50.1%\n",
      "42 models:  29.8% privacy gain, Target:  77.9%, Unlearn:  48.1%\n",
      "44 models:  30.5% privacy gain, Target:  77.5%, Unlearn:  47.0%\n",
      "47 models:  29.4% privacy gain, Target:  78.0%, Unlearn:  48.6%\n",
      "50 models:  29.5% privacy gain, Target:  78.0%, Unlearn:  48.5%\n",
      "\n",
      "Optimal: 18 shadow models with 31.1% privacy gain\n"
     ]
    }
   ],
   "source": [
    "def analyze_shadow_model_effects():\n",
    "    # Test different numbers of shadow models\n",
    "    shadow_counts = [6, 7, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 47, 50]\n",
    "    results = []\n",
    "    \n",
    "    for n_shadows in shadow_counts:\n",
    "        config = {\n",
    "            'forget_percentile': 0.85,  # Use optimal percentile from previous analysis\n",
    "            'random_seed': 42,\n",
    "            'num_shadow_models': n_shadows,\n",
    "            'training_size': 900\n",
    "        }\n",
    "        \n",
    "        result = run_pipeline(config)\n",
    "      \n",
    "        \n",
    "        results.append({\n",
    "            'n_shadow_models': n_shadows,\n",
    "            'forget_size': len(result['forget_set']),\n",
    "            'privacy_gain': (result['target_accuracy'] - result['unlearn_accuracy']) * 100,\n",
    "            'target_acc': result['target_accuracy'] * 100,\n",
    "            'unlearn_acc': result['unlearn_accuracy'] * 100,\n",
    "            'non_member_detection': (1 - result['unlearn_accuracy']) * 100,\n",
    "         \n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run the analysis\n",
    "shadow_results = analyze_shadow_model_effects()\n",
    "\n",
    "# Extract data for plotting\n",
    "shadow_counts = [r['n_shadow_models'] for r in shadow_results]\n",
    "privacy_gains = [r['privacy_gain'] for r in shadow_results]\n",
    "target_accs = [r['target_acc'] for r in shadow_results]\n",
    "unlearn_accs = [r['unlearn_acc'] for r in shadow_results]\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Main plot: Privacy Gain vs Shadow Model Count\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(shadow_counts, privacy_gains, 'ro-', linewidth=2, markersize=8)\n",
    "plt.xlabel('Number of Shadow Models')\n",
    "plt.ylabel('Privacy Gain (% Attack Accuracy Drop)')\n",
    "plt.title('Privacy Gain vs Shadow Model Count')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Annotate points\n",
    "for x, y in zip(shadow_counts, privacy_gains):\n",
    "    plt.annotate(f'{y:.1f}%', (x, y), xytext=(0, 10), textcoords='offset points', ha='center')\n",
    "\n",
    "# Subplot 2: Target Attack Accuracy\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(shadow_counts, target_accs, 'bo-', linewidth=2, markersize=6)\n",
    "plt.xlabel('Number of Shadow Models')\n",
    "plt.ylabel('Target Attack Accuracy (%)')\n",
    "plt.title('Attack Baseline Stability')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axhline(y=70, color='r', linestyle='--', alpha=0.7, label='Minimum Reliable Threshold')\n",
    "plt.legend()\n",
    "\n",
    "# Subplot 3: Unlearn Attack Accuracy\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(shadow_counts, unlearn_accs, 'go-', linewidth=2, markersize=6)\n",
    "plt.xlabel('Number of Shadow Models')\n",
    "plt.ylabel('Unlearn Attack Accuracy (%)')\n",
    "plt.title('Unlearning Effectiveness')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axhline(y=50, color='r', linestyle='--', alpha=0.7, label='Random Guessing')\n",
    "plt.legend()\n",
    "\n",
    "# Subplot 4: Both lines together\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(shadow_counts, target_accs, 'bo-', linewidth=2, markersize=6, label='Target (Pre-unlearning)')\n",
    "plt.plot(shadow_counts, unlearn_accs, 'ro-', linewidth=2, markersize=6, label='Unlearn (Post-unlearning)')\n",
    "plt.xlabel('Number of Shadow Models')\n",
    "plt.ylabel('Attack Accuracy (%)')\n",
    "plt.title('Attack Performance Comparison')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nShadow Model Count Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "for r in shadow_results:\n",
    "    print(f\"{r['n_shadow_models']:2d} models: {r['privacy_gain']:5.1f}% privacy gain, \"\n",
    "          f\"Target: {r['target_acc']:5.1f}%, Unlearn: {r['unlearn_acc']:5.1f}%\")\n",
    "\n",
    "# Find optimal number\n",
    "best_idx = max(range(len(shadow_results)), key=lambda i: shadow_results[i]['privacy_gain'])\n",
    "optimal = shadow_results[best_idx]\n",
    "print(f\"\\nOptimal: {optimal['n_shadow_models']} shadow models with {optimal['privacy_gain']:.1f}% privacy gain\")\n",
    "# Check shadow model chunk sizes and performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limited evaluation on different data types/models\n",
    "No standardized benchmarks for \"how unlearned is unlearned enough?\"\n",
    "What's the privacy-utility tradeoff curve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vary number of shadow models: Test with 1, 5, 10, 15, 20 shadow models\n",
    "Ablation study: Test individual confidence features vs. all combined\n",
    "Data size impact: Vary the size of data each shadow model trains on"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
